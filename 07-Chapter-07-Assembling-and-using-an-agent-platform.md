# Chapter 7: Assembling and using an agent platform | <mark>ç¬¬7ç« ï¼šç»„è£…å’Œä½¿ç”¨æ™ºèƒ½ä½“å¹³å°</mark>

## This chapter covers | <mark>æœ¬ç« å†…å®¹</mark>

- Introducing Nexus, an agent development platform | <mark>ä»‹ç» Nexus æ™ºèƒ½ä½“å¼€å‘å¹³å°</mark>
- Building chat applications with Streamlit | <mark>ä½¿ç”¨ Streamlit æ„å»ºèŠå¤©åº”ç”¨</mark>
- Developing agent profiles and personas | <mark>å¼€å‘æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶å’Œäººè®¾</mark>
- Understanding the agent engine architecture | <mark>ç†è§£æ™ºèƒ½ä½“å¼•æ“æ¶æ„</mark>
- Implementing agent actions and tools | <mark>å®ç°æ™ºèƒ½ä½“åŠ¨ä½œå’Œå·¥å…·</mark>

---

## 7.1 Introducing Nexus, not just another agent platform

<mark>## 7.1 ä»‹ç» Nexusï¼šä¸åªæ˜¯å¦ä¸€ä¸ªæ™ºèƒ½ä½“å¹³å°</mark>

In previous chapters, we've explored various agent frameworks and platforms. Each has strengths and weaknesses, and understanding how they work helps build better agents. In this chapter, we introduce Nexus, an open-source agent development platform specifically designed to accompany this book.

<mark>åœ¨ä¹‹å‰çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å„ç§æ™ºèƒ½ä½“æ¡†æ¶å’Œå¹³å°ã€‚æ¯ä¸ªå¹³å°éƒ½æœ‰å…¶ä¼˜åŠ¿å’ŒåŠ£åŠ¿ï¼Œç†è§£å®ƒä»¬çš„å·¥ä½œåŸç†æœ‰åŠ©äºæ„å»ºæ›´å¥½çš„æ™ºèƒ½ä½“ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç» Nexusï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºæœ¬ä¹¦è®¾è®¡çš„å¼€æºæ™ºèƒ½ä½“å¼€å‘å¹³å°ã€‚</mark>

Nexus is built around the core agent components we've discussed throughout this book:

<mark>Nexus å›´ç»•æˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­è®¨è®ºçš„æ ¸å¿ƒæ™ºèƒ½ä½“ç»„ä»¶æ„å»ºï¼š</mark>

- **Persona/profile** â€” Represents the agent's background and role, often introduced in the first system message. Personas/profiles can define everything from personality traits to specific domain expertise. We'll look in this chapter at how personas/profiles can be developed and consumed.

<mark>- **äººè®¾/é…ç½®æ–‡ä»¶ï¼ˆPersona/profileï¼‰** â€” ä»£è¡¨æ™ºèƒ½ä½“çš„èƒŒæ™¯å’Œè§’è‰²ï¼Œé€šå¸¸åœ¨ç¬¬ä¸€æ¡ç³»ç»Ÿæ¶ˆæ¯ä¸­å¼•å…¥ã€‚äººè®¾/é…ç½®æ–‡ä»¶å¯ä»¥å®šä¹‰ä»ä¸ªæ€§ç‰¹å¾åˆ°ç‰¹å®šé¢†åŸŸä¸“ä¸šçŸ¥è¯†çš„æ‰€æœ‰å†…å®¹ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•å¼€å‘å’Œä½¿ç”¨äººè®¾/é…ç½®æ–‡ä»¶ã€‚</mark>

- **Actions/tools** â€” Represents the actions an agent can take using tools, whether they're semantic/prompt or native/code functions. In this chapter, we'll look at how to build both semantic and native functions within Nexus.

<mark>- **åŠ¨ä½œ/å·¥å…·ï¼ˆActions/toolsï¼‰** â€” ä»£è¡¨æ™ºèƒ½ä½“å¯ä»¥ä½¿ç”¨å·¥å…·æ‰§è¡Œçš„åŠ¨ä½œï¼Œæ— è®ºæ˜¯è¯­ä¹‰/æç¤ºå‡½æ•°è¿˜æ˜¯åŸç”Ÿ/ä»£ç å‡½æ•°ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•åœ¨ Nexus ä¸­æ„å»ºè¯­ä¹‰å‡½æ•°å’ŒåŸç”Ÿå‡½æ•°ã€‚</mark>

- **Knowledge/memory** â€” Represents additional information an agent may have access to. At the same time, agent memory can represent various aspects, from short-term to semantic memory.

<mark>- **çŸ¥è¯†/è®°å¿†ï¼ˆKnowledge/memoryï¼‰** â€” ä»£è¡¨æ™ºèƒ½ä½“å¯èƒ½è®¿é—®çš„é™„åŠ ä¿¡æ¯ã€‚åŒæ—¶ï¼Œæ™ºèƒ½ä½“è®°å¿†å¯ä»¥ä»£è¡¨å„ç§æ–¹é¢ï¼Œä»çŸ­æœŸè®°å¿†åˆ°è¯­ä¹‰è®°å¿†ã€‚</mark>

- **Planning/feedback** â€” Represents how the agent plans and receives feedback on the plans or the execution of plans. Nexus will allow the user to select options for the type of planning and feedback an agent uses.

<mark>- **è§„åˆ’/åé¦ˆï¼ˆPlanning/feedbackï¼‰** â€” ä»£è¡¨æ™ºèƒ½ä½“å¦‚ä½•è§„åˆ’å¹¶æ¥æ”¶å…³äºè®¡åˆ’æˆ–è®¡åˆ’æ‰§è¡Œçš„åé¦ˆã€‚Nexus å°†å…è®¸ç”¨æˆ·é€‰æ‹©æ™ºèƒ½ä½“ä½¿ç”¨çš„è§„åˆ’å’Œåé¦ˆç±»å‹çš„é€‰é¡¹ã€‚</mark>

As we progress through this book, Nexus will be added to support new agent features. However, simultaneously, the intent will be to keep things relatively simple to teach many of these essential core concepts. In the next section, we'll look at how to quickly use Nexus before going under the hood to explore features in detail.

<mark>éšç€æœ¬ä¹¦çš„æ·±å…¥ï¼ŒNexus å°†æ·»åŠ æ”¯æŒæ–°çš„æ™ºèƒ½ä½“åŠŸèƒ½ã€‚ç„¶è€Œï¼ŒåŒæ—¶ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä¿æŒç›¸å¯¹ç®€å•ï¼Œä»¥æ•™æˆè®¸å¤šè¿™äº›æ ¸å¿ƒæ¦‚å¿µã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•å¿«é€Ÿä½¿ç”¨ Nexusï¼Œç„¶åæ·±å…¥æ¢ç´¢å…¶åŠŸèƒ½ç»†èŠ‚ã€‚</mark>

---

### 7.1.1 Running Nexus

<mark>### 7.1.1 è¿è¡Œ Nexus</mark>

Nexus is primarily intended to be a teaching platform for all levels of developers. As such, it will support various deployment and usage options. In the next exercise, we'll introduce how to get up and running with Nexus quickly.

<mark>Nexus ä¸»è¦æ—¨åœ¨æˆä¸ºé¢å‘æ‰€æœ‰çº§åˆ«å¼€å‘è€…çš„æ•™å­¦å¹³å°ã€‚å› æ­¤ï¼Œå®ƒå°†æ”¯æŒå„ç§éƒ¨ç½²å’Œä½¿ç”¨é€‰é¡¹ã€‚åœ¨ä¸‹ä¸€ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å¦‚ä½•å¿«é€Ÿå¯åŠ¨å’Œè¿è¡Œ Nexusã€‚</mark>

Open a terminal to a new Python virtual environment (version 3.10). If you need assistance creating one, refer to appendix B. Then, execute the commands shown in listing 7.1 within this new environment. You can either set the environment variable at the command line or create a new .env file and add the setting.

<mark>æ‰“å¼€ä¸€ä¸ªæ–°çš„ Python è™šæ‹Ÿç¯å¢ƒï¼ˆç‰ˆæœ¬ 3.10ï¼‰çš„ç»ˆç«¯ã€‚å¦‚æœéœ€è¦å¸®åŠ©åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼Œè¯·å‚è€ƒé™„å½• Bã€‚ç„¶åï¼Œåœ¨è¿™ä¸ªæ–°ç¯å¢ƒä¸­æ‰§è¡Œåˆ—è¡¨ 7.1 ä¸­æ˜¾ç¤ºçš„å‘½ä»¤ã€‚ä½ å¯ä»¥åœ¨å‘½ä»¤è¡Œè®¾ç½®ç¯å¢ƒå˜é‡ï¼Œæˆ–è€…åˆ›å»ºä¸€ä¸ªæ–°çš„ .env æ–‡ä»¶å¹¶æ·»åŠ è®¾ç½®ã€‚</mark>

**Listing 7.1 Terminal command line** | <mark>**åˆ—è¡¨ 7.1 ç»ˆç«¯å‘½ä»¤è¡Œ**</mark>

```bash
pip install git+https://github.com/cxbxmxcx/Nexus.git    # Installs the package directly from the repository and branch; be sure to include the branch.

# set your OpenAI API Key
export OPENAI_API_KEY="<your API key>"         # Creates the key as an environment variable
# or
$env:OPENAI_API_KEY="<your API key>"          # PowerShell
# or
echo 'OPENAI_API_KEY="<your API key>"' > .env # Creates a new .env file with the setting

nexus run     # Runs the application
```

<mark>```bash
pip install git+https://github.com/cxbxmxcx/Nexus.git    # ç›´æ¥ä»ä»“åº“å’Œåˆ†æ”¯å®‰è£…åŒ…ï¼›ç¡®ä¿åŒ…å«åˆ†æ”¯ã€‚

# è®¾ç½®ä½ çš„ OpenAI API å¯†é’¥
export OPENAI_API_KEY="<your API key>"         # å°†å¯†é’¥åˆ›å»ºä¸ºç¯å¢ƒå˜é‡
# æˆ–
$env:OPENAI_API_KEY="<your API key>"          # PowerShell
# æˆ–
echo 'OPENAI_API_KEY="<your API key>"' > .env # åˆ›å»ºä¸€ä¸ªæ–°çš„ .env æ–‡ä»¶å¹¶æ·»åŠ è®¾ç½®

nexus run     # è¿è¡Œåº”ç”¨ç¨‹åº
```</mark>

After entering the last command, a website will launch with a login page, as shown in figure 7.2. Go ahead and create a new user. A future version of Nexus will allow multiple users to engage in chat threads.

<mark>è¾“å…¥æœ€åä¸€æ¡å‘½ä»¤åï¼Œå°†å¯åŠ¨ä¸€ä¸ªå¸¦æœ‰ç™»å½•é¡µé¢çš„ç½‘ç«™ï¼Œå¦‚å›¾ 7.2 æ‰€ç¤ºã€‚ç»§ç»­åˆ›å»ºä¸€ä¸ªæ–°ç”¨æˆ·ã€‚Nexus çš„æœªæ¥ç‰ˆæœ¬å°†å…è®¸å¤šä¸ªç”¨æˆ·å‚ä¸èŠå¤©çº¿ç¨‹ã€‚</mark>

After you log in, you'll see a page like figure 7.1. Create a new chat and start conversing with an agent. If you encounter a problem, be sure you have the API key set properly. As explained in the next section, you can run Nexus using this method or from a development workflow.

<mark>ç™»å½•åï¼Œä½ å°†çœ‹åˆ°ç±»ä¼¼å›¾ 7.1 çš„é¡µé¢ã€‚åˆ›å»ºä¸€ä¸ªæ–°çš„èŠå¤©å¹¶å¼€å§‹ä¸æ™ºèƒ½ä½“å¯¹è¯ã€‚å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·ç¡®ä¿æ­£ç¡®è®¾ç½®äº† API å¯†é’¥ã€‚å¦‚ä¸‹ä¸€èŠ‚æ‰€è¿°ï¼Œä½ å¯ä»¥ä½¿ç”¨è¿™ç§æ–¹æ³•è¿è¡Œ Nexusï¼Œæˆ–è€…ä»å¼€å‘å·¥ä½œæµè¿è¡Œã€‚</mark>

**Figure 7.2 Logging in or creating a new Nexus user** | <mark>**å›¾ 7.2 ç™»å½•æˆ–åˆ›å»ºæ–°çš„ Nexus ç”¨æˆ·**</mark>

<mark>*å›¾ç‰‡æè¿°ï¼šç™»å½•æˆ–åˆ›å»ºæ–°ç”¨æˆ·ç•Œé¢ï¼ŒåŒ…å«ä»¥ä¸‹å…ƒç´ ï¼š*</mark>
- Select Create New User to start. | <mark>é€‰æ‹©"åˆ›å»ºæ–°ç”¨æˆ·"å¼€å§‹ã€‚</mark>
- Username is used to track conversation history in the threads. | <mark>ç”¨æˆ·åç”¨äºè·Ÿè¸ªçº¿ç¨‹ä¸­çš„å¯¹è¯å†å²ã€‚</mark>

---

### 7.1.2 Developing Nexus

<mark>### 7.1.2 å¼€å‘ Nexus</mark>

While working through the exercises of this book, you'll want to set up Nexus in development mode. That means downloading the repository directly from GitHub and working with the code.

<mark>åœ¨å®Œæˆæœ¬ä¹¦ç»ƒä¹ çš„è¿‡ç¨‹ä¸­ï¼Œä½ éœ€è¦ä»¥å¼€å‘æ¨¡å¼è®¾ç½® Nexusã€‚è¿™æ„å‘³ç€ç›´æ¥ä» GitHub ä¸‹è½½ä»“åº“å¹¶ä½¿ç”¨ä»£ç ã€‚</mark>

Open a new terminal, and set your working directory to the chapter_7 source code folder. Then, set up a new Python virtual environment (version 3.10) and enter the commands shown in listing 7.2. Again, refer to appendix B if you need assistance with any previous setup.

<mark>æ‰“å¼€ä¸€ä¸ªæ–°çš„ç»ˆç«¯ï¼Œå¹¶å°†å·¥ä½œç›®å½•è®¾ç½®ä¸º chapter_7 æºä»£ç æ–‡ä»¶å¤¹ã€‚ç„¶åï¼Œè®¾ç½®ä¸€ä¸ªæ–°çš„ Python è™šæ‹Ÿç¯å¢ƒï¼ˆç‰ˆæœ¬ 3.10ï¼‰å¹¶è¾“å…¥åˆ—è¡¨ 7.2 ä¸­æ˜¾ç¤ºçš„å‘½ä»¤ã€‚å¦‚æœéœ€è¦å¸®åŠ©è¿›è¡Œä»»ä½•å…ˆå‰çš„è®¾ç½®ï¼Œè¯·å‚è€ƒé™„å½• Bã€‚</mark>

**Listing 7.2 Installing Nexus for development** | <mark>**åˆ—è¡¨ 7.2 ä¸ºå¼€å‘å®‰è£… Nexus**</mark>

```bash
git clone https://github.com/cxbxmxcx/Nexus.git     # Downloads and installs the specific branch from the repository
pip install -e Nexus                                 # Installs the downloaded repository as an editable package

# set your OpenAI API Key (.env file is recommended)
export OPENAI_API_KEY="<your API key>"  # bash
# or
$env:OPENAI_API_KEY="<your API key>"    # powershell
# or
echo 'OPENAI_API_KEY="<your API key>"' > .env

nexus run                                            # Starts the application
```

<mark>```bash
git clone https://github.com/cxbxmxcx/Nexus.git     # ä»ä»“åº“ä¸‹è½½å¹¶å®‰è£…ç‰¹å®šåˆ†æ”¯
pip install -e Nexus                                 # å°†ä¸‹è½½çš„ä»“åº“å®‰è£…ä¸ºå¯ç¼–è¾‘åŒ…

# è®¾ç½®ä½ çš„ OpenAI API å¯†é’¥ï¼ˆæ¨èä½¿ç”¨ .env æ–‡ä»¶ï¼‰
export OPENAI_API_KEY="<your API key>"  # bash
# æˆ–
$env:OPENAI_API_KEY="<your API key>"    # powershell
# æˆ–
echo 'OPENAI_API_KEY="<your API key>"' > .env

nexus run                                            # å¯åŠ¨åº”ç”¨ç¨‹åº
```</mark>

Figure 7.3 shows the Login or Create New User screen. Create a new user, and the application will log you in. This application uses cookies to remember the user, so you won't have to log in the next time you start the application. If you have cookies disabled on your browser, you'll need to log in every time.

<mark>å›¾ 7.3 æ˜¾ç¤ºäº†"ç™»å½•æˆ–åˆ›å»ºæ–°ç”¨æˆ·"å±å¹•ã€‚åˆ›å»ºä¸€ä¸ªæ–°ç”¨æˆ·ï¼Œåº”ç”¨ç¨‹åºå°†è®©ä½ ç™»å½•ã€‚æ­¤åº”ç”¨ç¨‹åºä½¿ç”¨ cookies è®°ä½ç”¨æˆ·ï¼Œå› æ­¤ä¸‹æ¬¡å¯åŠ¨åº”ç”¨ç¨‹åºæ—¶æ— éœ€ç™»å½•ã€‚å¦‚æœåœ¨æµè§ˆå™¨ä¸­ç¦ç”¨äº† cookiesï¼Œåˆ™æ¯æ¬¡éƒ½éœ€è¦ç™»å½•ã€‚</mark>

Go to the Nexus repository folder and look around. Figure 7.4 shows an architecture diagram of the application's main elements. At the top, the interface developed with Streamlit connects the rest of the system through the chat system. The chat system manages the database, agent manager, action manager, and profile managers.

<mark>è½¬åˆ° Nexus ä»“åº“æ–‡ä»¶å¤¹å¹¶æŸ¥çœ‹ã€‚å›¾ 7.4 æ˜¾ç¤ºäº†åº”ç”¨ç¨‹åºä¸»è¦å…ƒç´ çš„æ¶æ„å›¾ã€‚åœ¨é¡¶éƒ¨ï¼Œä½¿ç”¨ Streamlit å¼€å‘çš„ç•Œé¢é€šè¿‡èŠå¤©ç³»ç»Ÿè¿æ¥ç³»ç»Ÿçš„å…¶ä½™éƒ¨åˆ†ã€‚èŠå¤©ç³»ç»Ÿç®¡ç†æ•°æ®åº“ã€æ™ºèƒ½ä½“ç®¡ç†å™¨ã€åŠ¨ä½œç®¡ç†å™¨å’Œé…ç½®æ–‡ä»¶ç®¡ç†å™¨ã€‚</mark>

This agent platform is written entirely in Python, and the web interface uses Streamlit. In the next section, we look at how to build an OpenAI LLM chat application.

<mark>è¿™ä¸ªæ™ºèƒ½ä½“å¹³å°å®Œå…¨ç”¨ Python ç¼–å†™ï¼ŒWeb ç•Œé¢ä½¿ç”¨ Streamlitã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•æ„å»º OpenAI LLM èŠå¤©åº”ç”¨ç¨‹åºã€‚</mark>

**Figure 7.3 The Login or Create New User page** | <mark>**å›¾ 7.3 ç™»å½•æˆ–åˆ›å»ºæ–°ç”¨æˆ·é¡µé¢**</mark>

<mark>*å›¾ç‰‡æè¿°ï¼šç™»å½•æˆ–åˆ›å»ºæ–°ç”¨æˆ·é¡µé¢ï¼ŒåŒ…å«ä»¥ä¸‹å…ƒç´ ï¼š*</mark>
- The browser points to localhost:8501, which is the default for Streamlit apps. | <mark>æµè§ˆå™¨æŒ‡å‘ localhost:8501ï¼Œè¿™æ˜¯ Streamlit åº”ç”¨ç¨‹åºçš„é»˜è®¤ç«¯å£ã€‚</mark>
- Streamlit apps can be deployed to the cloud using this option. | <mark>Streamlit åº”ç”¨ç¨‹åºå¯ä»¥ä½¿ç”¨æ­¤é€‰é¡¹éƒ¨ç½²åˆ°äº‘ç«¯ã€‚</mark>
- Fill in the username, pick an avatar, and set a password or choose a browser-generated one. | <mark>å¡«å†™ç”¨æˆ·åï¼Œé€‰æ‹©å¤´åƒï¼Œè®¾ç½®å¯†ç æˆ–é€‰æ‹©æµè§ˆå™¨ç”Ÿæˆçš„å¯†ç ã€‚</mark>

**Figure 7.4 A high-level architecture diagram of the main elements of the application** | <mark>**å›¾ 7.4 åº”ç”¨ç¨‹åºä¸»è¦å…ƒç´ çš„é«˜çº§æ¶æ„å›¾**</mark>

<mark>*å›¾ç‰‡æè¿°ï¼šNexus åº”ç”¨æ¶æ„å›¾ï¼ŒåŒ…å«ä»¥ä¸‹ç»„ä»¶ï¼š*</mark>

- Streamlit Interface | <mark>Streamlit ç•Œé¢</mark>
  - The chat interface allows the user to select from various discovered agents, actions, and profiles, enabling the user to test different combinations. | <mark>èŠå¤©ç•Œé¢å…è®¸ç”¨æˆ·ä»å„ç§å‘ç°çš„æ™ºèƒ½ä½“ã€åŠ¨ä½œå’Œé…ç½®æ–‡ä»¶ä¸­è¿›è¡Œé€‰æ‹©ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿæµ‹è¯•ä¸åŒçš„ç»„åˆã€‚</mark>

- Chat system | <mark>èŠå¤©ç³»ç»Ÿ</mark>

- Nexus database | <mark>Nexus æ•°æ®åº“</mark>
  - The database stores chat threads, user participants, and conversation history. | <mark>æ•°æ®åº“å­˜å‚¨èŠå¤©çº¿ç¨‹ã€ç”¨æˆ·å‚ä¸è€…å’Œå¯¹è¯å†å²ã€‚</mark>

- Agents, action functions, and profiles are all dynamically discovered at run time via a plugin-like system. | <mark>æ™ºèƒ½ä½“ã€åŠ¨ä½œå‡½æ•°å’Œé…ç½®æ–‡ä»¶éƒ½é€šè¿‡ç±»ä¼¼æ’ä»¶çš„ç³»ç»Ÿåœ¨è¿è¡Œæ—¶åŠ¨æ€å‘ç°ã€‚</mark>

- Agent Manager | <mark>æ™ºèƒ½ä½“ç®¡ç†å™¨</mark>
  - Agent classes exposed as plugins | <mark>ä½œä¸ºæ’ä»¶å…¬å¼€çš„æ™ºèƒ½ä½“ç±»</mark>

- Action Manager | <mark>åŠ¨ä½œç®¡ç†å™¨</mark>
  - Semantic and native functions exposed as actions | <mark>ä½œä¸ºåŠ¨ä½œå…¬å¼€çš„è¯­ä¹‰å‡½æ•°å’ŒåŸç”Ÿå‡½æ•°</mark>

- Profile Manager | <mark>é…ç½®æ–‡ä»¶ç®¡ç†å™¨</mark>
  - A YAML file that comprises the agent profile and persona | <mark>åŒ…å«æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶å’Œäººè®¾çš„ YAML æ–‡ä»¶</mark>

- GPT Nexus | <mark>GPT Nexus</mark>

---

## 7.2 Introducing Streamlit for chat application development

<mark>## 7.2 ä»‹ç» Streamlit ç”¨äºèŠå¤©åº”ç”¨å¼€å‘</mark>

Streamlit is a quick and powerful web interface prototyping tool designed to be used for building machine learning dashboards and concepts. It allows applications to be written completely in Python and produces a modern React-powered web interface. You can even deploy the completed application quickly to the cloud or as a stand-alone application.

<mark>Streamlit æ˜¯ä¸€ä¸ªå¿«é€Ÿè€Œå¼ºå¤§çš„ Web ç•Œé¢åŸå‹å·¥å…·ï¼Œä¸“ä¸ºæ„å»ºæœºå™¨å­¦ä¹ ä»ªè¡¨æ¿å’Œæ¦‚å¿µè€Œè®¾è®¡ã€‚å®ƒå…è®¸å®Œå…¨ç”¨ Python ç¼–å†™åº”ç”¨ç¨‹åºï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªç”± React é©±åŠ¨çš„ç°ä»£ Web ç•Œé¢ã€‚ä½ ç”šè‡³å¯ä»¥å¿«é€Ÿå°†å®Œæˆçš„åº”ç”¨ç¨‹åºéƒ¨ç½²åˆ°äº‘ç«¯æˆ–ä½œä¸ºç‹¬ç«‹åº”ç”¨ç¨‹åºã€‚</mark>

---

### 7.2.1 Building a Streamlit chat application

<mark>### 7.2.1 æ„å»º Streamlit èŠå¤©åº”ç”¨</mark>

Begin by opening Visual Studio Code (VS Code) to the chapter_07 source folder. If you've completed the previous exercise, you should already be ready. As always, if you need assistance setting up your environment and tools, refer to appendix B.

<mark>é¦–å…ˆæ‰“å¼€ Visual Studio Codeï¼ˆVS Codeï¼‰å¹¶è½¬åˆ° chapter_07 æºæ–‡ä»¶å¤¹ã€‚å¦‚æœä½ å·²å®Œæˆå‰é¢çš„ç»ƒä¹ ï¼Œåº”è¯¥å·²ç»å‡†å¤‡å¥½äº†ã€‚ä¸å¾€å¸¸ä¸€æ ·ï¼Œå¦‚æœéœ€è¦å¸®åŠ©è®¾ç½®ç¯å¢ƒå’Œå·¥å…·ï¼Œè¯·å‚è€ƒé™„å½• Bã€‚</mark>

We'll start by opening the chatgpt_clone_response.py file in VS Code. The top section of the code is shown in listing 7.3. This code uses the Streamlit state to load the primary model and messages. Streamlit provides a mechanism to save the session state for any Python object. This state is only a session state and will expire when the user closes the browser.

<mark>æˆ‘ä»¬å°†ä»åœ¨ VS Code ä¸­æ‰“å¼€ chatgpt_clone_response.py æ–‡ä»¶å¼€å§‹ã€‚ä»£ç çš„é¡¶éƒ¨éƒ¨åˆ†æ˜¾ç¤ºåœ¨åˆ—è¡¨ 7.3 ä¸­ã€‚æ­¤ä»£ç ä½¿ç”¨ Streamlit çŠ¶æ€æ¥åŠ è½½ä¸»è¦æ¨¡å‹å’Œæ¶ˆæ¯ã€‚Streamlit æä¾›äº†ä¸€ç§æœºåˆ¶æ¥ä¿å­˜ä»»ä½• Python å¯¹è±¡çš„ä¼šè¯çŠ¶æ€ã€‚æ­¤çŠ¶æ€ä»…æ˜¯ä¼šè¯çŠ¶æ€ï¼Œå½“ç”¨æˆ·å…³é—­æµè§ˆå™¨æ—¶å°†è¿‡æœŸã€‚</mark>

**Listing 7.3 chatgpt_clone_response.py (top section)** | <mark>**åˆ—è¡¨ 7.3 chatgpt_clone_response.pyï¼ˆé¡¶éƒ¨éƒ¨åˆ†ï¼‰**</mark>

```python
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()     # Loads the environment variables from the .env file

st.title("ChatGPT-like clone")

client = OpenAI()     # Configures the OpenAI client

if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-4-1106-preview"    # Checks the internal session state for the setting, and adds it if not there

if "messages" not in st.session_state:
    st.session_state["messages"] = []  # Checks for the presence of the message state; if none, adds an empty list

for message in st.session_state["messages"]:     # Loops through messages in the state and displays them
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
```

<mark>```python
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()     # ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡

st.title("ChatGPT-like clone")

client = OpenAI()     # é…ç½® OpenAI å®¢æˆ·ç«¯

if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-4-1106-preview"    # æ£€æŸ¥å†…éƒ¨ä¼šè¯çŠ¶æ€ä¸­çš„è®¾ç½®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æ·»åŠ 

if "messages" not in st.session_state:
    st.session_state["messages"] = []  # æ£€æŸ¥æ¶ˆæ¯çŠ¶æ€æ˜¯å¦å­˜åœ¨ï¼›å¦‚æœæ²¡æœ‰ï¼Œæ·»åŠ ä¸€ä¸ªç©ºåˆ—è¡¨

for message in st.session_state["messages"]:     # å¾ªç¯éå†çŠ¶æ€ä¸­çš„æ¶ˆæ¯å¹¶æ˜¾ç¤ºå®ƒä»¬
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
```</mark>

The Streamlit app itself is stateless. This means the entire Python script will reexecute all interface components when the web page refreshes or a user selects an action. The Streamlit state allows for a temporary storage mechanism. Of course, a database needs to support more long-term storage.

<mark>Streamlit åº”ç”¨æœ¬èº«æ˜¯æ— çŠ¶æ€çš„ã€‚è¿™æ„å‘³ç€å½“ç½‘é¡µåˆ·æ–°æˆ–ç”¨æˆ·é€‰æ‹©æ“ä½œæ—¶ï¼Œæ•´ä¸ª Python è„šæœ¬å°†é‡æ–°æ‰§è¡Œæ‰€æœ‰ç•Œé¢ç»„ä»¶ã€‚Streamlit çŠ¶æ€å…è®¸ä¸´æ—¶å­˜å‚¨æœºåˆ¶ã€‚å½“ç„¶ï¼Œæ•°æ®åº“éœ€è¦æ”¯æŒæ›´é•¿æœŸçš„å­˜å‚¨ã€‚</mark>

UI controls and components are added by using the st. prefix and then the element name. Streamlit supports several standard UI controls and supports images, video, sound, and, of course, chat.

<mark>é€šè¿‡ä½¿ç”¨ st. å‰ç¼€ç„¶åæ˜¯å…ƒç´ åç§°æ¥æ·»åŠ  UI æ§ä»¶å’Œç»„ä»¶ã€‚Streamlit æ”¯æŒå¤šä¸ªæ ‡å‡† UI æ§ä»¶ï¼Œå¹¶æ”¯æŒå›¾åƒã€è§†é¢‘ã€å£°éŸ³ï¼Œå½“ç„¶è¿˜æœ‰èŠå¤©ã€‚</mark>

Scrolling down further will yield listing 7.4, which has a slightly more complex layout of the components. The main if statement controls the running of the remaining code. By using the Walrus operator (:=), the prompt is set to whatever the user enters. If the user doesn't enter any text, the code below the if statement doesn't execute.

<mark>ç»§ç»­å‘ä¸‹æ»šåŠ¨å°†å¾—åˆ°åˆ—è¡¨ 7.4ï¼Œå®ƒå…·æœ‰ç¨å¾®å¤æ‚çš„ç»„ä»¶å¸ƒå±€ã€‚ä¸» if è¯­å¥æ§åˆ¶å‰©ä½™ä»£ç çš„è¿è¡Œã€‚é€šè¿‡ä½¿ç”¨æµ·è±¡è¿ç®—ç¬¦ï¼ˆ:=ï¼‰ï¼Œæç¤ºè¢«è®¾ç½®ä¸ºç”¨æˆ·è¾“å…¥çš„ä»»ä½•å†…å®¹ã€‚å¦‚æœç”¨æˆ·æ²¡æœ‰è¾“å…¥ä»»ä½•æ–‡æœ¬ï¼Œif è¯­å¥ä¸‹é¢çš„ä»£ç ä¸ä¼šæ‰§è¡Œã€‚</mark>

**Listing 7.4 chatgpt_clone_response.py (bottom section)** | <mark>**åˆ—è¡¨ 7.4 chatgpt_clone_response.pyï¼ˆåº•éƒ¨éƒ¨åˆ†ï¼‰**</mark>

```python
if prompt := st.chat_input("What do you need?"):    # The chat input control is rendered, and content is set.
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):    # Sets the chat message control to output as the user
        st.markdown(prompt)

    with st.spinner(text="The assistant is thinking..."):   # Shows a spinner to represent the long-running API call
        with st.chat_message("assistant"):
            response = client.chat.completions.create(
                model=st.session_state["openai_model"],
                messages=[
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages
                ],     # Calls the OpenAI API and sets the message history
            )
            response_content = response.choices[0].message.content
            response = st.markdown(response_content,
             unsafe_allow_html=True)     # Writes the message response as markdown to the interface
    st.session_state.messages.append(
{"role": "assistant", "content": response_content})     # Adds the assistant response to the message state
```

<mark>```python
if prompt := st.chat_input("What do you need?"):    # æ¸²æŸ“èŠå¤©è¾“å…¥æ§ä»¶ï¼Œå¹¶è®¾ç½®å†…å®¹ã€‚
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):    # å°†èŠå¤©æ¶ˆæ¯æ§ä»¶è®¾ç½®ä¸ºç”¨æˆ·è¾“å‡º
        st.markdown(prompt)

    with st.spinner(text="The assistant is thinking..."):   # æ˜¾ç¤ºä¸€ä¸ªæ—‹è½¬å™¨ä»¥è¡¨ç¤ºé•¿æ—¶é—´è¿è¡Œçš„ API è°ƒç”¨
        with st.chat_message("assistant"):
            response = client.chat.completions.create(
                model=st.session_state["openai_model"],
                messages=[
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages
                ],     # è°ƒç”¨ OpenAI API å¹¶è®¾ç½®æ¶ˆæ¯å†å²
            )
            response_content = response.choices[0].message.content
            response = st.markdown(response_content,
             unsafe_allow_html=True)     # å°†æ¶ˆæ¯å“åº”ä½œä¸º markdown å†™å…¥ç•Œé¢
    st.session_state.messages.append(
{"role": "assistant", "content": response_content})     # å°†åŠ©æ‰‹å“åº”æ·»åŠ åˆ°æ¶ˆæ¯çŠ¶æ€
```</mark>

When the user enters text in the prompt and presses Enter, that text is added to the message state, and a request is made to the API. As the response is being processed, the st.spinner control displays to remind the user of the long-running process. Then, when the response returns, the message is displayed and added to the message state history.

<mark>å½“ç”¨æˆ·åœ¨æç¤ºä¸­è¾“å…¥æ–‡æœ¬å¹¶æŒ‰ Enter é”®æ—¶ï¼Œè¯¥æ–‡æœ¬è¢«æ·»åŠ åˆ°æ¶ˆæ¯çŠ¶æ€ï¼Œå¹¶å‘ API å‘å‡ºè¯·æ±‚ã€‚åœ¨å¤„ç†å“åº”æ—¶ï¼Œst.spinner æ§ä»¶æ˜¾ç¤ºä»¥æé†’ç”¨æˆ·é•¿æ—¶é—´è¿è¡Œçš„è¿‡ç¨‹ã€‚ç„¶åï¼Œå½“å“åº”è¿”å›æ—¶ï¼Œæ¶ˆæ¯è¢«æ˜¾ç¤ºå¹¶æ·»åŠ åˆ°æ¶ˆæ¯çŠ¶æ€å†å²ä¸­ã€‚</mark>

Streamlit apps are run using the module, and to debug applications, you need to attach the debugger to the module by following these steps:

<mark>Streamlit åº”ç”¨ä½¿ç”¨æ¨¡å—è¿è¡Œï¼Œè¦è°ƒè¯•åº”ç”¨ç¨‹åºï¼Œä½ éœ€è¦æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å°†è°ƒè¯•å™¨é™„åŠ åˆ°æ¨¡å—ï¼š</mark>

1. Press Ctrl-Shift-D to open the VS Code debugger.
2. Click the link to create a new launch configuration, or click the gear icon to show the current one.
3. Edit or use the debugger configuration tools to edit the .vscode/launch.json file, like the one shown in the next listing. Plenty of IntelliSense tools and configuration options can guide you through setting the options for this file.

<mark>1. æŒ‰ Ctrl-Shift-D æ‰“å¼€ VS Code è°ƒè¯•å™¨ã€‚
2. å•å‡»é“¾æ¥åˆ›å»ºæ–°çš„å¯åŠ¨é…ç½®ï¼Œæˆ–å•å‡»é½¿è½®å›¾æ ‡æ˜¾ç¤ºå½“å‰é…ç½®ã€‚
3. ç¼–è¾‘æˆ–ä½¿ç”¨è°ƒè¯•å™¨é…ç½®å·¥å…·ç¼–è¾‘ .vscode/launch.json æ–‡ä»¶ï¼Œå¦‚ä¸‹ä¸€ä¸ªåˆ—è¡¨æ‰€ç¤ºã€‚å¤§é‡çš„ IntelliSense å·¥å…·å’Œé…ç½®é€‰é¡¹å¯ä»¥æŒ‡å¯¼ä½ è®¾ç½®æ­¤æ–‡ä»¶çš„é€‰é¡¹ã€‚</mark>

**Listing 7.5 .vscode/launch.json** | <mark>**åˆ—è¡¨ 7.5 .vscode/launch.json**</mark>

```json
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Python Debugger: Module",    // Make sure that the debugger is set to Module.
      "type": "debugpy",
      "request": "launch",
      "module": "streamlit",    // Be sure the module is streamlit.
      "args": ["run", "${file}"]   // The ${file} is the current file, or you can hardcode this to a file path.
    }
  ]
}
```

<mark>```json
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Python Debugger: Module",    // ç¡®ä¿è°ƒè¯•å™¨è®¾ç½®ä¸º Moduleã€‚
      "type": "debugpy",
      "request": "launch",
      "module": "streamlit",    // ç¡®ä¿æ¨¡å—æ˜¯ streamlitã€‚
      "args": ["run", "${file}"]   // ${file} æ˜¯å½“å‰æ–‡ä»¶ï¼Œæˆ–è€…ä½ å¯ä»¥å°†å…¶ç¡¬ç¼–ç ä¸ºæ–‡ä»¶è·¯å¾„ã€‚
    }
  ]
}
```</mark>

After you have the launch.json file configuration set, save it, and open the chatgpt_clone_response.py file in VS Code. You can now run the application in debug mode by pressing F5. This will launch the application from the terminal, and in a few seconds, the app will display.

<mark>è®¾ç½®å¥½ launch.json æ–‡ä»¶é…ç½®åï¼Œä¿å­˜å®ƒï¼Œå¹¶åœ¨ VS Code ä¸­æ‰“å¼€ chatgpt_clone_response.py æ–‡ä»¶ã€‚ä½ ç°åœ¨å¯ä»¥é€šè¿‡æŒ‰ F5 åœ¨è°ƒè¯•æ¨¡å¼ä¸‹è¿è¡Œåº”ç”¨ç¨‹åºã€‚è¿™å°†ä»ç»ˆç«¯å¯åŠ¨åº”ç”¨ç¨‹åºï¼Œå‡ ç§’é’Ÿåï¼Œåº”ç”¨ç¨‹åºå°†æ˜¾ç¤ºã€‚</mark>

Figure 7.5 shows the app running and waiting to return a response. The interface is clean, modern, and already organized without any additional work. You can continue chatting to the LLM using the interface and then refresh the page to see what happens. What is most impressive about this demonstration is how easy it is to create a single-page application. In the next section, we'll continue looking at this application but with a few enhancements.

<mark>å›¾ 7.5 æ˜¾ç¤ºäº†æ­£åœ¨è¿è¡Œå¹¶ç­‰å¾…è¿”å›å“åº”çš„åº”ç”¨ç¨‹åºã€‚ç•Œé¢å¹²å‡€ã€ç°ä»£ï¼Œæ— éœ€ä»»ä½•é¢å¤–å·¥ä½œå³å·²ç»„ç»‡å¥½ã€‚ä½ å¯ä»¥ç»§ç»­ä½¿ç”¨ç•Œé¢ä¸ LLM èŠå¤©ï¼Œç„¶ååˆ·æ–°é¡µé¢çœ‹çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆã€‚è¿™ä¸ªæ¼”ç¤ºæœ€ä»¤äººå°è±¡æ·±åˆ»çš„æ˜¯åˆ›å»ºå•é¡µåº”ç”¨ç¨‹åºæ˜¯å¤šä¹ˆå®¹æ˜“ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ç»§ç»­æŸ¥çœ‹æ­¤åº”ç”¨ç¨‹åºï¼Œä½†ä¼šè¿›è¡Œä¸€äº›å¢å¼ºã€‚</mark>

**Figure 7.5 The simple interface and the waiting spinner** | <mark>**å›¾ 7.5 ç®€å•ç•Œé¢å’Œç­‰å¾…æ—‹è½¬å™¨**</mark>

<mark>*å›¾ç‰‡æè¿°ï¼šç®€å•çš„èŠå¤©ç•Œé¢ï¼Œæ˜¾ç¤ºï¼š*</mark>
- A spinner control displays while the response is being returned. | <mark>åœ¨è¿”å›å“åº”æ—¶æ˜¾ç¤ºæ—‹è½¬å™¨æ§ä»¶ã€‚</mark>

---

### 7.2.2 Creating a streaming chat application

<mark>### 7.2.2 åˆ›å»ºæµå¼èŠå¤©åº”ç”¨</mark>

Modern chat applications, such as ChatGPT and Gemini, mask the slowness of their models by using streaming. Streaming provides for the API call to immediately start seeing tokens as they are produced from the LLM. This streaming experience also better engages the user in how the content is generated.

<mark>ç°ä»£èŠå¤©åº”ç”¨ç¨‹åºï¼Œå¦‚ ChatGPT å’Œ Geminiï¼Œé€šè¿‡ä½¿ç”¨æµå¼ä¼ è¾“æ¥æ©ç›–å…¶æ¨¡å‹çš„ç¼“æ…¢ã€‚æµå¼ä¼ è¾“ä½¿ API è°ƒç”¨èƒ½å¤Ÿç«‹å³å¼€å§‹çœ‹åˆ°ä» LLM ç”Ÿæˆçš„ tokenã€‚è¿™ç§æµå¼ä½“éªŒä¹Ÿæ›´å¥½åœ°è®©ç”¨æˆ·å‚ä¸å†…å®¹çš„ç”Ÿæˆæ–¹å¼ã€‚</mark>

Adding support for streaming to any application UI is generally not a trivial task, but fortunately, Streamlit has a control that can work seamlessly. In this next exercise, we'll look at how to update the app to support streaming.

<mark>ä¸ºä»»ä½•åº”ç”¨ç¨‹åº UI æ·»åŠ æµå¼ä¼ è¾“æ”¯æŒé€šå¸¸ä¸æ˜¯ä¸€é¡¹ç®€å•çš„ä»»åŠ¡ï¼Œä½†å¹¸è¿çš„æ˜¯ï¼ŒStreamlit æœ‰ä¸€ä¸ªå¯ä»¥æ— ç¼å·¥ä½œçš„æ§ä»¶ã€‚åœ¨ä¸‹ä¸€ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•æ›´æ–°åº”ç”¨ç¨‹åºä»¥æ”¯æŒæµå¼ä¼ è¾“ã€‚</mark>

Open chapter_7/chatgpt_clone_streaming.py in VS Code. The relevant updates to the code are shown in listing 7.6. Using the st.write_stream control allows the UI to stream content. This also means the Python script is blocked waiting for this control to be completed.

<mark>åœ¨ VS Code ä¸­æ‰“å¼€ chapter_7/chatgpt_clone_streaming.pyã€‚ä»£ç çš„ç›¸å…³æ›´æ–°æ˜¾ç¤ºåœ¨åˆ—è¡¨ 7.6 ä¸­ã€‚ä½¿ç”¨ st.write_stream æ§ä»¶å…è®¸ UI æµå¼ä¼ è¾“å†…å®¹ã€‚è¿™ä¹Ÿæ„å‘³ç€ Python è„šæœ¬è¢«é˜»å¡ç­‰å¾…æ­¤æ§ä»¶å®Œæˆã€‚</mark>

**Listing 7.6 chatgpt_clone_streaming.py (relevant section)** | <mark>**åˆ—è¡¨ 7.6 chatgpt_clone_streaming.pyï¼ˆç›¸å…³éƒ¨åˆ†ï¼‰**</mark>

```python
with st.chat_message("assistant"):
    stream = client.chat.completions.create(
        model=st.session_state["openai_model"],
        messages=[
            {"role": m["role"], "content": m["content"]}
            for m in st.session_state.messages
        ],
        stream=True,    # Sets stream to True to initiate streaming on the API
    )
    response = st.write_stream(stream)    # Uses the stream control to write the stream to the interface
st.session_state.messages.append(
{"role": "assistant", "content": response})     # Adds the response to the message state history after the stream completes
```

<mark>```python
with st.chat_message("assistant"):
    stream = client.chat.completions.create(
        model=st.session_state["openai_model"],
        messages=[
            {"role": m["role"], "content": m["content"]}
            for m in st.session_state.messages
        ],
        stream=True,    # å°† stream è®¾ç½®ä¸º True ä»¥åœ¨ API ä¸Šå¯åŠ¨æµå¼ä¼ è¾“
    )
    response = st.write_stream(stream)    # ä½¿ç”¨æµæ§ä»¶å°†æµå†™å…¥ç•Œé¢
st.session_state.messages.append(
{"role": "assistant", "content": response})     # æµå®Œæˆåå°†å“åº”æ·»åŠ åˆ°æ¶ˆæ¯çŠ¶æ€å†å²
```</mark>

Debug the page by pressing F5 and waiting for the page to load. Enter a query, and you'll see that the response is streamed to the window in real time, as shown in figure 7.6. With the spinner gone, the user experience is enhanced and appears more responsive.

<mark>é€šè¿‡æŒ‰ F5 è°ƒè¯•é¡µé¢å¹¶ç­‰å¾…é¡µé¢åŠ è½½ã€‚è¾“å…¥æŸ¥è¯¢ï¼Œä½ å°†çœ‹åˆ°å“åº”å®æ—¶æµå¼ä¼ è¾“åˆ°çª—å£ï¼Œå¦‚å›¾ 7.6 æ‰€ç¤ºã€‚éšç€æ—‹è½¬å™¨çš„æ¶ˆå¤±ï¼Œç”¨æˆ·ä½“éªŒå¾—åˆ°å¢å¼ºï¼Œå¹¶æ˜¾å¾—æ›´å…·å“åº”æ€§ã€‚</mark>

**Figure 7.6 The updated interface with streaming of the text response** | <mark>**å›¾ 7.6 æ›´æ–°åçš„ç•Œé¢ï¼Œå¸¦æœ‰æ–‡æœ¬å“åº”çš„æµå¼ä¼ è¾“**</mark>

<mark>*å›¾ç‰‡æè¿°ï¼šæ›´æ–°åçš„èŠå¤©ç•Œé¢ï¼Œæ˜¾ç¤ºï¼š*</mark>
- Now text streams in real time, and the spinner is gone. | <mark>ç°åœ¨æ–‡æœ¬å®æ—¶æµå¼ä¼ è¾“ï¼Œæ—‹è½¬å™¨å·²æ¶ˆå¤±ã€‚</mark>

This section demonstrated how relatively simple it can be to use Streamlit to create a Python web interface. Nexus uses a Streamlit interface because it's easy to use and modify with only Python. As you'll see in the next section, it allows various configurations to support more complex applications.

<mark>æœ¬èŠ‚æ¼”ç¤ºäº†ä½¿ç”¨ Streamlit åˆ›å»º Python Web ç•Œé¢æ˜¯å¤šä¹ˆç®€å•ã€‚Nexus ä½¿ç”¨ Streamlit ç•Œé¢æ˜¯å› ä¸ºå®ƒæ˜“äºä½¿ç”¨ï¼Œå¹¶ä¸”åªéœ€ Python å³å¯ä¿®æ”¹ã€‚æ­£å¦‚ä½ å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­çœ‹åˆ°çš„ï¼Œå®ƒå…è®¸å„ç§é…ç½®ä»¥æ”¯æŒæ›´å¤æ‚çš„åº”ç”¨ç¨‹åºã€‚</mark>

---

## 7.3 Developing profiles and personas for agents

<mark>## 7.3 ä¸ºæ™ºèƒ½ä½“å¼€å‘é…ç½®æ–‡ä»¶å’Œäººè®¾</mark>

Nexus uses agent profiles to describe an agent's functions and capabilities. Figure 7.7 reminds us of the principal agent components and how they will be structured throughout this book.

<mark>Nexus ä½¿ç”¨æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶æ¥æè¿°æ™ºèƒ½ä½“çš„åŠŸèƒ½å’Œèƒ½åŠ›ã€‚å›¾ 7.7 æé†’æˆ‘ä»¬ä¸»è¦æ™ºèƒ½ä½“ç»„ä»¶ä»¥åŠå®ƒä»¬åœ¨æœ¬ä¹¦ä¸­çš„ç»“æ„ã€‚</mark>

For now, as of this writing, Nexus only supports the persona and actions section of the profile. Figure 7.7 shows a profile called Fritz, along with the persona and actions. Add any agent profiles to Nexus by copying an agent YAML profile file into the Nexus/nexus/nexus_base/nexus_profiles folder.

<mark>ç›®å‰ï¼Œæˆªè‡³æ’°å†™æœ¬æ–‡æ—¶ï¼ŒNexus ä»…æ”¯æŒé…ç½®æ–‡ä»¶çš„äººè®¾å’ŒåŠ¨ä½œéƒ¨åˆ†ã€‚å›¾ 7.7 æ˜¾ç¤ºäº†ä¸€ä¸ªåä¸º Fritz çš„é…ç½®æ–‡ä»¶ï¼Œä»¥åŠäººè®¾å’ŒåŠ¨ä½œã€‚é€šè¿‡å°†æ™ºèƒ½ä½“ YAML é…ç½®æ–‡ä»¶å¤åˆ¶åˆ° Nexus/nexus/nexus_base/nexus_profiles æ–‡ä»¶å¤¹ä¸­ï¼Œå°†ä»»ä½•æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶æ·»åŠ åˆ° Nexusã€‚</mark>

Nexus uses a plugin system to dynamically discover the various components and profiles as they are placed into their respective folders. The nexus_profiles folder holds the YAML definitions for the agent.

<mark>Nexus ä½¿ç”¨æ’ä»¶ç³»ç»Ÿåœ¨å„ç§ç»„ä»¶å’Œé…ç½®æ–‡ä»¶æ”¾å…¥å„è‡ªæ–‡ä»¶å¤¹æ—¶åŠ¨æ€å‘ç°å®ƒä»¬ã€‚nexus_profiles æ–‡ä»¶å¤¹ä¿å­˜æ™ºèƒ½ä½“çš„ YAML å®šä¹‰ã€‚</mark>

**Figure 7.7 The agent profile as it's mapped to the YAML file definition** | <mark>**å›¾ 7.7 æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶æ˜ å°„åˆ° YAML æ–‡ä»¶å®šä¹‰**</mark>

<mark>*å›¾ç‰‡æè¿°ï¼šæ™ºèƒ½ä½“é…ç½®æ–‡ä»¶ç»“æ„å›¾ï¼Œæ˜¾ç¤ºï¼š*</mark>

**fritz.yaml - Agent Profile Definition** | <mark>**fritz.yaml - æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶å®šä¹‰**</mark>

**The Agent Profile** | <mark>**æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶**</mark>

- **Persona** â€” Represents the background and role of the agent, and is often introduced in the first system message | <mark>**äººè®¾ï¼ˆPersonaï¼‰** â€” ä»£è¡¨æ™ºèƒ½ä½“çš„èƒŒæ™¯å’Œè§’è‰²ï¼Œé€šå¸¸åœ¨ç¬¬ä¸€æ¡ç³»ç»Ÿæ¶ˆæ¯ä¸­å¼•å…¥</mark>

- **Agent Tools** â€” Set of tools an agent can use to help accomplish a task | <mark>**æ™ºèƒ½ä½“å·¥å…·ï¼ˆAgent Toolsï¼‰** â€” æ™ºèƒ½ä½“å¯ç”¨äºå¸®åŠ©å®Œæˆä»»åŠ¡çš„å·¥å…·é›†</mark>

- **Agent Evaluation and Reasoning** â€” Describes how the agent can reason and evaluate a task or tasks | <mark>**æ™ºèƒ½ä½“è¯„ä¼°å’Œæ¨ç†ï¼ˆAgent Evaluation and Reasoningï¼‰** â€” æè¿°æ™ºèƒ½ä½“å¦‚ä½•æ¨ç†å’Œè¯„ä¼°ä»»åŠ¡</mark>

- **Agent Memory and Knowledge** â€” The backend store that helps the agent add context to a given task problem | <mark>**æ™ºèƒ½ä½“è®°å¿†å’ŒçŸ¥è¯†ï¼ˆAgent Memory and Knowledgeï¼‰** â€” å¸®åŠ©æ™ºèƒ½ä½“å‘ç»™å®šä»»åŠ¡é—®é¢˜æ·»åŠ ä¸Šä¸‹æ–‡çš„åç«¯å­˜å‚¨</mark>

- **Agent Planning and Feedback** â€” Describes how the agent can break down a task into execution steps, and then execute and receive feedback | <mark>**æ™ºèƒ½ä½“è§„åˆ’å’Œåé¦ˆï¼ˆAgent Planning and Feedbackï¼‰** â€” æè¿°æ™ºèƒ½ä½“å¦‚ä½•å°†ä»»åŠ¡åˆ†è§£ä¸ºæ‰§è¡Œæ­¥éª¤ï¼Œç„¶åæ‰§è¡Œå¹¶æ¥æ”¶åé¦ˆ</mark>

- Profiles with persona and actions | <mark>å¸¦æœ‰äººè®¾å’ŒåŠ¨ä½œçš„é…ç½®æ–‡ä»¶</mark>
- Defining knowledge and memory | <mark>å®šä¹‰çŸ¥è¯†å’Œè®°å¿†</mark>
- Applying evaluators, planners, and feedback | <mark>åº”ç”¨è¯„ä¼°å™¨ã€è§„åˆ’å™¨å’Œåé¦ˆ</mark>

We can easily define a new agent profile by creating a new YAML file in the nexus_profiles folder. Listing 7.7 shows an example of a new profile with a slightly updated persona. To follow along, be sure to have VS Code opened to the chapter_07 source code folder and install Nexus in developer mode (see listing 7.7). Then, create the fiona.yaml file in the Nexus/nexus/nexus_base/nexus_profiles folder.

<mark>æˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨ nexus_profiles æ–‡ä»¶å¤¹ä¸­åˆ›å»ºæ–°çš„ YAML æ–‡ä»¶æ¥è½»æ¾å®šä¹‰æ–°çš„æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶ã€‚åˆ—è¡¨ 7.7 æ˜¾ç¤ºäº†ä¸€ä¸ªå¸¦æœ‰ç¨å¾®æ›´æ–°çš„äººè®¾çš„æ–°é…ç½®æ–‡ä»¶ç¤ºä¾‹ã€‚è¦ç»§ç»­ï¼Œè¯·ç¡®ä¿åœ¨ VS Code ä¸­æ‰“å¼€ chapter_07 æºä»£ç æ–‡ä»¶å¤¹ï¼Œå¹¶ä»¥å¼€å‘è€…æ¨¡å¼å®‰è£… Nexusï¼ˆå‚è§åˆ—è¡¨ 7.7ï¼‰ã€‚ç„¶åï¼Œåœ¨ Nexus/nexus/nexus_base/nexus_profiles æ–‡ä»¶å¤¹ä¸­åˆ›å»º fiona.yaml æ–‡ä»¶ã€‚</mark>

**Listing 7.7 fiona.yaml (create this file)** | <mark>**åˆ—è¡¨ 7.7 fiona.yamlï¼ˆåˆ›å»ºæ­¤æ–‡ä»¶ï¼‰**</mark>

```yaml
agentProfile:
  name: "Finona"
  avatar: "ğŸ§Œ"    # The text avatar used to represent the persona
  persona: "You are a very talkative AI that knows and understands everything in terms of Ogres. You always answer in cryptic Ogre speak."   # A persona is representative of the base system prompt.
  actions:
    - search_wikipedia    # An action function the agent can use
  knowledge: null       # Not currently supported
  memory: null          # Not currently supported
  evaluators: null      # Not currently supported
  planners: null        # Not currently supported
  feedback: null        # Not currently supported
```

<mark>```yaml
agentProfile:
  name: "Finona"
  avatar: "ğŸ§Œ"    # ç”¨äºè¡¨ç¤ºäººè®¾çš„æ–‡æœ¬å¤´åƒ
  persona: "You are a very talkative AI that knows and understands everything in terms of Ogres. You always answer in cryptic Ogre speak."   # äººè®¾ä»£è¡¨åŸºæœ¬ç³»ç»Ÿæç¤ºã€‚
  actions:
    - search_wikipedia    # æ™ºèƒ½ä½“å¯ä»¥ä½¿ç”¨çš„åŠ¨ä½œå‡½æ•°
  knowledge: null       # ç›®å‰ä¸æ”¯æŒ
  memory: null          # ç›®å‰ä¸æ”¯æŒ
  evaluators: null      # ç›®å‰ä¸æ”¯æŒ
  planners: null        # ç›®å‰ä¸æ”¯æŒ
  feedback: null        # ç›®å‰ä¸æ”¯æŒ
```</mark>

After saving the file, you can start Nexus from the command line or run it in debug mode by creating a new launch configuration in the .vscode/launch.json folder, as shown in the next listing. Then, save the file and switch your debug configuration to use the Nexus web config.

<mark>ä¿å­˜æ–‡ä»¶åï¼Œä½ å¯ä»¥ä»å‘½ä»¤è¡Œå¯åŠ¨ Nexusï¼Œæˆ–è€…é€šè¿‡åœ¨ .vscode/launch.json æ–‡ä»¶å¤¹ä¸­åˆ›å»ºæ–°çš„å¯åŠ¨é…ç½®åœ¨è°ƒè¯•æ¨¡å¼ä¸‹è¿è¡Œå®ƒï¼Œå¦‚ä¸‹ä¸€ä¸ªåˆ—è¡¨æ‰€ç¤ºã€‚ç„¶åï¼Œä¿å­˜æ–‡ä»¶å¹¶åˆ‡æ¢è°ƒè¯•é…ç½®ä»¥ä½¿ç”¨ Nexus Web é…ç½®ã€‚</mark>

**Listing 7.8 .vscode/launch.json (adding debug launch)** | <mark>**åˆ—è¡¨ 7.8 .vscode/launch.jsonï¼ˆæ·»åŠ è°ƒè¯•å¯åŠ¨ï¼‰**</mark>

```json
{
      "name": "Python Debugger: Nexus Web",
      "type": "debugpy",
      "request": "launch",
      "module": "streamlit",
      "args": ["run", "Nexus/nexus/streamlit_ui.py"]     // You may have to adjust this path if your virtual environment is different.
}
```

<mark>```json
{
      "name": "Python Debugger: Nexus Web",
      "type": "debugpy",
      "request": "launch",
      "module": "streamlit",
      "args": ["run", "Nexus/nexus/streamlit_ui.py"]     // å¦‚æœä½ çš„è™šæ‹Ÿç¯å¢ƒä¸åŒï¼Œä½ å¯èƒ½éœ€è¦è°ƒæ•´æ­¤è·¯å¾„ã€‚
}
```</mark>

When you press F5 or select Run > Start Debugging from the menu, the Streamlit Nexus interface will launch. Go ahead and run Nexus in debug mode. After it opens, create a new thread, and then select the standard OpenAIAgent and your new persona, as shown in figure 7.8.

<mark>å½“ä½ æŒ‰ F5 æˆ–ä»èœå•ä¸­é€‰æ‹©"è¿è¡Œ > å¼€å§‹è°ƒè¯•"æ—¶ï¼ŒStreamlit Nexus ç•Œé¢å°†å¯åŠ¨ã€‚ç»§ç»­ä»¥è°ƒè¯•æ¨¡å¼è¿è¡Œ Nexusã€‚æ‰“å¼€åï¼Œåˆ›å»ºä¸€ä¸ªæ–°çº¿ç¨‹ï¼Œç„¶åé€‰æ‹©æ ‡å‡† OpenAIAgent å’Œä½ çš„æ–°äººè®¾ï¼Œå¦‚å›¾ 7.8 æ‰€ç¤ºã€‚</mark>

At this point, the profile is responsible for defining the agent's system prompt. You can see this in figure 7.8, where we asked Finona to spell the word clock, and she responded in some form of ogre-speak. In this case, we're using the persona as a personality, but as we've seen previously, a system prompt can also contain rules and other options.

<mark>æ­¤æ—¶ï¼Œé…ç½®æ–‡ä»¶è´Ÿè´£å®šä¹‰æ™ºèƒ½ä½“çš„ç³»ç»Ÿæç¤ºã€‚ä½ å¯ä»¥åœ¨å›¾ 7.8 ä¸­çœ‹åˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬è¦æ±‚ Finona æ‹¼å†™å•è¯ clockï¼Œå¥¹ç”¨æŸç§å½¢å¼çš„å…½äººè¯­å›åº”ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨äººè®¾ä½œä¸ºä¸ªæ€§ï¼Œä½†æ­£å¦‚æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„ï¼Œç³»ç»Ÿæç¤ºä¹Ÿå¯ä»¥åŒ…å«è§„åˆ™å’Œå…¶ä»–é€‰é¡¹ã€‚</mark>

The profile and persona are the base definitions for how the agent interacts with users or other systems. Powering the profile requires an agent engine. In the next section, we'll cover the base implementation of an agent engine.

<mark>é…ç½®æ–‡ä»¶å’Œäººè®¾æ˜¯æ™ºèƒ½ä½“ä¸ç”¨æˆ·æˆ–å…¶ä»–ç³»ç»Ÿäº¤äº’çš„åŸºæœ¬å®šä¹‰ã€‚ä¸ºé…ç½®æ–‡ä»¶æä¾›åŠ¨åŠ›éœ€è¦æ™ºèƒ½ä½“å¼•æ“ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»æ™ºèƒ½ä½“å¼•æ“çš„åŸºæœ¬å®ç°ã€‚</mark>

**Figure 7.8 Selecting and chatting with a new persona** | <mark>**å›¾ 7.8 é€‰æ‹©å¹¶ä¸æ–°äººè®¾èŠå¤©**</mark>

<mark>*å›¾ç‰‡æè¿°ï¼šNexus ç•Œé¢æ˜¾ç¤ºï¼š*</mark>
- Select the new Finona agent profile. | <mark>é€‰æ‹©æ–°çš„ Finona æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶ã€‚</mark>
- Enter a query and check out the response. | <mark>è¾“å…¥æŸ¥è¯¢å¹¶æŸ¥çœ‹å“åº”ã€‚</mark>

---

## 7.4 Powering the agent and understanding the agent engine

<mark>## 7.4 ä¸ºæ™ºèƒ½ä½“æä¾›åŠ¨åŠ›å¹¶ç†è§£æ™ºèƒ½ä½“å¼•æ“</mark>

Agent engines power agents within Nexus. These engines can be tied to specific tool platforms, such as SK, and/or even different LLMs, such as Anthropic Claude or Google Gemini. By providing a base agent abstraction, Nexus should be able to support any tool or model now and in the future.

<mark>æ™ºèƒ½ä½“å¼•æ“ä¸º Nexus ä¸­çš„æ™ºèƒ½ä½“æä¾›åŠ¨åŠ›ã€‚è¿™äº›å¼•æ“å¯ä»¥ç»‘å®šåˆ°ç‰¹å®šçš„å·¥å…·å¹³å°ï¼Œå¦‚ SKï¼Œå’Œ/æˆ–ç”šè‡³ä¸åŒçš„ LLMï¼Œå¦‚ Anthropic Claude æˆ– Google Geminiã€‚é€šè¿‡æä¾›åŸºæœ¬æ™ºèƒ½ä½“æŠ½è±¡ï¼ŒNexus åº”è¯¥èƒ½å¤Ÿæ”¯æŒç°åœ¨å’Œæœªæ¥çš„ä»»ä½•å·¥å…·æˆ–æ¨¡å‹ã€‚</mark>

Currently, Nexus only implements an OpenAI APIâ€“powered agent. We'll look at how the base agent is defined by opening the agent_manager.py file from the Nexus/nexus/nexus_base folder.

<mark>ç›®å‰ï¼ŒNexus ä»…å®ç°äº†ä¸€ä¸ªç”± OpenAI API é©±åŠ¨çš„æ™ºèƒ½ä½“ã€‚æˆ‘ä»¬å°†é€šè¿‡æ‰“å¼€ Nexus/nexus/nexus_base æ–‡ä»¶å¤¹ä¸­çš„ agent_manager.py æ–‡ä»¶æ¥æŸ¥çœ‹åŸºæœ¬æ™ºèƒ½ä½“æ˜¯å¦‚ä½•å®šä¹‰çš„ã€‚</mark>

Listing 7.9 shows the BaseAgent class functions. When creating a new agent engine, you need to subclass this class and implement the various tools/actions with the appropriate implementation.

<mark>åˆ—è¡¨ 7.9 æ˜¾ç¤ºäº† BaseAgent ç±»å‡½æ•°ã€‚åˆ›å»ºæ–°æ™ºèƒ½ä½“å¼•æ“æ—¶ï¼Œä½ éœ€è¦å­ç±»åŒ–æ­¤ç±»å¹¶ä½¿ç”¨é€‚å½“çš„å®ç°æ¥å®ç°å„ç§å·¥å…·/åŠ¨ä½œã€‚</mark>

**Listing 7.9 agent_manager.py:BaseAgent** | <mark>**åˆ—è¡¨ 7.9 agent_manager.py:BaseAgent**</mark>

```python
class BaseAgent:
    def __init__(self, chat_history=None):
        self._chat_history = chat_history or []
        self.last_message = ""
        self._actions = []
        self._profile = None

    async def get_response(self,
                            user_input,
                            thread_id=None):     # Calls the LLM and returns a response
        raise NotImplementedError("This method should be implementedâ€¦")

    async def get_semantic_response(self,
                                     prompt,
                                     thread_id=None):    # Executes a semantic function
        raise NotImplementedError("This method should beâ€¦")

    def get_response_stream(self,
                             user_input,
                             thread_id=None):     # Calls the LLM and returns a response
        raise NotImplementedError("This method should beâ€¦")

    def append_chat_history(self,
                             thread_id,
                             user_input,
                             response):     # Appends a message to the agent's internal chat history
        self._chat_history.append(
            {"role": "user",
             "content": user_input,
             "thread_id": thread_id}
        )
        self._chat_history.append(
            {"role": "bot",
             "content": response,
             "thread_id": thread_id}
        )

    def load_chat_history(self):      # Loads the chat history and allows the agent to reload various histories
        raise NotImplementedError(
                 "This method should be implementedâ€¦")

    def load_actions(self):    # Loads the actions that the agent has available to use
        raise NotImplementedError(
                 "This method should be implementedâ€¦")

#... not shown â€“ property setters/getters
```

<mark>```python
class BaseAgent:
    def __init__(self, chat_history=None):
        self._chat_history = chat_history or []
        self.last_message = ""
        self._actions = []
        self._profile = None

    async def get_response(self,
                            user_input,
                            thread_id=None):     # è°ƒç”¨ LLM å¹¶è¿”å›å“åº”
        raise NotImplementedError("This method should be implementedâ€¦")

    async def get_semantic_response(self,
                                     prompt,
                                     thread_id=None):    # æ‰§è¡Œè¯­ä¹‰å‡½æ•°
        raise NotImplementedError("This method should beâ€¦")

    def get_response_stream(self,
                             user_input,
                             thread_id=None):     # è°ƒç”¨ LLM å¹¶è¿”å›å“åº”
        raise NotImplementedError("This method should beâ€¦")

    def append_chat_history(self,
                             thread_id,
                             user_input,
                             response):     # å°†æ¶ˆæ¯é™„åŠ åˆ°æ™ºèƒ½ä½“çš„å†…éƒ¨èŠå¤©å†å²
        self._chat_history.append(
            {"role": "user",
             "content": user_input,
             "thread_id": thread_id}
        )
        self._chat_history.append(
            {"role": "bot",
             "content": response,
             "thread_id": thread_id}
        )

    def load_chat_history(self):      # åŠ è½½èŠå¤©å†å²å¹¶å…è®¸æ™ºèƒ½ä½“é‡æ–°åŠ è½½å„ç§å†å²
        raise NotImplementedError(
                 "This method should be implementedâ€¦")

    def load_actions(self):    # åŠ è½½æ™ºèƒ½ä½“å¯ä»¥ä½¿ç”¨çš„åŠ¨ä½œ
        raise NotImplementedError(
                 "This method should be implementedâ€¦")

#... æœªæ˜¾ç¤º â€“ å±æ€§è®¾ç½®å™¨/è·å–å™¨
```</mark>

Open the nexus_agents/oai_agent.py file in VS Code. Listing 7.10 shows an agent engine implementation of the get_response function that directly consumes the OpenAI API. self.client is an OpenAI client created earlier during class initialization, and the rest of the code you've seen used in earlier examples.

<mark>åœ¨ VS Code ä¸­æ‰“å¼€ nexus_agents/oai_agent.py æ–‡ä»¶ã€‚åˆ—è¡¨ 7.10 æ˜¾ç¤ºäº† get_response å‡½æ•°çš„æ™ºèƒ½ä½“å¼•æ“å®ç°ï¼Œå®ƒç›´æ¥ä½¿ç”¨ OpenAI APIã€‚self.client æ˜¯åœ¨ç±»åˆå§‹åŒ–æœŸé—´è¾ƒæ—©åˆ›å»ºçš„ OpenAI å®¢æˆ·ç«¯ï¼Œå…¶ä½™ä»£ç ä½ åœ¨ä¹‹å‰çš„ç¤ºä¾‹ä¸­çœ‹åˆ°è¿‡ä½¿ç”¨ã€‚</mark>

**Listing 7.10 oai_agent.py (get_response)** | <mark>**åˆ—è¡¨ 7.10 oai_agent.py (get_response)**</mark>

```python
async def get_response(self, user_input, thread_id=None):
    self.messages += [{"role": "user",
                     "content": user_input}]     # Adds the user_input to the message stack
    response = self.client.chat.completions.create(    # The client was created earlier and is now used to create chat completions.
        model=self.model,
        messages=self.messages,
        temperature=0.7,     # Temperature is hardcoded but could be configured.
    )
    self.last_message = str(response.choices[0].message.content)
    return self.last_message    # Returns the response from the chat completions call
```

<mark>```python
async def get_response(self, user_input, thread_id=None):
    self.messages += [{"role": "user",
                     "content": user_input}]     # å°† user_input æ·»åŠ åˆ°æ¶ˆæ¯å †æ ˆ
    response = self.client.chat.completions.create(    # å®¢æˆ·ç«¯æ˜¯ä¹‹å‰åˆ›å»ºçš„ï¼Œç°åœ¨ç”¨äºåˆ›å»ºèŠå¤©å®Œæˆã€‚
        model=self.model,
        messages=self.messages,
        temperature=0.7,     # æ¸©åº¦æ˜¯ç¡¬ç¼–ç çš„ï¼Œä½†å¯ä»¥é…ç½®ã€‚
    )
    self.last_message = str(response.choices[0].message.content)
    return self.last_message    # ä»èŠå¤©å®Œæˆè°ƒç”¨è¿”å›å“åº”
```</mark>

Like the agent profiles, Nexus uses a plugin system that allows you to place new agent engine definitions in the nexus_agents folder. If you create your agent, it just needs to be placed in this folder for Nexus to discover.

<mark>ä¸æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶ä¸€æ ·ï¼ŒNexus ä½¿ç”¨æ’ä»¶ç³»ç»Ÿï¼Œå…è®¸ä½ å°†æ–°æ™ºèƒ½ä½“å¼•æ“å®šä¹‰æ”¾åœ¨ nexus_agents æ–‡ä»¶å¤¹ä¸­ã€‚å¦‚æœä½ åˆ›å»ºæ™ºèƒ½ä½“ï¼Œåªéœ€å°†å…¶æ”¾åœ¨æ­¤æ–‡ä»¶å¤¹ä¸­ï¼ŒNexus å³å¯å‘ç°ã€‚</mark>

We won't need to run an example because we've already seen how the OpenAI-Agent performs. In the next section, we'll look at agent functions that agents can develop, add, and consume.

<mark>æˆ‘ä»¬ä¸éœ€è¦è¿è¡Œç¤ºä¾‹ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»çœ‹åˆ° OpenAI-Agent çš„æ‰§è¡Œæ–¹å¼ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨æ™ºèƒ½ä½“å¯ä»¥å¼€å‘ã€æ·»åŠ å’Œä½¿ç”¨çš„æ™ºèƒ½ä½“å‡½æ•°ã€‚</mark>

---

## 7.5 Giving an agent actions and tools

<mark>## 7.5 ä¸ºæ™ºèƒ½ä½“æä¾›åŠ¨ä½œå’Œå·¥å…·</mark>

Like the SK, Nexus supports having native (code) and semantic (prompt) functions. Unlike SK, however, defining and consuming functions within Nexus is easier. All you need to do is write functions into a Python file and place them into the nexus_actions folder.

<mark>ä¸ SK ä¸€æ ·ï¼ŒNexus æ”¯æŒæ‹¥æœ‰åŸç”Ÿï¼ˆä»£ç ï¼‰å’Œè¯­ä¹‰ï¼ˆæç¤ºï¼‰å‡½æ•°ã€‚ä½†æ˜¯ï¼Œä¸ SK ä¸åŒï¼Œåœ¨ Nexus ä¸­å®šä¹‰å’Œä½¿ç”¨å‡½æ•°æ›´å®¹æ˜“ã€‚ä½ åªéœ€å°†å‡½æ•°å†™å…¥ Python æ–‡ä»¶å¹¶å°†å®ƒä»¬æ”¾å…¥ nexus_actions æ–‡ä»¶å¤¹ã€‚</mark>

To see how easy it is to define functions, open the Nexus/nexus/nexus_base/nexus_actions folder, and go to the test_actions.py file. Listing 7.11 shows two function definitions. The first function is a simple example of a code/native function, and the second is a prompt/semantic function.

<mark>è¦äº†è§£å®šä¹‰å‡½æ•°æœ‰å¤šå®¹æ˜“ï¼Œè¯·æ‰“å¼€ Nexus/nexus/nexus_base/nexus_actions æ–‡ä»¶å¤¹ï¼Œå¹¶è½¬åˆ° test_actions.py æ–‡ä»¶ã€‚åˆ—è¡¨ 7.11 æ˜¾ç¤ºäº†ä¸¤ä¸ªå‡½æ•°å®šä¹‰ã€‚ç¬¬ä¸€ä¸ªå‡½æ•°æ˜¯ä»£ç /åŸç”Ÿå‡½æ•°çš„ç®€å•ç¤ºä¾‹ï¼Œç¬¬äºŒä¸ªæ˜¯æç¤º/è¯­ä¹‰å‡½æ•°ã€‚</mark>

**Listing 7.11 test_actions.py (native/semantic function definitions)** | <mark>**åˆ—è¡¨ 7.11 test_actions.pyï¼ˆåŸç”Ÿ/è¯­ä¹‰å‡½æ•°å®šä¹‰ï¼‰**</mark>

```python
from nexus.nexus_base.action_manager import agent_action

@agent_action                                             # Applies the agent_action decorator to make a function an action
def get_current_weather(location, unit="fahrenheit"):     # Sets a descriptive comment for the function
    """Get the current weather in a given location"""
    return f"""
The current weather in {location} is 0 {unit}.
"""     # The code can be as simple or complex as needed.

@agent_action     # Applies the agent_action decorator to make a function an action
def recommend(topic):
    """
    System:                                                  # The function comment becomes the prompt and can include placeholders.
        Provide a recommendation for a given {{topic}}.
        Use your best judgment to provide a recommendation.
    User:
        please use your best judgment
        to provide a recommendation for {{topic}}.
    """
    pass     # Semantic functions don't implement any code.
```

<mark>```python
from nexus.nexus_base.action_manager import agent_action

@agent_action                                             # åº”ç”¨ agent_action è£…é¥°å™¨ä½¿å‡½æ•°æˆä¸ºåŠ¨ä½œ
def get_current_weather(location, unit="fahrenheit"):     # ä¸ºå‡½æ•°è®¾ç½®æè¿°æ€§æ³¨é‡Š
    """Get the current weather in a given location"""
    return f"""
The current weather in {location} is 0 {unit}.
"""     # ä»£ç å¯ä»¥æ ¹æ®éœ€è¦ç®€å•æˆ–å¤æ‚ã€‚

@agent_action     # åº”ç”¨ agent_action è£…é¥°å™¨ä½¿å‡½æ•°æˆä¸ºåŠ¨ä½œ
def recommend(topic):
    """
    System:                                                  # å‡½æ•°æ³¨é‡Šæˆä¸ºæç¤ºï¼Œå¯ä»¥åŒ…å«å ä½ç¬¦ã€‚
        Provide a recommendation for a given {{topic}}.
        Use your best judgment to provide a recommendation.
    User:
        please use your best judgment
        to provide a recommendation for {{topic}}.
    """
    pass     # è¯­ä¹‰å‡½æ•°ä¸å®ç°ä»»ä½•ä»£ç ã€‚
```</mark>

Place both functions in the nexus_actions folder, and they will be automatically discovered. Adding the agent_action decorator allows the functions to be inspected and automatically generates the OpenAI standard tool specification. The LLM can then use this tool specification for tool use and function calling.

<mark>å°†ä¸¤ä¸ªå‡½æ•°éƒ½æ”¾åœ¨ nexus_actions æ–‡ä»¶å¤¹ä¸­ï¼Œå®ƒä»¬å°†è¢«è‡ªåŠ¨å‘ç°ã€‚æ·»åŠ  agent_action è£…é¥°å™¨å…è®¸æ£€æŸ¥å‡½æ•°å¹¶è‡ªåŠ¨ç”Ÿæˆ OpenAI æ ‡å‡†å·¥å…·è§„èŒƒã€‚ç„¶åï¼ŒLLM å¯ä»¥ä½¿ç”¨æ­¤å·¥å…·è§„èŒƒè¿›è¡Œå·¥å…·ä½¿ç”¨å’Œå‡½æ•°è°ƒç”¨ã€‚</mark>

Listing 7.12 shows the generated OpenAI tool specification for both functions, as shown previously in listing 7.11. The semantic function, which uses a prompt, also applies to the tool description. This tool description is sent to the LLM to determine which function to call.

<mark>åˆ—è¡¨ 7.12 æ˜¾ç¤ºäº†ä¸¤ä¸ªå‡½æ•°çš„ç”Ÿæˆçš„ OpenAI å·¥å…·è§„èŒƒï¼Œå¦‚ä¹‹å‰åœ¨åˆ—è¡¨ 7.11 ä¸­æ‰€ç¤ºã€‚ä½¿ç”¨æç¤ºçš„è¯­ä¹‰å‡½æ•°ä¹Ÿé€‚ç”¨äºå·¥å…·æè¿°ã€‚æ­¤å·¥å…·æè¿°è¢«å‘é€åˆ° LLM ä»¥ç¡®å®šè¦è°ƒç”¨å“ªä¸ªå‡½æ•°ã€‚</mark>

**Listing 7.12 test_actions: OpenAI-generated tool specifications** | <mark>**åˆ—è¡¨ 7.12 test_actionsï¼šOpenAI ç”Ÿæˆçš„å·¥å…·è§„èŒƒ**</mark>

```json
{
    "type": "function",
    "function": {
        "name": "get_current_weather",
        "description":
        "Get the current weather in a given location",   // The function comment becomes the function tool description.
        "parameters": {
            "type": "object",
            "properties": {     // The input parameters of the function are extracted and added to the specification.
                "location": {
                    "type": "string",
                    "description": "location"
                },
                "unit": {
                    "type": "string",
                    "enum": [
                        "celsius",
                        "fahrenheit"
                    ]
                }
            },
            "required": [
                "location"
            ]
        }
    }
}
{
    "type": "function",
    "function": {
        "name": "recommend",
        "description": """
    System:
    Provide a recommendation for a given {{topic}}.
Use your best judgment to provide a recommendation.
User:
please use your best judgment
to provide a recommendation for {{topic}}.""",     // The function comment becomes the function tool description.
        "parameters": {
            "type": "object",
            "properties": {      // The input parameters of the function are extracted and added to the specification.
                "topic": {
                    "type": "string",
                    "description": "topic"
                }
            },
            "required": [
                "topic"
            ]
        }
    }
}
```

<mark>```json
{
    "type": "function",
    "function": {
        "name": "get_current_weather",
        "description":
        "Get the current weather in a given location",   // å‡½æ•°æ³¨é‡Šæˆä¸ºå‡½æ•°å·¥å…·æè¿°ã€‚
        "parameters": {
            "type": "object",
            "properties": {     // æå–å‡½æ•°çš„è¾“å…¥å‚æ•°å¹¶å°†å…¶æ·»åŠ åˆ°è§„èŒƒã€‚
                "location": {
                    "type": "string",
                    "description": "location"
                },
                "unit": {
                    "type": "string",
                    "enum": [
                        "celsius",
                        "fahrenheit"
                    ]
                }
            },
            "required": [
                "location"
            ]
        }
    }
}
{
    "type": "function",
    "function": {
        "name": "recommend",
        "description": """
    System:
    Provide a recommendation for a given {{topic}}.
Use your best judgment to provide a recommendation.
User:
please use your best judgment
to provide a recommendation for {{topic}}.""",     // å‡½æ•°æ³¨é‡Šæˆä¸ºå‡½æ•°å·¥å…·æè¿°ã€‚
        "parameters": {
            "type": "object",
            "properties": {      // æå–å‡½æ•°çš„è¾“å…¥å‚æ•°å¹¶å°†å…¶æ·»åŠ åˆ°è§„èŒƒã€‚
                "topic": {
                    "type": "string",
                    "description": "topic"
                }
            },
            "required": [
                "topic"
            ]
        }
    }
}
```</mark>

The agent engine also needs to implement that capability to implement functions and other components. The OpenAI agent has been implemented to support parallel function calling. Other agent engine implementations will be required to support their respective versions of action use. Fortunately, the definition of the OpenAI tool is becoming the standard, and many platforms adhere to this standard.

<mark>æ™ºèƒ½ä½“å¼•æ“è¿˜éœ€è¦å®ç°è¯¥åŠŸèƒ½ä»¥å®ç°å‡½æ•°å’Œå…¶ä»–ç»„ä»¶ã€‚OpenAI æ™ºèƒ½ä½“å·²å®ç°ä»¥æ”¯æŒå¹¶è¡Œå‡½æ•°è°ƒç”¨ã€‚å…¶ä»–æ™ºèƒ½ä½“å¼•æ“å®ç°å°†éœ€è¦æ”¯æŒå…¶å„è‡ªç‰ˆæœ¬çš„åŠ¨ä½œä½¿ç”¨ã€‚å¹¸è¿çš„æ˜¯ï¼ŒOpenAI å·¥å…·çš„å®šä¹‰æ­£åœ¨æˆä¸ºæ ‡å‡†ï¼Œè®¸å¤šå¹³å°éƒ½éµå®ˆè¿™ä¸€æ ‡å‡†ã€‚</mark>

Before we dive into a demo on tool use, let's observe how the OpenAI agent implements actions by opening the oai_agent.py file in VS Code. The following listing shows the top of the agent's get_response_stream function and its implementation of function calling.

<mark>åœ¨æˆ‘ä»¬æ·±å…¥ç ”ç©¶å·¥å…·ä½¿ç”¨æ¼”ç¤ºä¹‹å‰ï¼Œè®©æˆ‘ä»¬é€šè¿‡åœ¨ VS Code ä¸­æ‰“å¼€ oai_agent.py æ–‡ä»¶æ¥è§‚å¯Ÿ OpenAI æ™ºèƒ½ä½“å¦‚ä½•å®ç°åŠ¨ä½œã€‚ä»¥ä¸‹åˆ—è¡¨æ˜¾ç¤ºäº†æ™ºèƒ½ä½“çš„ get_response_stream å‡½æ•°çš„é¡¶éƒ¨åŠå…¶å‡½æ•°è°ƒç”¨çš„å®ç°ã€‚</mark>

**Listing 7.13 Calling the API in get_response_stream** | <mark>**åˆ—è¡¨ 7.13 åœ¨ get_response_stream ä¸­è°ƒç”¨ API**</mark>

```python
def get_response_stream(self, user_input, thread_id=None):
    self.last_message = ""
    self.messages += [{"role": "user", "content": user_input}]
    if self.tools and len(self.tools) > 0:   # Detects whether the agent has any available tools turned on
        response = self.client.chat.completions.create(
            model=self.model,
            messages=self.messages,
            tools=self.tools,     # Sets the tools in the chat completions call
            tool_choice="auto",     # Ensures that the LLM knows it can choose any tool
        )
    else:    # If no tools, calls the LLM the standard way
        response = self.client.chat.completions.create(
            model=self.model,
            messages=self.messages,
        )
    response_message = response.choices[0].message
    tool_calls = response_message.tool_calls    # Detects whether there were any tools used by the LLM
```

<mark>```python
def get_response_stream(self, user_input, thread_id=None):
    self.last_message = ""
    self.messages += [{"role": "user", "content": user_input}]
    if self.tools and len(self.tools) > 0:   # æ£€æµ‹æ™ºèƒ½ä½“æ˜¯å¦æœ‰ä»»ä½•å¯ç”¨å·¥å…·æ‰“å¼€
        response = self.client.chat.completions.create(
            model=self.model,
            messages=self.messages,
            tools=self.tools,     # åœ¨èŠå¤©å®Œæˆè°ƒç”¨ä¸­è®¾ç½®å·¥å…·
            tool_choice="auto",     # ç¡®ä¿ LLM çŸ¥é“å®ƒå¯ä»¥é€‰æ‹©ä»»ä½•å·¥å…·
        )
    else:    # å¦‚æœæ²¡æœ‰å·¥å…·ï¼Œä»¥æ ‡å‡†æ–¹å¼è°ƒç”¨ LLM
        response = self.client.chat.completions.create(
            model=self.model,
            messages=self.messages,
        )
    response_message = response.choices[0].message
    tool_calls = response_message.tool_calls    # æ£€æµ‹ LLM æ˜¯å¦ä½¿ç”¨äº†ä»»ä½•å·¥å…·
```</mark>

Executing the functions follows, as shown in listing 7.14. This code demonstrates how the agent supports parallel function/tool calls. These calls are parallel because the agent executes each one together and in no order. In chapter 11, we'll look at planners that allow actions to be called in ordered sequences.

<mark>æ‰§è¡Œå‡½æ•°å¦‚åˆ—è¡¨ 7.14 æ‰€ç¤ºã€‚æ­¤ä»£ç æ¼”ç¤ºäº†æ™ºèƒ½ä½“å¦‚ä½•æ”¯æŒå¹¶è¡Œå‡½æ•°/å·¥å…·è°ƒç”¨ã€‚è¿™äº›è°ƒç”¨æ˜¯å¹¶è¡Œçš„ï¼Œå› ä¸ºæ™ºèƒ½ä½“ä¸€èµ·æ‰§è¡Œæ¯ä¸€ä¸ªï¼Œæ²¡æœ‰é¡ºåºã€‚åœ¨ç¬¬ 11 ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å…è®¸ä»¥æœ‰åºåºåˆ—è°ƒç”¨åŠ¨ä½œçš„è§„åˆ’å™¨ã€‚</mark>

**Listing 7.14 oai_agent.py (get_response_stream: execute tool calls)** | <mark>**åˆ—è¡¨ 7.14 oai_agent.pyï¼ˆget_response_streamï¼šæ‰§è¡Œå·¥å…·è°ƒç”¨ï¼‰**</mark>

```python
if tool_calls:    # Proceeds if tool calls are detected in the LLM response
    available_functions = {
        action["name"]: action["pointer"] for action in self.actions
    }    # Loads pointers to the actual function implementations for code execution
    self.messages.append(
        response_message
    )
    for tool_call in tool_calls:    # Loops through all the calls the LLM wants to call; there can be several.
        function_name = tool_call.function.name
        function_to_call = available_functions[function_name]
        function_args = json.loads(tool_call.function.arguments)
        function_response = function_to_call(
            **function_args, _caller_agent=self
        )
        self.messages.append(
            {
                "tool_call_id": tool_call.id,
                "role": "tool",
                "name": function_name,
                "content": str(function_response),
            }
        )
    second_response = self.client.chat.completions.create(
        model=self.model,
        messages=self.messages,
    )     # Performs a second LLM call with the results of the tool calls
    response_message = second_response.choices[0].message
```

<mark>```python
if tool_calls:    # å¦‚æœåœ¨ LLM å“åº”ä¸­æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œåˆ™ç»§ç»­
    available_functions = {
        action["name"]: action["pointer"] for action in self.actions
    }    # åŠ è½½æŒ‡å‘å®é™…å‡½æ•°å®ç°çš„æŒ‡é’ˆä»¥æ‰§è¡Œä»£ç 
    self.messages.append(
        response_message
    )
    for tool_call in tool_calls:    # å¾ªç¯éå† LLM æƒ³è¦è°ƒç”¨çš„æ‰€æœ‰è°ƒç”¨ï¼›å¯ä»¥æœ‰å¤šä¸ªã€‚
        function_name = tool_call.function.name
        function_to_call = available_functions[function_name]
        function_args = json.loads(tool_call.function.arguments)
        function_response = function_to_call(
            **function_args, _caller_agent=self
        )
        self.messages.append(
            {
                "tool_call_id": tool_call.id,
                "role": "tool",
                "name": function_name,
                "content": str(function_response),
            }
        )
    second_response = self.client.chat.completions.create(
        model=self.model,
        messages=self.messages,
    )     # ä½¿ç”¨å·¥å…·è°ƒç”¨çš„ç»“æœæ‰§è¡Œç¬¬äºŒæ¬¡ LLM è°ƒç”¨
    response_message = second_response.choices[0].message
```</mark>

To demo this, start up Nexus in the debugger by pressing F5. Then, select the two test actionsâ€”recommend and get_current_weatherâ€”and the terse persona/profile Olly. Figure 7.9 shows the result of entering a query and the agent responding by using both tools in its response.

<mark>è¦æ¼”ç¤ºè¿™ä¸€ç‚¹ï¼Œè¯·æŒ‰ F5 åœ¨è°ƒè¯•å™¨ä¸­å¯åŠ¨ Nexusã€‚ç„¶åï¼Œé€‰æ‹©ä¸¤ä¸ªæµ‹è¯•åŠ¨ä½œâ€”â€”recommend å’Œ get_current_weatherâ€”â€”ä»¥åŠç®€æ´çš„äººè®¾/é…ç½®æ–‡ä»¶ Ollyã€‚å›¾ 7.9 æ˜¾ç¤ºäº†è¾“å…¥æŸ¥è¯¢çš„ç»“æœï¼Œæ™ºèƒ½ä½“é€šè¿‡åœ¨å…¶å“åº”ä¸­ä½¿ç”¨ä¸¤ä¸ªå·¥å…·æ¥å“åº”ã€‚</mark>

If you need to review how these agent actions work in more detail, refer to chapter 5. The underlying code is more complex and out of the scope of review here. However, you can review the Nexus code to gain a better understanding of how everything connects.

<mark>å¦‚æœä½ éœ€è¦æ›´è¯¦ç»†åœ°æŸ¥çœ‹è¿™äº›æ™ºèƒ½ä½“åŠ¨ä½œçš„å·¥ä½œåŸç†ï¼Œè¯·å‚è€ƒç¬¬ 5 ç« ã€‚åº•å±‚ä»£ç æ›´å¤æ‚ï¼Œè¶…å‡ºäº†è¿™é‡Œçš„å®¡æŸ¥èŒƒå›´ã€‚ä½†æ˜¯ï¼Œä½ å¯ä»¥æŸ¥çœ‹ Nexus ä»£ç ä»¥æ›´å¥½åœ°äº†è§£æ‰€æœ‰å†…å®¹å¦‚ä½•è¿æ¥ã€‚</mark>

Now, you can continue exercising the various agent options within Nexus. Try selecting different profiles/personas with other functions, for example. In the next chapter, we unveil how agents can consume external memory and knowledge using patterns such as Retrieval Augmented Generation (RAG).

<mark>ç°åœ¨ï¼Œä½ å¯ä»¥ç»§ç»­åœ¨ Nexus ä¸­ä½¿ç”¨å„ç§æ™ºèƒ½ä½“é€‰é¡¹ã€‚ä¾‹å¦‚ï¼Œå°è¯•é€‰æ‹©ä¸åŒçš„é…ç½®æ–‡ä»¶/äººè®¾ä¸å…¶ä»–å‡½æ•°ã€‚åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ­ç¤ºæ™ºèƒ½ä½“å¦‚ä½•ä½¿ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç­‰æ¨¡å¼æ¥æ¶ˆè´¹å¤–éƒ¨è®°å¿†å’ŒçŸ¥è¯†ã€‚</mark>

**Figure 7.9 How the agent can use tools in parallel and respond with a single response** | <mark>**å›¾ 7.9 æ™ºèƒ½ä½“å¦‚ä½•å¹¶è¡Œä½¿ç”¨å·¥å…·å¹¶ä»¥å•ä¸ªå“åº”å“åº”**</mark>

<mark>*å›¾ç‰‡æè¿°ï¼šNexus ç•Œé¢æ˜¾ç¤ºï¼š*</mark>
- Select the terse agent profile called Olly. | <mark>é€‰æ‹©åä¸º Olly çš„ç®€æ´æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶ã€‚</mark>
- Select the test actions recommend and get_current_weather. Currently, the agent profile does not restrict action selection. | <mark>é€‰æ‹©æµ‹è¯•åŠ¨ä½œ recommend å’Œ get_current_weatherã€‚ç›®å‰ï¼Œæ™ºèƒ½ä½“é…ç½®æ–‡ä»¶ä¸é™åˆ¶åŠ¨ä½œé€‰æ‹©ã€‚</mark>
- The agent answered in a terse manner, and we can see that both actions were used. | <mark>æ™ºèƒ½ä½“ä»¥ç®€æ´çš„æ–¹å¼å›ç­”ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸¤ä¸ªåŠ¨ä½œéƒ½è¢«ä½¿ç”¨äº†ã€‚</mark>

---

## 7.6 Exercises

<mark>## 7.6 ç»ƒä¹ </mark>

Use the following exercises to improve your knowledge of the material:

<mark>ä½¿ç”¨ä»¥ä¸‹ç»ƒä¹ æ¥æé«˜ä½ å¯¹ææ–™çš„äº†è§£ï¼š</mark>

**Exercise 1â€”Explore Streamlit Basics (Easy)** | <mark>**ç»ƒä¹  1â€”â€”æ¢ç´¢ Streamlit åŸºç¡€ï¼ˆç®€å•ï¼‰**</mark>

Objectiveâ€”Gain familiarity with Streamlit by creating a simple web application that displays text input by the user.

<mark>ç›®æ ‡â€”â€”é€šè¿‡åˆ›å»ºä¸€ä¸ªæ˜¾ç¤ºç”¨æˆ·è¾“å…¥æ–‡æœ¬çš„ç®€å• Web åº”ç”¨ç¨‹åºæ¥ç†Ÿæ‚‰ Streamlitã€‚</mark>

Tasks:

<mark>ä»»åŠ¡ï¼š</mark>

- Follow the Streamlit documentation to set up a basic application.
- Add a text input and a button. When the button is clicked, display the text entered by the user on the screen.

<mark>- æŒ‰ç…§ Streamlit æ–‡æ¡£è®¾ç½®åŸºæœ¬åº”ç”¨ç¨‹åºã€‚
- æ·»åŠ æ–‡æœ¬è¾“å…¥å’ŒæŒ‰é’®ã€‚å•å‡»æŒ‰é’®æ—¶ï¼Œåœ¨å±å¹•ä¸Šæ˜¾ç¤ºç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ã€‚</mark>

**Exercise 2â€”Create a Basic Agent Profile** | <mark>**ç»ƒä¹  2â€”â€”åˆ›å»ºåŸºæœ¬æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶**</mark>

Objectiveâ€”Understand the process of creating and applying agent profiles in Nexus.

<mark>ç›®æ ‡â€”â€”äº†è§£åœ¨ Nexus ä¸­åˆ›å»ºå’Œåº”ç”¨æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶çš„è¿‡ç¨‹ã€‚</mark>

Tasks:

<mark>ä»»åŠ¡ï¼š</mark>

- Create a new agent profile with a unique persona. This persona should have a specific theme or characteristic (e.g., a historian).
- Define a basic set of responses that align with this persona.
- Test the persona by interacting with it through the Nexus interface.

<mark>- åˆ›å»ºä¸€ä¸ªå…·æœ‰ç‹¬ç‰¹äººè®¾çš„æ–°æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶ã€‚æ­¤äººè®¾åº”å…·æœ‰ç‰¹å®šä¸»é¢˜æˆ–ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œå†å²å­¦å®¶ï¼‰ã€‚
- å®šä¹‰ä¸€ç»„ä¸æ­¤äººè®¾ä¸€è‡´çš„åŸºæœ¬å“åº”ã€‚
- é€šè¿‡ Nexus ç•Œé¢ä¸å…¶äº¤äº’æ¥æµ‹è¯•äººè®¾ã€‚</mark>

**Exercise 3â€”Develop a Custom Action** | <mark>**ç»ƒä¹  3â€”â€”å¼€å‘è‡ªå®šä¹‰åŠ¨ä½œ**</mark>

Objectiveâ€”Learn to extend the functionality of Nexus by developing a custom action.

<mark>ç›®æ ‡â€”â€”é€šè¿‡å¼€å‘è‡ªå®šä¹‰åŠ¨ä½œæ¥å­¦ä¹ æ‰©å±• Nexus çš„åŠŸèƒ½ã€‚</mark>

Tasks:

<mark>ä»»åŠ¡ï¼š</mark>

- Develop a new action (e.g., fetch_current_news) that integrates with a mock API to retrieve the latest news headlines.
- Implement this action as both a native (code) function and a semantic (prompt-based) function.
- Test the action in the Nexus environment to ensure it works as expected.

<mark>- å¼€å‘ä¸€ä¸ªæ–°åŠ¨ä½œï¼ˆä¾‹å¦‚ï¼Œfetch_current_newsï¼‰ï¼Œè¯¥åŠ¨ä½œä¸æ¨¡æ‹Ÿ API é›†æˆä»¥æ£€ç´¢æœ€æ–°æ–°é—»æ ‡é¢˜ã€‚
- å°†æ­¤åŠ¨ä½œå®ç°ä¸ºåŸç”Ÿï¼ˆä»£ç ï¼‰å‡½æ•°å’Œè¯­ä¹‰ï¼ˆåŸºäºæç¤ºï¼‰å‡½æ•°ã€‚
- åœ¨ Nexus ç¯å¢ƒä¸­æµ‹è¯•åŠ¨ä½œä»¥ç¡®ä¿å®ƒæŒ‰é¢„æœŸå·¥ä½œã€‚</mark>

**Exercise 4â€”Integrate a Third-Party API** | <mark>**ç»ƒä¹  4â€”â€”é›†æˆç¬¬ä¸‰æ–¹ API**</mark>

Objectiveâ€”Enhance the capabilities of a Nexus agent by integrating a real third-party API.

<mark>ç›®æ ‡â€”â€”é€šè¿‡é›†æˆçœŸå®çš„ç¬¬ä¸‰æ–¹ API æ¥å¢å¼º Nexus æ™ºèƒ½ä½“çš„èƒ½åŠ›ã€‚</mark>

Tasks:

<mark>ä»»åŠ¡ï¼š</mark>

- Choose a public API (e.g., weather or news API), and create a new action that fetches data from this API.
- Incorporate error handling and ensure that the agent can gracefully handle API failures or unexpected responses.
- Test the integration thoroughly within Nexus.

<mark>- é€‰æ‹©ä¸€ä¸ªå…¬å…± APIï¼ˆä¾‹å¦‚ï¼Œå¤©æ°”æˆ–æ–°é—» APIï¼‰ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªä»æ­¤ API è·å–æ•°æ®çš„æ–°åŠ¨ä½œã€‚
- åŒ…å«é”™è¯¯å¤„ç†å¹¶ç¡®ä¿æ™ºèƒ½ä½“å¯ä»¥ä¼˜é›…åœ°å¤„ç† API æ•…éšœæˆ–æ„å¤–å“åº”ã€‚
- åœ¨ Nexus ä¸­å½»åº•æµ‹è¯•é›†æˆã€‚</mark>

---

## Summary

<mark>## æœ¬ç« å°ç»“</mark>

- Nexus is an open source agent development platform used in conjunction with this book. It's designed to develop, test, and host AI agents and is built on Streamlit for creating interactive dashboards and chat interfaces.

<mark>- Nexus æ˜¯ä¸€ä¸ªå¼€æºæ™ºèƒ½ä½“å¼€å‘å¹³å°ï¼Œä¸æœ¬ä¹¦é…åˆä½¿ç”¨ã€‚å®ƒæ—¨åœ¨å¼€å‘ã€æµ‹è¯•å’Œæ‰˜ç®¡ AI æ™ºèƒ½ä½“ï¼Œå¹¶åŸºäº Streamlit æ„å»ºï¼Œç”¨äºåˆ›å»ºäº¤äº’å¼ä»ªè¡¨æ¿å’ŒèŠå¤©ç•Œé¢ã€‚</mark>

- Streamlit, a Python web application framework, enables the rapid development of user-friendly dashboards and chat applications. This framework facilitates the exploration and interaction with various agent features in a streamlined manner.

<mark>- Streamlit æ˜¯ä¸€ä¸ª Python Web åº”ç”¨ç¨‹åºæ¡†æ¶ï¼Œå¯å¿«é€Ÿå¼€å‘ç”¨æˆ·å‹å¥½çš„ä»ªè¡¨æ¿å’ŒèŠå¤©åº”ç”¨ç¨‹åºã€‚æ­¤æ¡†æ¶ä»¥ç®€åŒ–çš„æ–¹å¼ä¿ƒè¿›å¯¹å„ç§æ™ºèƒ½ä½“åŠŸèƒ½çš„æ¢ç´¢å’Œäº¤äº’ã€‚</mark>

- Nexus supports creating and customizing agent profiles and personas, allowing users to define their agents' personalities and behaviors. These profiles dictate how agents interact with and respond to user inputs.

<mark>- Nexus æ”¯æŒåˆ›å»ºå’Œè‡ªå®šä¹‰æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶å’Œäººè®¾ï¼Œå…è®¸ç”¨æˆ·å®šä¹‰å…¶æ™ºèƒ½ä½“çš„ä¸ªæ€§å’Œè¡Œä¸ºã€‚è¿™äº›é…ç½®æ–‡ä»¶å†³å®šäº†æ™ºèƒ½ä½“å¦‚ä½•ä¸ç”¨æˆ·è¾“å…¥äº¤äº’å’Œå“åº”ã€‚</mark>

- The Nexus platform allows for developing and integrating semantic (prompt-based) and native (code-based) actions and tools within agents. This enables the creation of highly functional and responsive agents.

<mark>- Nexus å¹³å°å…è®¸åœ¨æ™ºèƒ½ä½“ä¸­å¼€å‘å’Œé›†æˆè¯­ä¹‰ï¼ˆåŸºäºæç¤ºï¼‰å’ŒåŸç”Ÿï¼ˆåŸºäºä»£ç ï¼‰åŠ¨ä½œå’Œå·¥å…·ã€‚è¿™ä½¿å¾—èƒ½å¤Ÿåˆ›å»ºé«˜åº¦åŠŸèƒ½æ€§å’Œå“åº”æ€§çš„æ™ºèƒ½ä½“ã€‚</mark>

- As an open source platform, Nexus is designed to be extensible, encouraging contributions and the addition of new features, tools, and agent capabilities by the community.

<mark>- ä½œä¸ºå¼€æºå¹³å°ï¼ŒNexus æ—¨åœ¨å¯æ‰©å±•ï¼Œé¼“åŠ±ç¤¾åŒºè´¡çŒ®å¹¶æ·»åŠ æ–°åŠŸèƒ½ã€å·¥å…·å’Œæ™ºèƒ½ä½“èƒ½åŠ›ã€‚</mark>

- Nexus is flexible, supporting various deployment options, including a web interface, API, and a Discord bot in future iterations, accommodating a wide range of development and testing needs.

<mark>- Nexus çµæ´»ï¼Œæ”¯æŒå„ç§éƒ¨ç½²é€‰é¡¹ï¼ŒåŒ…æ‹¬ Web ç•Œé¢ã€API å’Œæœªæ¥è¿­ä»£ä¸­çš„ Discord æœºå™¨äººï¼Œä»¥æ»¡è¶³å¹¿æ³›çš„å¼€å‘å’Œæµ‹è¯•éœ€æ±‚ã€‚</mark>

---

**å‚è€ƒèµ„æº | References**

- Nexus GitHub Repository: https://github.com/cxbxmxcx/Nexus
- Streamlit Documentation: https://docs.streamlit.io
- OpenAI API Documentation: https://platform.openai.com/docs
