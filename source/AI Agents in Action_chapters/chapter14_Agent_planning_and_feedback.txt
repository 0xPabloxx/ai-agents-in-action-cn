Chapter 14: Agent planning and feedback
Starting Page: 13
================================================================================

272
11.1
Planning: The essential tool for all agents/assistants
273
11.2
Understanding the sequential planning process
277
11.3
Building a sequential planner
278
11.4
Reviewing a stepwise planner: OpenAI Strawberry
285

CONTENTS
xii
11.5
Applying planning, reasoning, evaluation, and feedback to
assistant and agentic systems
288
Application of assistant/agentic planning
288
■Application of
assistant/agentic reasoning
290
■Application of evaluation to
agentic systems
291
■Application of feedback to agentic/assistant
applications
293
11.6
Exercises
296
appendix A
Accessing OpenAI large language models
299
appendix B
Python development environment
305
index
311

xiii
preface
My journey into the world of intelligent systems began back in the early 1980s. Like
many people then, I believed artificial intelligence (AI) was just around the corner. It
always seemed like one more innovation and technological leap would lead us to the
intelligence we imagined. But that leap never came.
Perhaps the promise of HAL, from Stanley Kubrick’s 2001: A Space Odyssey, capti-
vated me with the idea of a truly intelligent computer companion. After years of effort,
trial, and countless errors, I began to understand that creating AI was far more com-
plex than we humans had imagined. In the early 1990s, I shifted my focus, applying
my skills to more tangible goals in other industries.
Not until the late 1990s, after experiencing a series of challenging and transforma-
tive events, did I realize my passion for building intelligent systems. I knew these sys-
tems might never reach the superintelligence of HAL, but I was okay with that. I
found fulfillment in working with machine learning and data science, creating models
that could learn and adapt. For more than 20 years, I thrived in this space, tackling
problems that required creativity, precision, and a sense of possibility.
During that time, I worked on everything from genetic algorithms for predicting
unknown inputs to developing generative learning models for horizontal drilling in
the oil-and-gas sector. These experiences led me to write, where I shared my knowl-
edge by way of books on various topics—reverse-engineering Pokémon Go, building
augmented and virtual reality experiences, designing audio for games, and applying
reinforcement learning to create intelligent agents. I spent years knuckles-deep in
code, developing agents in Unity ML-Agents and deep reinforcement learning.

PREFACE
xiv
Even then, I never imagined that one day I could simply describe what I wanted to
an AI model, and it would make it happen. I never imagined that, in my lifetime, I
would be able to collaborate with an AI as naturally as I do today. And I certainly never
imagined how fast—and simultaneously how slow—this journey would feel.
In November 2022, the release of ChatGPT changed everything. It changed the
world’s perception of AI, and it changed the way we build intelligent systems. For me,
it also altered my perspective on the capabilities of these systems. Suddenly, the idea
of agents that could autonomously perform complex tasks wasn’t just a far-off dream
but instead a tangible, achievable reality. In some of my earlier books, I had described
agentic systems that could undertake specific tasks, but now, those once-theoretical
ideas were within reach.
This book is the culmination of my decades of experience in building intelligent
systems, but it’s also a realization of the dreams I once had about what AI could
become. AI agents are here, poised to transform how we interact with technology, how
we work, and, ultimately, how we live.
Yet, even now, I see hesitation from organizations when it comes to adopting agen-
tic systems. I believe this hesitation stems not from fear of AI but rather from a lack
of understanding and expertise in building these systems. I hope that this book
helps to bridge that gap. I want to introduce AI agents as tools that can be accessible
to everyone—tools we shouldn’t fear but instead respect, manage responsibly, and
learn to work with in harmony.

xv
acknowledgments
I want to extend my deepest gratitude to the machine learning and deep learning
communities for their tireless dedication and incredible work. Just a few short years
ago, many questioned whether the field was headed for another AI winter—a period
of stagnation and doubt. But thanks to the persistence, brilliance, and passion of
countless individuals, the field not only persevered but also flourished. We’re standing
on the threshold of an AI-driven future, and I am endlessly grateful for the contribu-
tions of this talented community.
Writing a book, even with the help of AI, is no small feat. It takes dedication, col-
laboration, and a tremendous amount of support. I am incredibly thankful to the
team of editors and reviewers who made this book possible. I want to express my
heartfelt thanks to everyone who took the time to review and provide feedback. In
particular, I want to thank Becky Whitney, my content editor, and Ross Turner, my
technical editor and chief production and technology officer at OpenSC, for their
dedication, as well as the whole production team at Manning for their insight and
unwavering support throughout this journey.
To my partner, Rhonda—your love, patience, and encouragement mean the world
to me. You’ve been the cornerstone of my support system, not just for this book but
for all the books that have come before. I truly couldn’t have done any of this without
you. Thank you for being my rock, my partner, and my inspiration.
Many of the early ideas for this book grew out of my work at Symend. It was during
my time there that I first began developing the concepts and designs for agentic sys-
tems that laid the foundation for this book. I am deeply grateful to my colleagues at

ACKNOWLEDGMENTS
xvi
Symend for their collaboration and contributions, including Peh Teh, Andrew Wright,
Ziko Rajabali, Chris Garrett, Kouros, Fatemeh Torabi Asr, Sukh Singh, and Hanif
Joshaghani. Your insights and hard work helped bring these ideas to life, and I am
honored to have worked alongside such an incredible group of people.
Finally, I would like to thank all the reviewers: Anandaganesh Balakrishnan, Aryan
Jadon, Chau Giang, Dan Sheikh, David Curran, Dibyendu Roy Chowdhury, Divya
Bhargavi, Felipe Provezano Coutinho, Gary Pass, John Williams, Jose San Leandro,
Laurence Giglio, Manish Jain, Maxim Volgin, Michael Wang, Mike Metzger, Piti
Champeethong, Prashant Dwivedi, Radhika Kanubaddhi, Rajat Kant Goel, Ramaa
Vissa, Richard Vaughan, Satej Kumar Sahu, Sergio Gtz, Siva Dhandapani, Annamaneni
Sriharsha, Sri Ram Macharla, Sumit Bhattacharyya, Tony Holdroyd, Vidal Graupera,
Vidhya Vinay, and Vinoth Nageshwaran. Your suggestions helped make this a better
book.

xvii
about this book
AI Agents in Action is about building and working with intelligent agent systems—not
just creating autonomous entities but also developing agents that can effectively tackle
and solve real-world problems. The book starts with the basics of working with large
language models (LLMs) to build assistants, multi-agent systems, and agentic behav-
ioral agents. From there, it explores the key components of agentic systems: retrieval
systems for knowledge and memory augmentation, action and tool usage, reasoning,
planning, evaluation, and feedback. The book demonstrates how these components
empower agents to perform a wide range of complex tasks through practical examples.
This journey isn’t just about technology; it’s about reimagining how we approach
problem solving. I hope this book inspires you to see intelligent agents as partners in
innovation, capable of transforming ideas into actions in ways that were once thought
impossible. Together, we’ll explore how AI can augment human potential, enabling us
to achieve far more than we could alone.
Who should read this book
This book is for anyone curious about intelligent agents and how to develop agentic
systems—whether you’re building your first helpful assistant or diving deeper into
complex multi-agent systems. No prior experience with agents, agentic systems,
prompt engineering, or working with LLMs is required. All you need is a basic under-
standing of Python and familiarity with GitHub repositories. My goal is to make these
concepts accessible and engaging, empowering anyone who wants to explore the
world of AI agents to do so with confidence.

ABOUT THIS BOOK
xviii
Whether you’re a developer, researcher, or hobbyist or are simply intrigued by the
possibilities of AI, this book is for you. I hope that in these pages you’ll find inspira-
tion, practical guidance, and a new appreciation for the remarkable potential of intel-
ligent agents. Let this book guide understanding, creating, and unleashing the power
of AI agents in action.
How this book is organized: A road map
This book has 11 chapters. Chapter 1, “Introduction to agents and their world,”
begins by laying a foundation with fundamental definitions of large language models,
chat systems, assistants, and autonomous agents. As the book progresses, the discus-
sion shifts to the key components that make up an agent and how these components
work together to create truly effective systems. Here is a quick summary of chapters 2
through 11:
Chapter 2, “Harnessing the power of large language models”—We start by exploring
how to use commercial LLMs, such as OpenAI. We then examine tools, such as
LM Studio, that provide the infrastructure and support for running various
open source LLMs, enabling anyone to experiment and innovate.
Chapter 3, “Engaging GPT assistants”—This chapter dives into the capabilities of
the GPT Assistants platform from OpenAI. Assistants are foundational agent
types, and we explore how to create practical and diverse assistants, from culi-
nary helpers to intern data scientists and even a book learning assistant.
Chapter 4, “Exploring multi-agent systems”—Agentic tools have advanced signifi-
cantly quickly. Here, we explore two sophisticated multi-agent systems: CrewAI
and AutoGen. We demonstrate AutoGen’s ability to develop code autono-
mously and see how CrewAI can bring together a group of joke researchers to
create humor collaboratively.
Chapter 5, “Empowering agents with actions”—Actions are fundamental to any
agentic system. This chapter discusses how agents can use tools and functions to
execute actions, ranging from database and application programming interface
(API) queries to generating images. We focus on enabling agents to take mean-
ingful actions autonomously.
Chapter 6, “Building autonomous assistants”—We explore the behavior tree—a sta-
ple in robotics and game systems—as a mechanism to orchestrate multiple
coordinated agents. We’ll use behavior trees to tackle challenges such as code
competitions and social media content creation.
Chapter 7, “Assembling and using an agent platform”—This chapter introduces Nexus,
a sophisticated platform for orchestrating multiple agents and LLMs. We discuss
how Nexus facilitates agentic workflows and enables complex interactions between
agents, providing an example of a fully functioning multi-agent environment.
Chapter 8, “Understanding agent memory and knowledge”—Retrieval-augmented
generation (RAG) has become an essential tool for extending the capabilities

ABOUT THIS BOOK
xix
of LLM agents. This chapter explores how retrieval mechanisms can serve as
both a source of knowledge by processing ingested files, and of memory, allow-
ing agents to recall previous interactions or events.
Chapter 9, “Mastering agent prompts with prompt flow”—Prompt engineering is cen-
tral to an agent’s success. This chapter introduces prompt flow, a tool from Mic-
rosoft that helps automate the testing and evaluation of prompts, enabling
more robust and effective agentic behavior.
Chapter 10, “Agent reasoning and evaluation”—Reasoning is crucial to solving
problems intelligently. In this chapter, we explore various reasoning techniques,
such as chain of thought (CoT), and show how agents can evaluate reasoning
strategies even during inference, improving their capacity to solve problems
autonomously.
Chapter 11, “Agent planning and feedback”—Planning is perhaps an agent’s most crit-
ical skill in achieving its goals. We discuss how agents can incorporate planning to
navigate complex tasks and how feedback loops can be used to refine those plans.
The chapter concludes by integrating all the key components—actions, memory
and knowledge, reasoning, evaluation, planning, and feedback—into practical
examples of agentic systems that solve real-world problems.
About the code
The code for this book is spread across several open source projects, many of which
are hosted by me or by other organizations in GitHub repositories. Throughout this
book, I strive to make the content as accessible as possible, taking a low-code approach
to help you focus on core concepts. Many chapters demonstrate how simple prompts
can generate meaningful code, showcasing the power of AI-assisted development.
Additionally, you’ll find a variety of assistant profiles and multi-agent systems that
demonstrate how to solve real-world problems using generated code. These examples
are meant to inspire, guide, and empower you to explore what is possible with AI
agents. I am deeply grateful to the many contributors and the community members
who have collaborated on these projects, and I encourage you to explore the reposito-
ries, experiment with the code, and adapt it to your own needs. This book is a testa-
ment to the power of collaboration and the incredible things we can achieve together.
This book contains many examples of source code both in numbered listings and in
line with normal text. In both cases, source code is formatted in a fixed-width font
like this to separate it from ordinary text. Sometimes, some of the code is typeset in
bold to highlight code that has changed from previous steps in the chapter, such as
when a feature is added to an existing line of code. In many cases, the original source
code has been reformatted; we’ve added line breaks and reworked indentation to
accommodate the available page space in the book. In some cases, even this wasn’t
enough, and listings include line-continuation markers (➥). Additionally, comments in
the source code have often been removed from the listings when the code is described

ABOUT THIS BOOK
xx
in the text. Code annotations accompany many of the listings, highlighting important
concepts.
You can get executable snippets of code from the liveBook (online) version of this
book at https://livebook.manning.com/book/ai-agents-in-action. The complete code
for the examples in the book is available for download from the Manning website at
www.manning.com/books/ai-agents-in-action. In addition, the code developed for this
book has been placed in three GitHub repositories that are all publicly accessible:
GPT-Agents (the original book title), at https://github.com/cxbxmxcx/GPT-
Agents, holds the code for several examples demonstrated in the chapters.
GPT Assistants Playground, at https://github.com/cxbxmxcx/GPTAssistants
Playground, is an entire platform and tool dedicated to building OpenAI GPT
assistants with a helpful web user interface and plenty of tools to develop auton-
omous agent systems.
Nexus, at https://github.com/cxbxmxcx/Nexus, is an example of a web-based
agentic tool that can help you create agentic systems and demonstrate various
code challenges.
liveBook discussion forum
Purchase of AI Agents in Action includes free access to liveBook, Manning’s online
reading platform. Using liveBook’s exclusive discussion features, you can attach com-
ments to the book globally or to specific sections or paragraphs. It’s a snap to make
notes for yourself, ask and answer technical questions, and receive help from the
author and other users. To access the forum, go to https://livebook.manning.com/
book/ai-agents-in-action/discussion. You can also learn more about Manning’s forums
and the rules of conduct at https://livebook.manning.com/discussion.
Manning’s commitment to our readers is to provide a venue where a meaningful
dialogue between individual readers and between readers and the author can take
place. It isn’t a commitment to any specific amount of participation on the part of the
author, whose contribution to the forum remains voluntary (and unpaid). We suggest
you try asking the him challenging questions lest his interest stray! The forum and the
archives of previous discussions will be accessible from the publisher’s website as long
as the book is in print.

xxi
about the author
MICHEAL LANHAM is a distinguished software and technology
innovator with more than two decades of experience in the
industry. He has an extensive background in developing various
software applications across several domains, such as gaming,
graphics, web development, desktop engineering, AI, GIS, oil
and gas geoscience/geomechanics, and machine learning.
Micheal began by pioneering work in integrating neural net-
works and evolutionary algorithms into game development,
which began around the turn of the millennium. He has
authored multiple influential books exploring deep learning, game development,
and augmented reality, including Evolutionary Deep Learning (Manning, 2023) and
Augmented Reality Game Development (Packt Publishing, 2017). He has contributed to
the tech community via publications with many significant tech publishers, including
Manning. Micheal resides in Calgary, Alberta, Canada, with his large family, whom he
enjoys cooking for.

xxii
about the cover illustration
The figure on the cover of AI Agents in Action is “Clémentinien,” taken from Balthasar
Hacquet’s Illustrations de L’Illyrie et la Dalmatie, published in 1815.
In those days, it was easy to identify where people lived and what their trade or sta-
tion in life was just by their dress. Manning celebrates the inventiveness and initiative
of the computer business with book covers based on the rich diversity of regional cul-
ture centuries ago, brought back to life by pictures from collections such as this one.

1
Introduction to agents
and their world
The agent isn’t a new concept in machine learning and artificial intelligence (AI).
In reinforcement learning, for instance, the word agent denotes an active decision-
making and learning intelligence. In other areas, the word agent aligns more with
an automated application or software that does something on your behalf.
1.1
Defining agents
You can consult any online dictionary to find the definition of an agent. The Mer-
riam-Webster Dictionary defines it this way (www.merriam-webster.com/dictionary/
agent):
This chapter covers
Defining the concept of agents
Differentiating the components of an
agent
Analyzing the rise of the agent era:
Why agents?
Peeling back the AI interface
Navigating the agent landscape

2
CHAPTER 1
Introduction to agents and their world
One that acts or exerts power
Something that produces or can produce an effect
A means or instrument by which a guiding intelligence achieves a result
The word agent in our journey to build powerful agents in this book uses this dictio-
nary definition. That also means the term assistant will be synonymous with agent.
Tools like OpenAI’s GPT Assistants will also fall under the AI agent blanket. OpenAI
avoids the word agent because of the history of machine learning, where an agent is
self-deciding and autonomous.
Figure 1.1 shows four cases where a user may interact with a large language model
(LLM) directly or through an agent/assistant proxy, an agent/assistant, or an autono-
mous agent. These four use cases are highlighted in more detail in this list:
Direct user interaction—If you used earlier versions of ChatGPT, you experienced
direct interaction with the LLM. There is no proxy agent or other assistant
interjecting on your behalf.
Agent/assistant proxy—If you’ve used Dall-E 3 through ChatGPT, then you’ve expe-
rienced a proxy agent interaction. In this use case, an LLM interjects your
requests and reformulates them in a format better designed for the task. For
example, for image generation, ChatGPT better formulates the prompt. A proxy
agent is an everyday use case to assist users with unfamiliar tasks or models.
Agent/assistant—If you’ve ever used a ChatGPT plugin or GPT assistant, then
you’ve experienced this use case. In this case, the LLM is aware of the plugin
or assistant functions and prepares to make calls to this plugin/function.
However, before making a call, the LLM requires user approval. If approved,
the plugin or function is executed, and the results are returned to the LLM.
The LLM then wraps this response in natural language and returns it to
the user.
Autonomous agent—In this use case, the agent interprets the user’s request, con-
structs a plan, and identifies decision points. From this, it executes the steps in
the plan and makes the required decisions independently. The agent may
request user feedback after certain milestone tasks, but it’s often given free rein
to explore and learn if possible. This agent poses the most ethical and safety
concerns, which we’ll explore later.
Figure 1.1 demonstrates the use cases for a single flow of actions on an LLM using a
single agent. For more complex problems, we often break agents into profiles or per-
sonas. Each agent profile is given a specific task and executes that task with specialized
tools and knowledge.
Multi-agent systems are agent profiles that work together in various configurations to
solve a problem. Figure 1.2 demonstrates an example of a multi-agent system using
three agents: a controller or proxy and two profile agents as workers controlled by the
proxy. The coder profile on the left writes the code the user requests; on the right is a

3
1.1
Defining agents
tester profile designed to write unit tests. These agents work and communicate
together until they are happy with the code and then pass it on to the user.
Figure 1.2 shows one of the possibly infinite agent configurations. (In chapter 4,
we’ll explore Microsoft’s open source platform, AutoGen, which supports multiple
configurations for employing multi-agent systems.)
Multi-agent systems can work autonomously but may also function guided entirely
by human feedback. The benefits of using multiple agents are like those of a single
Please explain the
deﬁnition of agent.
Large language model
(ChatGPT)
LLM: The deﬁnition
of agent is...
Show an illustration
of an agent.
Large language model
(ChatGPT)
"An image of a female
secret agent of Hispanic
descent in a nighttime
urban setting. . .
Image generation model
(DALL-E 3)
No agent or assistant
direct connection to LLM
Agent/assistant proxy for
image generator
What is the temperature
in Calgary today?
Large language model
(ChatGPT)
LLM identiﬁes an external
function API to call and
parameters to connect
to a weather service.
Agent/assistant acting on
behalf of user
User conﬁrms
execution okay.
Asks user if it’s okay
to execute the function
on their behalf.
Executes the function
and returns weather
information.
Filter my emails by
importance and notify
me of the top 5 most
important emails.
Large language model
(ChatGPT)
LLM identiﬁes an external
function API to call and
parameters to connect
to an email service.
Notiﬁes the user of
important emails.
Autonomous agent making
decisions on behalf of user
LLM reads
and sorts emails by
what it deems to be
important.
Decision step
LLM reformulates
weather information and
responds to the user.
.
Figure 1.1
The differences between the LLM interactions from direct action compared to using proxy agents,
agents, and autonomous agents

4
CHAPTER 1
Introduction to agents and their world
agent but often magnified. Where a single agent typically specializes in a single task,
multi-agent systems can tackle multiple tasks in parallel. Multiple agents can also pro-
vide feedback and evaluation, reducing errors when completing assignments.
As we can see, an AI agent or agent system can be assembled in multiple ways.
However, an agent itself can also be assembled using multiple components. In the
next section, we’ll cover topics ranging from an agent’s profile to the actions it may
perform, as well as memory and planning.
1.2
Understanding the component systems of an agent
Agents can be complex units composed of multiple component systems. These com-
ponents are the tools the agent employs to help it complete its goal or assigned tasks
and even create new ones. Components may be simple or complex systems, typically
split into five categories.
Figure 1.3 describes the major categories of components a single-agent system may
incorporate. Each element will have subtypes that can define the component’s type,
User query
Answer
Controller
Coder
Tester
Feature request
Code
Code
Unit tests
Large Language Model
Large Language Model
The controller agent
can execute code on
the user’s behalf.
Repeat until the
code and tests
work as expected.
Worker agents
interact with
the LLM.
Figure 1.2
In this example of a multi-agent system, the controller or agent proxy communicates directly with
the user. Two agents—a coder and a tester—work in the background to create code and write unit tests to test
the code.

5
1.2
Understanding the component systems of an agent
structure, and use. At the core of all agents is the profile and persona; extending from
that are the systems and functions that enhance the agent.
The agent profile and persona shown in figure 1.4 represent the base description of
the agent. The persona—often called the system prompt—guides an agent to complete
tasks, learn how to respond, and other nuances. It includes elements such as the back-
ground (e.g., coder, writer) and demographics, and it can be generated through
methods such as handcrafting, LLM assistance, or data-driven techniques, including
evolutionary algorithms.
We’ll explore how to create effective and specific agent profiles/personas through
techniques such as rubrics and grounding. In addition, we’ll explain the aspects of
human-formulated versus AI-formulated (LLM) profiles, including innovative tech-
niques using data and evolutionary algorithms to build profiles.
A persona represents the agent’s
main role or function, typically
deﬁned in a system prompt. The
proﬁle describes the entire agent
system.
Proﬁle and Persona
Actions and Tool Use
Reasoning and Evaluation
Memory and Knowledge
Planning and Feedback
Actions represent a function/
tool an agent can use.
Reasoning and evaluation
ground the agent and empower
it to make better decisions.
Planning and feedback
allow the agent to learn and
improve on task completion.
Memory and knowledge provide
added context to the agent for a
speciﬁc request or task.
Figure 1.3
The five main components of a single-agent system (image generated through DALL-E 3)

6
CHAPTER 1
Introduction to agents and their world
NOTE
The agent or assistant profile is composed of elements, including the
persona. It may be helpful to think of profiles describing the work the agent/
assistant will perform and the tools it needs.
Figure 1.5 demonstrates the component actions and tool use in the context of agents
involving activities directed toward task completion or acquiring information. These
actions can be categorized into task completion, exploration, and communication,
with varying levels of effect on the agent’s environment and internal states. Actions
can be generated manually, through memory recollection, or by following predefined
plans, influencing the agent’s behavior and enhancing learning.
Understanding the action target helps us define clear objectives for task comple-
tion, exploration, or communication. Recognizing the action effect reveals how actions
influence task outcomes, the agent’s environment, and its internal states, contributing
to efficient decision making. Lastly, grasping action generation methods equips us
with the knowledge to create actions manually, recall them from memory, or follow
predefined plans, enhancing our ability to effectively shape agent behavior and learn-
ing processes.
Figure 1.6 shows the component knowledge and memory in more detail. Agents
use knowledge and memory to annotate context with the most pertinent information
while limiting the number of tokens used. Knowledge and memory structures can be
unified, where both subsets follow a single structure or hybrid structure involving a
mix of different retrieval forms. Knowledge and memory formats can vary widely from
Agent persona: We’ll understand how
to clearly deﬁne the persona, specifying
their role and characteristics to guide
the agent effectively.
Agent role and demographics: We’ll
see how relevant demographic and role
details can provide agent context, such
as age, gender, or background, for a
more relevant interaction.
Human vs. AI assistance for persona
generation: We’ll highlight the role
of human involvement in persona
generation, whether it’s entirely
human driven or assisted by LLMs
or other agents.
Innovative persona techniques:
Prompts generated through data
or other novel approaches such as
evolutionary algorithms to enhance
agent capabilities.
Proﬁle and Persona
Proﬁle Contents
Proﬁle Generation
Persona: Role, i.e., coder or tester
Demographics: Sex, age, background
Handcrafted: Manually designed by
humans
LLM generated: Directed by human
prompts
Data generated: Constructed from
data personas
Figure 1.4
An in-depth look at how we’ll explore creating agent profiles

7
1.2
Understanding the component systems of an agent
language (e.g., PDF documents) to databases (relational, object, or document) and
embeddings, simplifying semantic similarity search through vector representations or
even simple lists serving as agent memories.
Figure 1.7 shows the reasoning and evaluation component of an agent system. Research
and practical applications have shown that LLMs/agents can effectively reason. Rea-
soning and evaluation systems annotate an agent’s workflow by providing an ability to
think through problems and evaluate solutions.
Action targets: We’ll learn the importance
of deﬁning action targets, whether for task
completion, exploration, or communication,
to clarify the agent’s objectives.
Action space and impact: We’ll learn the
signiﬁcance of understanding how actions
affect task completion and their effect on
the agent’s environment, internal states,
and self-knowledge.
Action generation methods: We’ll see the
various ways actions can be generated, such
as manual creation, memory recollection,
or plan following, to illustrate the diversity
of agent behaviors.
Action and Tool Use
Action Target
Semantic or native functions
Tools, self-knowledge, other agents
Environments, new actions, internal
states, other agents
Manual, memory recollection, plan
following
Figure 1.5
The aspects of agent actions we’ll explore in this book
Memory and Knowledge
Retrieval Structure
• Uniﬁed
• Hybrid
Retrieval Formats
• Language
• Databases
• Embeddings
• Lists
Retrieval Operation
• Augmentation
• Semantic Extraction
• Compression
Retrieval structure variety: We’ll learn
about the diverse memory structures
agents can employ, including uniﬁed and
hybrid approaches, enabling ﬂexibility in
information storage.
Retrieval formats: We’ll explore the
various data sources for memory, such
as language (e.g., PDF documents),
databases (relational, object, or
document), and embeddings, offering a
rich pool of information to draw upon.
Semantic similarity: We’ll learn how
embeddings enable semantic similarity
searches, facilitating efﬁcient retrieval of
relevant data and enhancing the agent’s
decision-making capabilities.
Figure 1.6
Exploring the role and use of agent memory and knowledge

8
CHAPTER 1
Introduction to agents and their world
Figure 1.8 shows the component agent planning/feedback and its role in organizing
tasks to achieve higher-level goals. It can be categorized into these two approaches:
Planning without feedback—Autonomous agents make decisions independently.
Planning with feedback—Monitoring and modifying plans is based on various
sources of input, including environmental changes and direct human feedback.
Within planning, agents may employ single-path reasoning, sequential reasoning through
each step of a task, or multipath reasoning to explore multiple strategies and save the
Reasoning and Evaluation
Reasoning
• Zero-shot prompting
• One-shot prompting
• Few-shot prompting
• Chain of thought
• Tree of thought
• Skeleton of thought
Evaluation
• Self-consistency
• Prompt chaining
Reasoning enables the agent
to self-reﬂect and internally
reason out the completion
of a task or tasks.
Evaluation provides the basis
for an agent’s self-reﬂection
on working through and upon
task completion.
Figure 1.7
The reasoning and evaluation component and details
We’ll look at various planning
strategies with and without
feedback—from basic and
sequential planners to automatic
tool use with reasoning.
Feedback may come from a variety
of sources, such as environmental,
human, and an LLM via various
constructive feedback patterns.
Planning and Feedback
Planning without feedback
(autonomous)
• Basic planning
• Automatic reasoning with
tool use
• Sequential planning
Planning with feedback
• Environmental feedback
• Human feedback
• LLM feedback
• Adaptive constructive
feedback
Figure 1.8
Exploring the role of agent planning and reasoning

9
1.3
Examining the rise of the agent era: Why agents?
efficient ones for future use. External planners, which can be code or other agent sys-
tems, may also play a role in orchestrating plans.
Any of our previous agent types—the proxy agent/assistant, agent/assistant, or
autonomous agent—may use some or all of these components. Even the planning
component has a role outside of the autonomous agent and can effectively empower
even the regular agent.
1.3
Examining the rise of the agent era: Why agents?
AI agents and assistants have quickly moved from the main commodity in AI research
to mainstream software development. An ever-growing list of tools and platforms assist
in the construction and empowerment of agents. To an outsider, it may all seem like
hype intended to inflate the value of some cool but overrated technology.
During the first few months after ChatGPT’s initial release, a new discipline called
prompt engineering was formed: users found that using various techniques and patterns
in their prompts allowed them to generate better and more consistent output. How-
ever, users also realized that prompt engineering could only go so far.
Prompt engineering is still an excellent way to interact directly with LLMs such as
ChatGPT. Over time, many users discovered that effective prompting required iteration,
reflection, and more iteration. The first agent systems, such as AutoGPT, emerged from
these discoveries, capturing the community’s attention.
Figure 1.9 shows the original design of AutoGPT, one of the first autonomous
agent systems. The agent is designed to iterate a planned sequence of tasks that it
defines by looking at the user’s goal. Through each task iteration of steps, the agent
evaluates the goal and determines if the task is complete. If the task isn’t complete, the
agent may replan the steps and update the plan based on new knowledge or human
feedback.
AutoGPT became the first example to demonstrate the power of using task plan-
ning and iteration with LLM models. From this and in tandem, other agent systems
and frameworks exploded into the community using similar planning and task itera-
tion systems. It’s generally accepted that planning, iteration, and repetition are the
best processes for solving complex and multifaceted goals for an LLM.
However, autonomous agent systems require trust in the agent decision-making
process, the guardrails/evaluation system, and the goal definition. Trust is also some-
thing that is acquired over time. Our lack of trust stems from our lack of understand-
ing of an autonomous agent’s capabilities.
NOTE
Artificial general intelligence (AGI) is a form of intelligence that
can learn to accomplish any task a human can. Many practitioners in this
new world of AI believe an AGI using autonomous agent systems is an
attainable goal.
For this reason, many of the mainstream and production-ready agent tools aren’t auton-
omous. However, they still provide a significant benefit in managing and automating

10
CHAPTER 1
Introduction to agents and their world
tasks using GPTs (LLMs). Therefore, as our goal in this book is to understand all agent
forms, many more practical applications will be driven by non-autonomous agents.
Agents and agent tools are only the top layer of a new software application devel-
opment paradigm. We’ll look at this new paradigm in the next section.
The agent evaluates if
the goal is complete
after every task
iteration.
AI Large Language
Models (GPT-4)
Internet
Other Tools
Evaluation
Deﬁning and
Sequencing Tasks
Setting Goals
Task Execution
Goals not complete
The agent can be
set to ask for
permission for
every task or for
every x number
of tasks.
Goals complete
User sets the main
objective goal
Agent executes
tasks.
The agent could write code to
perform other tasks as needed.
The agent
plans out the
sequence of
tasks to
undertake.
Autonomous AI Mechanism
Figure 1.9
The original design of the AutoGPT agent system

11
1.4
Peeling back the AI interface
1.4
Peeling back the AI interface
The AI agent paradigm is not only a shift in how we work with LLMs but is also per-
ceived as a shift in how we develop software and handle data. Software and data will
no longer be interfaced using user interfaces (UIs), application programming inter-
faces (APIs), and specialized query languages such as SQL. Instead, they will be
designed to be interfaced using natural language.
Figure 1.10 shows a high-level snapshot of what this new architecture may look like
and what role AI agents play. Data, software, and applications adapt to support seman-
tic, natural language interfaces. These AI interfaces allow agents to collect data and
interact with software applications, even other agents or agent applications. This rep-
resents a new shift in how we interact with software and applications.
An AI interface is a collection of functions, tools, and data layers that expose data and
applications by natural language. In the past, the word semantic has been heavily
Agent interface layer (natural language)
Planning: Agent takes the goal and breaks into tasks.
1. Collect data.
2. Annotate data.
3. Format data, and create report visualizations.
4. Present report.
4. Agent presents the report.
Please create a report of
last year’s sales.
GPT data layer
Database
1. Query database using natural
language.
GPT functions
APIs,
web browsing,
search, etc.
All communication via natural language
2. Annotate data by calling semantic
functions using natural language.
External agents
GPT tools
3. External agent formats data and
may write code to generate visuals.
Figure 1.10
A vision of how agents will interact with software systems

12
CHAPTER 1
Introduction to agents and their world
used to describe these interfaces, and even some tools use the name; however,
“semantic” can also have a variety of meanings and uses. Therefore, in this book,
we’ll use the term AI interface.
The construction of AI interfaces will empower agents that need to consume
the services, tools, and data. With this empowerment will come increased accuracy
in completing tasks and more trustworthy and autonomous applications. While an
AI interface may not be appropriate for all software and data, it will dominate many
use cases.
1.5
Navigating the agent landscape
GPT agents represent an entire shift in how consumers and developers approach
everything, from finding information to building software and accessing data. Almost
daily, a new agent framework, component, or interface pops up on GitHub or in a
research paper. This can be overwhelming and intimidating to the new user trying to
grasp what agent systems are and how to use them.
Summary
An agent is an entity that acts or exerts power, produces an effect, or serves as a
means for achieving a result. An agent automates interaction with a large lan-
guage model (LLM) in AI.
An assistant is synonymous with an agent. Both terms encompass tools such as
OpenAI’s GPT Assistants.
Autonomous agents can make independent decisions, and their distinction
from non-autonomous agents is crucial.
The four main types of LLM interactions include direct user interaction, agent/
assistant proxy, agent/assistant, and autonomous agent.
Multi-agent systems involve agent profiles working together, often controlled by
a proxy, to accomplish complex tasks.
The main components of an agent include the profile/persona, actions, knowl-
edge/memory, reasoning/evaluation, and planning/feedback.
Agent profiles and personas guide an agent’s tasks, responses, and other nuances,
often including background and demographics.
Actions and tools for agents can be manually generated, recalled from memory,
or follow predefined plans.
Agents use knowledge and memory structures to optimize context and mini-
mize token usage via various formats, from documents to embeddings.
Reasoning and evaluation systems enable agents to think through problems
and assess solutions using prompting patterns such as zero-shot, one-shot, and
few-shot.
Planning/feedback components organize tasks to achieve goals using single-path
or multipath reasoning and integrating environmental and human feedback.

13
Summary
The rise of AI agents has introduced a new software development paradigm,
shifting from traditional to natural language–based AI interfaces.
Understanding the progression and interaction of these tools helps develop
agent systems, whether single, multiple, or autonomous.

14
Harnessing the power
of large language models
The term large language models (LLMs) has now become a ubiquitous descriptor of a
form of AI. These LLMs have been developed using generative pretrained trans-
formers (GPTs). While other architectures also power LLMs, the GPT form is cur-
rently the most successful.
LLMs and GPTs are generative models, which means they are trained to generate
rather than predict or classify content. To illustrate this further, consider figure 2.1,
which shows the difference between generative and predictive/classification mod-
els. Generative models create something from the input, whereas predictive and
classifying models classify it.
This chapter covers
Understanding the basics of LLMs
Connecting to and consuming the OpenAI API
Exploring and using open source LLMs with
LM Studio
Prompting LLMs with prompt engineering
Choosing the optimal LLM for your specific
needs

15
We can further define an LLM by its constituent parts, as shown in figure 2.2. In
this diagram, data represents the content used to train the model, and architecture is
an attribute of the model itself, such as the number of parameters or size of the
model. Models are further trained specifically to the desired use case, including
chat, completions, or instruction. Finally, fine-tuning is a feature added to models
that refines the input data and model training to better match a particular use case
or domain.
Input text
Outputs the most
probable next word
given the input
thus far
Outputs the most
probable class
the phrase is
aligned with
Outputs text
Outputs prediction
Figure 2.1
The difference between generative and predictive models
Data
LLM
Training
Architecture
Fine-tuning
The input data represents the
content the model will train on.
This typically consists of terabytes
to petabytes of data.
Denotes the model architecture.
The architecture deﬁnes things
such as context, token limits,
embedding size, and number of
parameters (model size).
Deﬁnes the form of training used to
train the model. Training will also
deﬁne the model use case, such as
chat completions, completions,
instruct, or question/answer.
Fine-tuning is the process of
making a model more speciﬁc
to a particular domain or dataset.
Figure 2.2
The main elements that describe an LLM
CHAPTER 2
Harnessing the power of large language models

16
CHAPTER 2
Harnessing the power of large language models
The transformer architecture of GPTs, which is a specific architecture of LLMs, allows
the models to be scaled to billions of parameters in size. This requires these large
models to be trained on terabytes of documents to build a foundation. From there,
these models will be successively trained using various methods for the desired use
case of the model.
ChatGPT, for example, is trained effectively on the public internet and then fine-
tuned using several training strategies. The final fine-tuning training is completed
using an advanced form called reinforcement learning with human feedback (RLHF). This
produces a model use case called chat completions.
Chat completions LLMs are designed to improve through iteration and refine-
ment—in other words, chatting. These models have also been benchmarked to be the
best in task completion, reasoning, and planning, which makes them ideal for build-
ing agents and assistants. Completion models are trained/designed only to provide
generated content on input text, so they don’t benefit from iteration.
For our journey to build powerful agents in this book, we focus on the class of
LLMs called chat completions models. That, of course, doesn’t preclude you from try-
ing other model forms for your agents. However, you may have to significantly alter
the code samples provided to support other model forms.
We’ll uncover more details about LLMs and GPTs later in this chapter when we
look at running an open source LLM locally. In the next section, we look at how to
connect to an LLM using a growing standard from OpenAI.
2.1
Mastering the OpenAI API
Numerous AI agents and assistant projects use the OpenAI API SDK to connect to an
LLM. While not standard, the basic concepts describing a connection now follow the
OpenAI pattern. Therefore, we must understand the core concepts of an LLM con-
nection using the OpenAI SDK.
This chapter will look at connecting to an LLM model using the OpenAI Python
SDK/package. We’ll discuss connecting to a GPT-4 model, the model response, count-
ing tokens, and how to define consistent messages. Starting in the following subsec-
tion, we’ll examine how to use OpenAI.
2.1.1
Connecting to the chat completions model
To complete the exercises in this section and subsequent ones, you must set up a
Python developer environment and get access to an LLM. Appendix A walks you
through setting up an OpenAI account and accessing GPT-4 or other models. Appen-
dix B demonstrates setting up a Python development environment with Visual Studio
Code (VS Code), including installing needed extensions. Review these sections if you
want to follow along with the scenarios.
Start by opening the source code chapter_2 folder in VS Code and creating a new
Python virtual environment. Again, refer to appendix B if you need assistance.

17
2.1
Mastering the OpenAI API
Then, install the OpenAI and Python dot environment packages using the com-
mand in the following listing. This will install the required packages into the virtual
environment.
pip install openai python-dotenv
Next, open the connecting.py file in VS Code, and inspect the code shown in listing 2.2.
Be sure to set the model’s name to an appropriate name—for example, gpt-4. At the
time of writing, the gpt-4-1106-preview was used to represent GPT-4 Turbo.
import os
from openai import OpenAI
from dotenv import load_dotenv
load_dotenv()
api_key = os.getenv('OPENAI_API_KEY')
if not api_key:
raise ValueError("No API key found. Please check your .env file.")
client = OpenAI(api_key=api_key)
def ask_chatgpt(user_message):
response = client.chat.completions.create(
model="gpt-4-1106-preview",
messages=[{"role": "system",
"content": "You are a helpful assistant."},
{"role": "user", "content": user_message}],
temperature=0.7,
)
return response.choices[0].message.content
user = "What is the capital of France?"
response = ask_chatgpt(user)
print(response)
A lot is happening here, so let’s break it down by section, starting with the beginning
and loading the environment variables. In the chapter_2 folder is another file called
.env, which holds environment variables. These variables are set automatically by call-
ing the load_dotenv function.
You must set your OpenAI API key in the .env file, as shown in the next listing.
Again, refer to appendix A to find out how to get a key and find a model name.
OPENAI_API_KEY='your-openai-api-key'
After setting the key, you can debug the file by pressing the F5 key or selecting Run >
Start Debugging from the VS Code menu. This will run the code, and you should see
something like “The capital of France is Paris.”
Listing 2.1
pip installs
Listing 2.2
connecting.py
Listing 2.3
.env
Loads the secrets
stored in the .env file
Checks to see
whether the key is set
Creates a client
with the key
Uses the create
function to generate
a response
Returns just the content
of the response
Executes the request and
returns the response

18
CHAPTER 2
Harnessing the power of large language models
Remember that the response from a generative model depends on the probability.
The model will probably give us a correct and consistent answer in this case.
You can play with these probabilities by adjusting the temperature of the request.
If you want a model to be more consistent, turn the temperature down to 0, but if you
want the model to produce more variation, turn the temperature up. We’ll explore
setting the temperature further in the next section.
2.1.2
Understanding the request and response
Digging into the chat completions request and response features can be helpful. We’ll
focus on the request first, as shown next. The request encapsulates the intended
model, the messages, and the temperature.
response = client.chat.completions.create(
model="gpt-4-1106-preview",
messages=[{"role": "system",
"content": "You are a helpful assistant."},
{"role": "user", "content": user_message}],
temperature=0.7,
)
Within the request, the messages block describes a set of messages and roles used in a
request. Messages for a chat completions model can be defined in three roles:
System role—A message that describes the request’s rules and guidelines. It can
often be used to describe the role of the LLM in making the request.
User role—Represents and contains the message from the user.
Assistant role—Can be used to capture the message history of previous responses
from the LLM. It can also inject a message history when perhaps none existed.
The message sent in a single request can encapsulate an entire conversation, as shown
in the JSON in the following listing.
[
{
"role": "system",
"content": "You are a helpful assistant."
},
{
"role": "user",
"content": "What is the capital of France?"
},
{
"role": "assistant",
Listing 2.4
The chat completions request
Listing 2.5
Messages with history
The model or deployment used
to respond to the request
The system
role message
The user role
message
The temperature or
variability of the request

19
2.1
Mastering the OpenAI API
"content": "The capital of France is Paris."
},
{
"role": "user",
"content": "What is an interesting fact of Paris."
}
],
You can see how this can be applied by opening message_history.py in VS Code and
debugging it by pressing F5. After the file runs, be sure to check the output. Then, try
to run the sample a few more times to see how the results change.
The results will change from each run to the next due to the high temperature of
.7. Go ahead and reduce the temperature to .0, and run the message_history.py
sample a few more times. Keeping the temperature at 0 will show the same or similar
results each time.
Setting a request’s temperature will often depend on your particular use case.
Sometimes, you may want to limit the responses’ stochastic nature (randomness).
Reducing the temperature to 0 will give consistent results. Likewise, a value of 1.0 will
give the most variability in the responses.
Next, we also want to know what information is being returned for each request.
The next listing shows the output format for the response. You can see this output by
running the message_history.py file in VS Code.
{
"id": "chatcmpl-8WWL23up3IRfK1nrDFQ3EHQfhx0U6",
"choices": [
{
"finish_reason": "stop",
"index": 0,
"message": {
"content": "… omitted",
"role": "assistant",
"function_call": null,
"tool_calls": null
},
"logprobs": null
}
],
"created": 1702761496,
"model": "gpt-4-1106-preview",
"object": "chat.completion",
"system_fingerprint": "fp_3905aa4f79",
"usage": {
"completion_tokens": 78,
"prompt_tokens": 48,
"total_tokens": 126
}
}
Listing 2.6
Chat completions response
A model may
return more than
one response.
Responses
returned in the
assistant role
Indicates the
model used
Counts the number of
input (prompt) and output
(completion) tokens used

20
CHAPTER 2
Harnessing the power of large language models
It can be helpful to track the number of input tokens (those used in prompts) and the
output tokens (the number returned through completions). Sometimes, minimizing
and reducing the number of tokens can be essential. Having fewer tokens typically
means LLM interactions will be cheaper, respond faster, and produce better and more
consistent results.
That covers the basics of connecting to an LLM and returning responses. Through-
out this book, we’ll review and expand on how to interact with LLMs. Until then, we’ll
explore in the next section how to load and use open source LLMs.
2.2
Exploring open source LLMs with LM Studio
Commercial LLMs, such as GPT-4 from OpenAI, are an excellent place to start to
learn how to use modern AI and build agents. However, commercial agents are an
external resource that comes at a cost, reduces data privacy and security, and
introduces dependencies. Other external influences can further complicate these
factors.
It’s unsurprising that the race to build comparable open source LLMs is growing
more competitive every day. As a result, there are now open source LLMs that may be
adequate for numerous tasks and agent systems. There have even been so many
advances in tooling in just a year that hosting LLMs locally is now very easy, as we’ll see
in the next section.
2.2.1
Installing and running LM Studio
LM Studio is a free download that supports downloading and hosting LLMs and other
models locally for Windows, Mac, and Linux. The software is easy to use and offers sev-
eral helpful features to get you started quickly. Here is a quick summary of steps to
download and set up LM Studio:
1
Download LM Studio from https://lmstudio.ai/.
2
After downloading, install the software per your operating system. Be aware that
some versions of LM Studio may be in beta and require installation of addi-
tional tools or libraries.
3
Launch the software.
Figure 2.3 shows the LM Studio window running. From there, you can review the cur-
rent list of hot models, search for others, and even download. The home page content
can be handy for understanding the details and specifications of the top models.
An appealing feature of LM Studio is its ability to analyze your hardware and align
it with the requirements of a given model. The software will let you know how well you
can run a given model. This can be a great time saver in guiding what models you
experiment with.


21
2.2
Exploring open source LLMs with LM Studio
Enter some text to search for a model, and click Go. You’ll be taken to the search
page interface, as shown in figure 2.4. From this page, you can see all the model
variations and other specifications, such as context token size. After you click the
Compatibility Guess button, the software will even tell you if the model will run on
your system.
Click to download any model that will run on your system. You may want to stick
with models designed for chat completions, but if your system is limited, work with
what you have. In addition, if you’re unsure of which model to use, go ahead and
download to try them. LM Studio is a great way to explore and experiment with many
models.




Chat interface to talk
directly to a local LLM
Run a local model
as a service.
Search area
Browse already
downloaded models.
Figure 2.3
LM Studio software showing the main home page

22
CHAPTER 2
Harnessing the power of large language models
After the model is downloaded, you can then load and run the model on the chat
page or as a server on the server page. Figure 2.5 shows loading and running a
model on the chat page. It also shows the option for enabling and using a GPU if
you have one.
To load and run a model, open the drop-down menu at the top middle of the
page, and select a downloaded model. A progress bar will appear showing the model
loading, and when it’s ready, you can start typing into the UI.
The software even allows you to use some or all of your GPU, if detected, for the
model inference. A GPU will generally speed up the model response times in some
capacities. You can see how adding a GPU can affect the model’s performance by
looking at the performance status at the bottom of the page, as shown in figure 2.5.
Chatting with a model and using or playing with various prompts can help you
determine how well a model will work for your given use case. A more systematic
approach is using the prompt flow tool for evaluating prompts and LLMs. We’ll
describe how to use prompt flow in chapter 9.
LM Studio also allows a model to be run on a server and made accessible using the
OpenAI package. We’ll see how to use the server feature and serve a model in the
next section.
Search text
Look at the model
card on Hugging Face.
The compatibility guesser
informs you if a model will run.
Shows the
downloaded models
Figure 2.4
The LM Studio search page

23
2.2
Exploring open source LLMs with LM Studio
2.2.2
Serving an LLM locally with LM Studio
Running an LLM locally as a server is easy with LM Studio. Just open the server page,
load a model, and then click the Start Server button, as shown in figure 2.6. From
there, you can copy and paste any of the examples to connect with your model.
You can review an example of the Python code by opening chapter_2/lmstudio_
server.py in VS Code. The code is also shown here in listing 2.7. Then, run the code
in the VS Code debugger (press F5).


Loaded model
Conversation
history
Text area for
user messages
Model system
prompt
Enabling GPU acceleration,
available when GPU detected
Model performance
and usage
Figure 2.5
The LM Studio chat page with a loaded, locally running LLM

24
CHAPTER 2
Harnessing the power of large language models
from openai import OpenAI
client = OpenAI(base_url="http://localhost:1234/v1", api_key="not-needed")
completion = client.chat.completions.create(
model="local-model",
messages=[
{"role": "system", "content": "Always answer in rhymes."},
{"role": "user", "content": "Introduce yourself."}
],
temperature=0.7,
)
print(completion.choices[0].message)
Listing 2.7
lmstudio_server.py
Loaded model
Enabling GPU acceleration,
available when GPU detected
Example to connect
to the server
Start/stop the server
Logs showing startup and
connection information
Figure 2.6
The LM Studio server page and a server running an LLM
Currently not used;
can be anything
Feel free to change
the message as
you like.
Default code outputs
the whole message.

25
2.3
Prompting LLMs with prompt engineering
If you encounter problems connecting to the server or experience any other prob-
lems, be sure your configuration for the Server Model Settings matches the model
type. For example, in figure 2.6, shown earlier, the loaded model differs from the
server settings. The corrected settings are shown in figure 2.7.
Now, you can use a locally hosted LLM or a commercial model to build, test, and
potentially even run your agents. The following section will examine how to build
prompts using prompt engineering more effectively.
2.3
Prompting LLMs with prompt engineering
A prompt defined for LLMs is the message content used in the request for better
response output. Prompt engineering is a new and emerging field that attempts to struc-
ture a methodology for building prompts. Unfortunately, prompt building isn’t a well-
established science, and there is a growing and diverse set of methods defined as
prompt engineering.
Fortunately, organizations such as OpenAI have begun documenting a universal
set of strategies, as shown in figure 2.8. These strategies cover various tactics, some
requiring additional infrastructure and considerations. As such, the prompt engineer-
ing strategies relating to more advanced concepts will be covered in the indicated
chapters.
Each strategy in figure 2.8 unfolds into tactics that can further refine the specific
method of prompt engineering. This chapter will examine the fundamental Write
Loaded model
Server
odel ettings
M
S
match the loaded model.
When running correctly,
you’ll see the message logs.
Figure 2.7
Choosing the correct Server Model Settings for the loaded model

26
CHAPTER 2
Harnessing the power of large language models
Clear Instructions strategy. Figure 2.9 shows the tactics for this strategy in more detail,
along with examples for each tactic. We’ll look at running these examples using a
code demo in the following sections.
The Write Clear Instructions strategy is about being careful and specific about
what you ask for. Asking an LLM to perform a task is no different from asking a per-
son to complete the same task. Generally, the more information and context relevant
to a task you can specify in a request, the better the response.
This strategy has been broken down into specific tactics you can apply to prompts.
To understand how to use those, a code demo (prompt_engineering.py) with various
prompt examples is in the chapter 2 source code folder.
Open the prompt_engineering.py file in VS Code, as shown in listing 2.8. This
code starts by loading all the JSON Lines files in the prompts folder. Then, it displays
the list of files as choices and allows the user to select a prompt option. After selecting
the option, the prompts are submitted to an LLM, and the response is printed.



Write Clear Instructions
Be speciﬁc in what you ask.
Tactics include detailing queries, adopting personas, using delimiters,
specifying steps, providing examples, and specifying output length.
Basics
Provide Reference Text
Helps reduce fabrications.
Tactics involve instructing the model to use or cite reference texts.
Memory
Use External Tools
Enhances model capabilities.
Tactics include embeddings-based search, code execution, and
access to speciﬁc functions.
Memory
Split Complex Tasks into Simpler Subtasks
Reduces error rates.
Tactics include intent classiﬁcation, summarizing dialogues, and
piecewise summarization of documents.
Planning
Give Models Time to “Think”
Allows more reliable reasoning.
Tactics involve working out solutions before conclusions, using inner
monologue, and reviewing previous answers.
Planning
Test Changes Systematically
Ensures improvements are genuine.
Tactics involve evaluating model outputs with reference to standard
answers.
Evaluation
Prompt Engineering Strategies
Figure 2.8
OpenAI prompt engineering strategies reviewed in this book, by chapter location

27
2.3
Prompting LLMs with prompt engineering
def main():
directory = "prompts"
text_files = list_text_files_in_directory(directory)
if not text_files:
print("No text files found in the directory.")
return
def print_available():
print("Available prompt tactics:")
for i, filename in enumerate(text_files, start=1):
print(f"{i}. {filename}")
while True:
try:
print_available()
choice = int(input("Enter … 0 to exit): "))
Listing 2.8
prompt_engineering.py (main())
Detailed
Queries
Adopting
Personas
Using
Delimiters
Specifying
Steps
Providing
Examples
Specify Output
Length
Tactics for Strategy: Writing Clear Instructions
Without detailed
queries:
Who’s the prime
minister?
With detailed
queries:
Who is the prime
minister of Canada,
and how frequently
are elections held?
SYSTEM:
You are a prompt
expert and will
suggest ways to
improve a user
request.
USER:
What is the capital
of Canada?
USER:
Summarize the text
delimited by triple
quotes with a
limerick:
“text to be
summarized”
.
EXAMPLES
SYSTEM:
Use the following
step-by-step
instructions to
respond to user
inputs:
Step 1 - Summarize
the text in triple
quotes to one
sentence with a
preﬁx that says
“Summary: ”.
Step 2 - Translate
the summary from
Step 1 into French,
with a preﬁx that
says “Translation: ”.
USER:
“text to summarize
and translate”
SYSTEM:
Answer in a
consistent style.
USER:
T
o
each me ab ut
patience.
A
N
SSISTA T:
The river that
carves the deepest
valley ﬂows from a
modest spring; the
most intricate
tapestry begins with
a solitary thread.
USER:
T
o
each me ab ut
the ocean.
USER:
Summarize the text
delimited by triple
quotes in about 50
words.
“text to summarize
here”
This is the
example.
Provide as much
detail as you can
in a query;
generally, the
more detail the
better.
Personas can
include details
about
demographics,
knowledge, and
personality.
Delimiters can
hel separate
p
blocks of content
from speciﬁcation
details.
Limiting the
length of output
can be speciﬁc
to words, bullet
points, or other
metrics.
Using steps can
help the LLM
better process
the task, but be
sure to limit
the number.
Examples are a
form of few-shot
learning and can
be an excellent
way to indicate
the desired
response format
and other details.
Figure 2.9
The tactics for the Write Clear Instructions strategy
Collects all
the files for the
given folder
Prints the list of
files as choices
Inputs the
user’s choice

28
CHAPTER 2
Harnessing the power of large language models
if choice == 0:
break
elif 1 <= choice <= len(text_files):
selected_file = text_files[choice - 1]
file_path = os.path.join(directory,
selected_file)
prompts =
➥ load_and_parse_json_file(file_path)
print(f"Running prompts for {selected_file}")
for i, prompt in enumerate(prompts):
print(f"PROMPT {i+1} --------------------")
print(prompt)
print(f"REPLY ---------------------------")
print(prompt_llm(prompt))
else:
print("Invalid choice. Please enter a valid number.")
except ValueError:
print("Invalid input. Please enter a number.")
A commented-out section from the listing demonstrates how to connect to a local
LLM. This will allow you to explore the same prompt engineering tactics applied to
open source LLMs running locally. By default, this example uses the OpenAI model
we configured previously in section 2.1.1. If you didn’t complete that earlier, please go
back and do it before running this one.
Figure 2.10 shows the output of running the prompt engineering tactics tester, the
prompt_engineering.py file in VS Code. When you run the tester, you can enter a
value for the tactic you want to test and watch it run.
In the following sections, we’ll explore each prompt tactic in more detail. We’ll also
examine the various examples.
2.3.1
Creating detailed queries
The basic premise of this tactic is to provide as much detail as possible but also to be
careful not to give irrelevant details. The following listing shows the JSON Lines file
examples for exploring this tactic.


Loads the
prompt and
parses it into
messages
Submits the
prompt to an
OpenAI LLM
Figure 2.10
The output of the prompt engineering tactics tester

29
2.3
Prompting LLMs with prompt engineering
[
{
"role": "system",
"content": "You are a helpful assistant."
},
{
"role": "user",
"content": "What is an agent?"
}
]
[
{
"role": "system",
"content": "You are a helpful assistant."
},
{
"role": "user",
"content": """
What is a GPT Agent?
Please give me 3 examples of a GPT agent
"""
}
]
This example demonstrates the difference between using detailed queries and not. It
also goes a step further by asking for examples. Remember, the more relevance and
context you can provide in your prompt, the better the overall response. Asking for
examples is another way of enforcing the relationship between the question and the
expected output.
2.3.2
Adopting personas
Adopting personas grants the ability to define an overarching context or set of rules to
the LLM. The LLM can then use that context and/or rules to frame all later output
responses. This is a compelling tactic and one that we’ll make heavy use of throughout
this book.
Listing 2.10 shows an example of employing two personas to answer the same ques-
tion. This can be an enjoyable technique for exploring a wide range of novel applica-
tions, from getting demographic feedback to specializing in a specific task or even
rubber ducking.
Listing 2.9
detailed_queries.jsonl
GPT rubber ducking
Rubber ducking is a problem-solving technique in which a person explains a problem
to an inanimate object, like a rubber duck, to understand or find a solution. This
method is prevalent in programming and debugging, as articulating the problem aloud
often helps clarify the problem and can lead to new insights or solutions.
The first example doesn’t
use detailed queries.
First ask the LLM a
very general question.
Ask a more specific question,
and ask for examples.

30
CHAPTER 2
Harnessing the power of large language models
[
{
"role": "system",
"content": """
You are a 20 year old female who attends college
in computer science. Answer all your replies as
a junior programmer.
"""
},
{
"role": "user",
"content": "What is the best subject to study."
}
]
[
{
"role": "system",
"content": """
You are a 38 year old male registered nurse.
Answer all replies as a medical professional.
"""
},
{
"role": "user",
"content": "What is the best subject to study."
}
]
A core element of agent profiles is the persona. We’ll employ various personas to assist
agents in completing their tasks. When you run this tactic, pay particular attention to
the way the LLM outputs the response.
2.3.3
Using delimiters
Delimiters are a useful way of isolating and getting the LLM to focus on some part of a
message. This tactic is often combined with other tactics but can work well inde-
pendently. The following listing demonstrates two examples, but there are several
other ways of describing delimiters, from XML tags to using markdown.
[
{
(continued)
GPT rubber ducking uses the same technique, but instead of an inanimate object, we
use an LLM. This strategy can be expanded further by giving the LLM a persona spe-
cific to the desired solution domain.
Listing 2.10
adopting_personas.jsonl
Listing 2.11
using_delimiters.jsonl
First persona
Second persona

31
2.3
Prompting LLMs with prompt engineering
"role": "system",
"content": """
Summarize the text delimited by triple quotes
with a haiku.
"""
},
{
"role": "user",
"content": "A gold chain is cool '''but a silver chain is better'''"
}
]
[
{
"role": "system",
"content": """
You will be provided with a pair of statements
(delimited with XML tags) about the same topic.
First summarize the arguments of each statement.
Then indicate which of them makes a better statement
and explain why.
"""
},
{
"role": "user",
"content": """
<statement>gold chains are cool</statement>
<statement>silver chains are better</statement>
"""
}
]
When you run this tactic, pay attention to the parts of the text the LLM focuses on
when it outputs the response. This tactic can be beneficial for describing information
in a hierarchy or other relationship patterns.
2.3.4
Specifying steps
Specifying steps is another powerful tactic that can have many uses, including in
agents, as shown in listing 2.12. It’s especially powerful when developing prompts or
agent profiles for complex multistep tasks. You can specify steps to break down these
complex prompts into a step-by-step process that the LLM can follow. In turn, these
steps can guide the LLM through multiple interactions over a more extended conver-
sation and many iterations.
[
{
"role": "system",
"content": """
Use the following step-by-step instructions to respond to user inputs.
Step 1 - The user will provide you with text in triple single quotes.
Summarize this text in one sentence with a prefix that says 'Summary: '.
Listing 2.12
specifying_steps.jsonl
The delimiter is defined by
character type and repetition.
The delimiter is defined
by XML standards.

32
CHAPTER 2
Harnessing the power of large language models
Step 2 - Translate the summary from Step 1 into Spanish,
with a prefix that says 'Translation: '.
"""
},
{
"role": "user",
"content": "'''I am hungry and would like to order an appetizer.'''"
}
]
[
{
"role": "system",
"content": """
Use the following step-by-step instructions to respond to user inputs.
Step 1 - The user will provide you with text. Answer any questions in
the text in one sentence with a prefix that says 'Answer: '.
Step 2 - Translate the Answer from Step 1 into a dad joke,
with a prefix that says 'Dad Joke: '."""
},
{
"role": "user",
"content": "What is the tallest structure in Paris?"
}
]
2.3.5
Providing examples
Providing examples is an excellent way to guide the desired output of an LLM. There
are numerous ways to demonstrate examples to an LLM. The system message/prompt
can be a helpful way to emphasize general output. In the following listing, the example
is added as the last LLM assistant reply, given the prompt “Teach me about Python.”
[
{
"role": "system",
"content": """
Answer all replies in a consistent style that follows the format,
length and style of your previous responses.
Example:
user:
Teach me about Python.
assistant:
Python is a programming language developed in 1989
by Guido van Rossum.
Future replies:
The response was only a sentence so limit
all future replies to a single sentence.
"""
},
{
"role": "user",
Listing 2.13
providing_examples.jsonl
Notice the tactic of
using delimiters.
Steps can be
completely
different
operations.
Injects the
sample output as
the “previous”
assistant reply
Adds a limit output tactic to
restrict the size of the output
and match the example

33
2.3
Prompting LLMs with prompt engineering
"content": "Teach me about Java."
}
]
Providing examples can also be used to request a particular output format from a
complex series of tasks that derive the output. For example, asking an LLM to pro-
duce code that matches a sample output is an excellent use of examples. We’ll employ
this tactic throughout the book, but other methods exist for guiding output.
2.3.6
Specifying output length
The tactic of specifying output length can be helpful in not just limiting tokens but
also in guiding the output to a desired format. Listing 2.14 shows an example of using
two different techniques for this tactic. The first limits the output to fewer than 10
words. This can have the added benefit of making the response more concise and
directed, which can be desirable for some use cases. The second example demon-
strates limiting output to a concise set of bullet points. This method can help narrow
down the output and keep answers short. More concise answers generally mean the
output is more focused and contains less filler.
[
{
"role": "system",
"content": """
Summarize all replies into 10 or fewer words.
"""
},
{
"role": "user",
"content": "Please tell me an exciting fact about Paris?"
}
]
[
{
"role": "system",
"content": """
Summarize all replies into 3 bullet points.
"""
},
{
"role": "user",
"content": "Please tell me an exciting fact about Paris?"
}
]
Keeping answers brief can have additional benefits when developing multi-agent sys-
tems. Any agent system that converses with other agents can benefit from more con-
cise and focused replies. It tends to keep the LLM more focused and reduces noisy
communication.
Listing 2.14
specifying_output_length.jsonl
Restricting the output
makes the answer
more concise.
Restricts the answer
to a short set of
bullets

34
CHAPTER 2
Harnessing the power of large language models
Be sure to run through all the examples of the prompt tactics for this strategy. As
mentioned, we’ll cover other prompt engineering strategies and tactics in future chap-
ters. We’ll finish this chapter by looking at how to pick the best LLM for your use case.
2.4
Choosing the optimal LLM for your specific needs
While being a successful crafter of AI agents doesn’t require an in-depth understand-
ing of LLMs, it’s helpful to be able to evaluate the specifications. Like a computer
user, you don’t need to know how to build a processor to understand the differences
in processor models. This analogy holds well for LLMs, and while the criteria may be
different, it still depends on some primary considerations.
From our previous discussion and look at LM Studio, we can extract some funda-
mental criteria that will be important to us when considering LLMs. Figure 2.11
LLMs
2
1
3
4
5
Model Performance:
Determines how well a
model may perform on a
given benchmark, such
as answering SAT
questions.
Model Parameters (Size):
Speciﬁcs the size of the
model in billions of
parameters. Larger
models typically perform
better on general tasks.
Use Case (Model Type):
Determines the type of
model and expected use
case. This could be chat
completions for a model
like ChatGPT.
Training Input: Speciﬁes
the material used to train
the model. This can
range from everything on
the internet to a speciﬁc
domain Python code.
Training Method: Speciﬁes
how the model is trained
and/or ﬁne-tuned. Models
like ChatGPT are trained
using reinforcement learning
with human feedback.
6
7
8
Context Token Size:
Speciﬁes how large the
model’s context size is in
tokens. Large context is
important for verbose agent
conversations.
Model Speed (Model
Deployment): Denotes the
speed of the model. OpenAI
models marked Turbo are
typically faster. For local LLMs,
speed will be determined by
the infrastructure.
Model Cost (Project
Budget): Could represent
the price of the service or
the cost to host and run a
model on your infrastructure.
Figure 2.11
The important criteria to consider when consuming an LLM

35
2.4
Choosing the optimal LLM for your specific needs
explains the essential criteria to define what makes an LLM worth considering for cre-
ating a GPT agent or any LLM task.
For our purposes of building AI agents, we need to look at each of these criteria in
terms related to the task. Model context size and speed could be considered the sixth
and seventh criteria, but they are usually considered variations of a model deployment
architecture and infrastructure. An eighth criterion to consider for an LLM is cost,
but this depends on many other factors. Here is a summary of how these criteria relate
to building AI agents:
Model performance—You’ll generally want to understand the LLM’s performance
for a given set of tasks. For example, if you’re building an agent specific to cod-
ing, then an LLM that performs well on code will be essential.
Model parameters (size)—The size of a model is often an excellent indication of
inference performance and how well the model responds. However, the size of
a model will also dictate your hardware requirements. If you plan to use your
own locally hosted model, the model size will also primarily dictate the com-
puter and GPU you need. Fortunately, we’re seeing small, very capable open
source models being released regularly.
Use case (model type)—The type of model has several variations. Chat completions
models such as ChatGPT are effective for iterating and reasoning through a
problem, whereas models such as completion, question/answer, and instruct
are more related to specific tasks. A chat completions model is essential for
agent applications, especially those that iterate.
Training input—Understanding the content used to train a model will often dic-
tate the domain of a model. While general models can be effective across tasks,
more specific or fine-tuned models can be more relevant to a domain. This may
be a consideration for a domain-specific agent where a smaller, more fine-tuned
model may perform as well as or better than a larger model such as GPT-4.
Training method—It’s perhaps less of a concern, but it can be helpful to under-
stand what method was used to train a model. How a model is trained can
affect its ability to generalize, reason, and plan. This can be essential for plan-
ning agents but perhaps less significant for agents than for a more task-specific
assistant.
Context token size—The context size of a model is more specific to the model
architecture and type. It dictates the size of context or memory the model may
hold. A smaller context window of less than 4,000 tokens is typically more than
enough for simple tasks. However, a large context window can be essential when
using multiple agents—all conversing over a task. The models will typically be
deployed with variations on the context window size.
Model speed (model deployment)—The speed of a model is dictated by its inference
speed (or how fast a model replies to a request), which in turn is dictated by the
infrastructure it runs on. If your agent isn’t directly interacting with users, raw

36
CHAPTER 2
Harnessing the power of large language models
real-time speed may not be necessary. On the other hand, an LLM agent inter-
acting in real time needs to be as quick as possible. For commercial models,
speed will be determined and supported by the provider. Your infrastructure
will determine the speed for those wanting to run their LLMs.
Model cost (project budget)—The cost is often dictated by the project. Whether
learning to build an agent or implementing enterprise software, cost is always a
consideration. A significant tradeoff exists between running your LLMs versus
using a commercial API.
There is a lot to consider when choosing which model you want to build a production
agent system on. However, picking and working with a single model is usually best for
research and learning purposes. If you’re new to LLMs and agents, you’ll likely want
to choose a commercial option such as GPT-4 Turbo. Unless otherwise stated, the
work in this book will depend on GPT-4 Turbo.
Over time, models will undoubtedly be replaced by better models. So you may
need to upgrade or swap out models. To do this, though, you must understand the
performance metrics of your LLMs and agents. Fortunately, in chapter 9, we’ll explore
evaluating LLMs, prompts, and agent profiles with prompt flow.
2.5
Exercises
Use the following exercises to help you engage with the material in this chapter:
Exercise 1—Consuming Different LLMs
Objective—Use the connecting.py code example to consume a different LLM
from OpenAI or another provider.
Tasks:
– Modify connecting.py to connect to a different LLM.
– Choose an LLM from OpenAI or another provider.
– Update the API keys and endpoints in the code.
– Execute the modified code and validate the response.
Exercise 2—Exploring Prompt Engineering Tactics
Objective—Explore various prompt engineering tactics, and create variations
for each.
Tasks:
– Review the prompt engineering tactics covered in the chapter.
– Write variations for each tactic, experimenting with different phrasing and
structures.
– Test the variations with an LLM to observe different outcomes.
– Document the results, and analyze the effectiveness of each variation.
Exercise 3—Downloading and Running an LLM with LM Studio
Objective—Download an LLM using LM Studio, and connect it to prompt engi-
neering tactics.

37
Summary
Tasks:
– Install LM Studio on your machine.
– Download an LLM using LM Studio.
– Serve the model using LM Studio.
– Write Python code to connect to the served model.
– Integrate the prompt engineering tactics example with the served model.
Exercise 4—Comparing Commercial and Open source LLMs
Objective—Compare the performance of a commercial LLM such as GPT-4
Turbo with an open source model using prompt engineering examples.
Tasks:
– Implement the prompt engineering examples using GPT-4 Turbo.
– Repeat the implementation using an open source LLM.
– Evaluate the models based on criteria such as response accuracy, coherence,
and speed.
– Document the evaluation process, and summarize the findings.
Exercise 5—Hosting Alternatives for LLMs
Objective—Contrast and compare alternatives for hosting an LLM versus using a
commercial model.
Tasks:
– Research different hosting options for LLMs (e.g., local servers, cloud services).
– Evaluate the benefits and drawbacks of each hosting option.
– Compare these options to using a commercial model in terms of cost, perfor-
mance, and ease of use.
– Write a report summarizing the comparison and recommending the best
approach based on specific use cases.
Summary
LLMs use a type of architecture called generative pretrained transformers (GPTs).
Generative models (e.g., LLMs and GPTs) differ from predictive/classification
models by learning how to represent data and not simply classify it.
LLMs are a collection of data, architecture, and training for specific use cases,
called fine-tuning.
The OpenAI API SDK can be used to connect to an LLM from models, such as
GPT-4, and also used to consume open source LLMs.
You can quickly set up Python environments and install the necessary packages
for LLM integration.
LLMs can handle various requests and generate unique responses that can be
used to enhance programming skills related to LLM integration.
Open source LLMs are an alternative to commercial models and can be hosted
locally using tools such as LM Studio.

38
CHAPTER 2
Harnessing the power of large language models
Prompt engineering is a collection of techniques that help craft more effective
prompts to improve LLM responses.
LLMs can be used to power agents and assistants, from simple chatbots to fully
capable autonomous workers.
Selecting the most suitable LLM for specific needs depends on the perfor-
mance, parameters, use case, training input, and other criteria.
Running LLMs locally requires a variety of skills, from setting up GPUs to under-
standing various configuration options.

39
Engaging
GPT assistants
As we explore the OpenAI crusade into assistants and what has been hinted at, ulti-
mately, an agent platform called GPT Assistants, we’ll introduce GPT assistants
through the ChatGPT interface. Then, we’ll add in several fully developed assis-
tants that can suggest recipes from ingredients, fully analyze data as a data scientist,
guide readers through books, and be extended with custom actions. By the end of
the chapter, we’ll be ready to build a fully functional agent that can be published to
the OpenAI GPT Store.
This chapter covers
Introducing the OpenAI GPT Assistants platform
and the ChatGPT UI
Building a GPT that can use the code
interpretation capabilities
Extending an assistant via custom actions
Adding knowledge to a GPT via file uploads
Commercializing your GPT and publishing it to
the GPT Store

40
CHAPTER 3
Engaging GPT assistants
3.1
Exploring GPT assistants through ChatGPT
ChatGPT (ChatGPT Plus, at the time of writing) allows you to build GPT assistants,
consume other assistants, and even publish them, as you’ll see by the end of the chap-
ter. When OpenAI announced the release of the GPT Assistants platform, it helped
define and solidify the emergence of AI agents. As such, it’s worth a serious review by
anyone interested in building and consuming agent systems. First, we’ll look at build-
ing GPT assistants through ChatGPT Plus, which requires a premium subscription. If
you don’t want to purchase a subscription, browse this chapter as a primer, and chap-
ter 6 will demonstrate consuming the API service later.
Figure 3.1 shows the page for the GPT Store within ChatGPT (https://chatgpt
.com/gpts). From here, you can search and explore various GPTs for virtually any
task. The amount of usage will typically indicate how well each GPT works, so gauge
which works best for you.
Creating your first GPT Assistant is as simple as clicking the Create button and follow-
ing along with the GPT Builder chat interface. Figure 3.2 shows using the Builder to
Explore the GPTs
you have made.
Search for GPTs by
name of category.
Click Create to create
your own GPT.
Figure 3.1
The main interface to the GPT Store

41
3.1
Exploring GPT assistants through ChatGPT
create a GPT. Working through this exercise a couple of times can be a great way to
start understanding an assistant’s requirements.
After working with the Builder, you can open the manual configuration panel, shown
in figure 3.3, and edit the GPT directly. You’ll see the name, description, instruc-
tions, and conversation starters populated from your conversations with the Builder.
This can be a great start, but generally, you’ll want to edit and tweak these proper-
ties manually.
If you want to follow along with building your own Culinary Companion, enter the
text from listing 3.1 into the instructions. These instructions were partly generated by
conversing with the Builder and added based on explicit outputs. The explicit outputs
are added to the instructions as rules.




The Builder can guide you
through the creation process.
Dialog with the Builder
to create your GPT.
Figure 3.2
Interacting with
the GPT Builder to create an
assistant

42
CHAPTER 3
Engaging GPT assistants
Culinary Companion assists users with a friendly, engaging tone,
reminiscent of the famous chef Julia Child.
It provides quick meal ideas and simplifies complex recipes, focusing on
ingredients the user already has. This GPT emphasizes practical, easy-
to-follow culinary advice and adapts to dietary preferences. It's
designed to make cooking a more accessible and enjoyable experience,
encouraging users to experiment with their meals while offering helpful
Listing 3.1
Instructions for Culinary Companion
Using the Builder will generate a set
of instructions for your assistant, or
you can start completely from scratch.
The Conﬁgure panel gives
you direct control over your
GPT’s properties.
A good name and description
will be essential if you plan on
publishing this agent.
Good conversation starters can help
users quickly understand what your
agent does and how it works.
Figure 3.3
The Configure panel of the GPT Assistants platform interface
Personality or persona
of your assistant

43
3.1
Exploring GPT assistants through ChatGPT
tips in a warm, approachable manner.
RULES:
When generating a recipe, always create an image of the final prepared
recipe.
When generating a recipe, estimate the calories and nutritional values
per serving.
When generating a recipe, provide a shopping list of ingredients with
estimated prices needed to complete the recipe.
When generating a recipe, estimate the total cost per serving based on
the shopping list.
Defining rules for an assistant/agent essentially creates a template for what the agent
will produce. Adding rules ensures that the GPT output is consistent and aligned with
your expectations of how the agent should operate. Defining and giving an agent/
assistant a persona provides them with a unique and memorable personality.
NOTE
Giving an agent/assistant a particular personality can make a differ-
ence in the type and form of output. Asking a cooking agent to speak as the
first celebrity chef, Julia Child, not only provides for a fun tone but also
engages more references that may mention or talk about her cooking style
and teaching. When constructing an agent/assistant, assigning a particular
persona/personality can be helpful.
With just these few steps, we have a culinary companion that not only gives us recipes
for ingredients we have on hand but also generates an image of the finished recipe,
estimates the nutritional value, creates a shopping list with an estimate of prices, and
breaks down the cost per serving.
Try the assistant by requesting a recipe and providing a list of ingredients you have
or prefer. Listing 3.2 shows an example of a simple request with extra information to
set the mood. Of course, you can add any ingredients or situations you like and then
see the results.
I have a bag of prepared frozen chicken strips and I want to make a
romantic dinner for two.
Figure 3.4 shows the formatted output results from the GPT provided by the prompt.
It certainly looks good enough to eat. All of this output was generated because of the
instructions we provided the agent.
While the output results look great, they may not all be factual and correct, and
your results may vary. For instance, the GPT added chicken strips to the shopping list
when we had already suggested having those ingredients. Furthermore, the prices and
estimated nutritional information are just estimates, but this can be resolved later if
they interest you.
Listing 3.2
Prompting the recipe
General guidelines of the
agent’s role and goal
A set of rules the agent will
follow when suggesting a recipe

44
CHAPTER 3
Engaging GPT assistants
Out of the box, though, GPT Assistants is quite impressive for quickly building a proof-
of-concept assistant or agent. As you’ll see later in the chapter, it also provides an excel-
lent platform for consuming assistants outside ChatGPT. In the next section, we’ll look
at more impressive features GPTs provide, such as file uploads and code interpretation.
3.2
Building a GPT that can do data science
The GPT Assistants platform has and will likely be extended to include various agent
components. Currently, GPT Assistants support what is referred to as knowledge,
memory, and actions. In chapter 8, we’ll discuss the details of knowledge and memory,
and in chapter 5, we cover the concept of tool use through actions.
In our next exercise, we’ll build an assistant to perform a first-pass data science
review of any CSV document we provide. This agent will use the ability or action that
allows for coding and code interpretation. When you enable code interpretation, the
assistant will allow file uploads by default.
Before we do that, though, we want to design our agent, and what better way to do
that than to ask an LLM to build us an assistant? Listing 3.3 shows the prompt request-
ing ChatGPT (GPT-4) to design a data science assistant. Notice how we’re not asking
for everything in a single prompt but instead iterating over the information returned
by the LLM.
FIRST PROMPT:
what is a good basic and interesting data science
experiment you can task someone with a single
csv file that contains interesting data?
Listing 3.3
Prompting for a data science assistant
The GPT assistant creates
the recipe from the provided
ingredients and provides a
shopping list with costs and
cost per ser
nutritional
ving,
information per serving, and
instructions on how to cook
the recipe.
Chicken Parmesan with Spaghetti Recipe
Ingredients:
