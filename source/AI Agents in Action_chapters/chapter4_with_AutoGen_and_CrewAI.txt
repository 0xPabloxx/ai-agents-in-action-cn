Chapter 4: with AutoGen and CrewAI.
Starting Page: 169
================================================================================

For this coding challenge, we’re going a little further and looking at Python cod-
ing challenges from the Edabit site (https://edabit.com), which range in complexity
from beginner to expert. We’ll stick with the expert code challenges because GPT-4o
and other models are excellent coders. Look at the challenge in the next listing, and
think about how you would solve it.
Plant the Grass by AniXDownLoe
You will be given a matrix representing a field g
and two numbers x, y coordinate.
There are three types of possible characters in the matrix:
x representing a rock.
o representing a dirt space.
+ representing a grassed space.
You have to simulate grass growing from the position (x, y).
Grass can grow in all four directions (up, left, right, down).
Grass can only grow on dirt spaces and can't go past rocks.
Return the simulated matrix.
Examples
simulate_grass([
"xxxxxxx",
"xooooox",
"xxxxoox"
"xoooxxx"
"xxxxxxx"
], 1, 1) → [
"xxxxxxx",
"x+++++x",
"xxxx++x"
"xoooxxx"
"xxxxxxx"
]
Notes
There will always be rocks on the perimeter
You can use any challenge or coding exercise you want, but here are a few things to
consider:
Listing 6.5
Edabit challenge: Plant the Grass

146
CHAPTER 6
Building autonomous assistants
The challenge should be testable with quantifiable assertions (pass/fail).
Avoid opening windows when asking for a game, building a website, or using
another interface. At some point, testing full interfaces will be possible, but for
now, it’s just text output.
Avoid long-running challenges, at least initially. Start by keeping the challenges
concise and short lived.
Along with any challenge, you’ll also want a set of tests or assertions to confirm the
solution works. On Edabit, a challenge typically provides a comprehensive set of tests.
The following listing shows the additional tests provided with the challenge.
Test.assert_equals(simulate_grass(
["xxxxxxx","xooooox","xxxxoox","xoooxxx","xxxxxxx"],
1, 1),
["xxxxxxx","x+++++x","xxxx++x","xoooxxx","xxxxxxx"])
Test.assert_equals(simulate_grass(
["xxxxxxx","xoxooox","xxoooox","xooxxxx",
"xoxooox","xoxooox","xxxxxxx"],
2, 3), ["xxxxxxx","xox+++x","xx++++x","x++xxxx",
"x+xooox","x+xooox","xxxxxxx"])
Test.assert_equals(simulate_grass(
["xxxxxx","xoxoox","xxooox","xoooox","xoooox","xxxxxx"],
1, 1),
["xxxxxx","x+xoox","xxooox","xoooox","xoooox","xxxxxx"])
Test.assert_equals(simulate_grass(
["xxxxx","xooox","xooox","xooox","xxxxx"],
1, 1),
["xxxxx","x+++x","x+++x","x+++x","xxxxx"])
Test.assert_equals(simulate_grass(
["xxxxxx","xxxxox","xxooox","xoooxx","xooxxx",
"xooxxx","xxooox","xxxoxx","xxxxxx"],
4, 1),
["xxxxxx","xxxx+x","xx+++x","x+++xx","x++xxx",
"x++xxx","xx+++x","xxx+xx","xxxxxx"])
Test.assert_equals(simulate_grass(
["xxxxxxxxxxx", "xoxooooooox", "xoxoxxxxxox",
"xoxoxoooxox", "xoxoxoxoxox", "xoxoxoxoxox",
"xoxoxxxoxox", "xoxoooooxox", "xoxxxxxxxox",
"xooooooooox", "xxxxxxxxxxx"], 1, 1),
["xxxxxxxxxxx", "x+x+++++++x", "x+x+xxxxx+x",
"x+x+x+++x+x", "x+x+x+x+x+x", "x+x+x+x+x+x",
"x+x+xxx+x+x", "x+x+++++x+x", "x+xxxxxxx+x",
"x+++++++++x", "xxxxxxxxxxx"])
The tests will be run as part of a two-step verification to confirm that the solution
works. We’ll also use the tests and challenges as written, which will further test the AI.
Figure 6.8 shows the makeup of a straightforward behavior tree that will be used to
solve various programming challenges. You’ll notice that this ABT uses a different
Listing 6.6
Plant the Grass tests

147
6.3
Introducing agentic behavior trees
assistant for the actions and conditions. For the first step, the Python coding assistant
(called the Hacker) generates a solution that is then reviewed by the coding challenge
Judge (called the Judge), which produces a refined solution that is verified by a differ-
ent Python coding assistant (called the Verifier).
Figure 6.8 also shows how each agent converses on which thread. Assistants use mes-
sage threads, similar to a Slack or Discord channel, where all assistants conversing on
a thread will see all messages. For this ABT, we keep one main conversation thread for
the Hacker and Judge to share messages, while the Verifier works on a separate mes-
sage thread. Keeping the Verifier on its own thread isolates it from the noise of the
solution-solving efforts.
Now, building the ABT in code is a matter of combining the py_trees package and
the Playground API functions. Listing 6.7 shows an excerpt of code that creates each
of the action/condition nodes with the assistants and gives them the instructions.




→
Verify solution
Hacking solution
The root node is a sequence.
Judge solution
The initial solution will
be generated by the
Python oding ssistant,
c
a
which will save output to
solution.py.
solution.py
The solution will be judged
by the oding hallenge
c
c
Judge. It will load the
solution.py, judge it, and
output a ﬁle called
judged_solution.py.
judged_solution.py
The last step uses a Python
c
a
oding ssistant and veriﬁes
that the solution is correct
by looking at the
judged_solution.py ﬁle.
Main conversation
thread
New conversation
thread
Assistants use threads to
capture conversations.
Figure 6.8
The ABT for the coding challenge

148
CHAPTER 6
Building autonomous assistants
root = py_trees.composites.Sequence("RootSequence", memory=True)
thread = api.create_thread()
challenge = textwrap.dedent("""

""")
judge_test_cases = textwrap.dedent("""

""")
hacker = create_assistant_action_on_thread(
thread=thread,
action_name="Hacker",
assistant_name="Python Coding Assistant",
assistant_instructions=textwrap.dedent(f"""
Challenge goal:
{challenge}
Solve the challenge and output the
final solution to a file called solution.py
"""),
)
root.add_child(hacker)
judge = create_assistant_action_on_thread(
thread=thread,
action_name="Judge solution",
assistant_name="Coding Challenge Judge",
assistant_instructions=textwrap.dedent(
f"""
Challenge goal:
{challenge}
Load the solution from the file solution.py.
Then confirm is a solution to the challenge
and test it with the following test cases:
{judge_test_cases}
Run the code for the solution and confirm it passes all the test cases.
If the solution passes all tests save the solution to a file called
judged_solution.py
""",
),
)
root.add_child(judge)
# verifier operates on a different thread, essentially in closed room
verifier = create_assistant_condition(
condition_name="Verify solution",
assistant_name="Python Coding Assistant",
assistant_instructions=textwrap.dedent(
f"""
Challenge goal:
{challenge}
Load the file called judged_solution.py and
Listing 6.7
agentic_btree_coding_challenge.py
Creates a message thread that will
be shared by the Hacker and Judge
The challenge as shown
in the example listing 6.5
The tests as shown in
the example listing 6.6
Creates a message thread that will
be shared by the Hacker and Judge
The challenge as shown
in the example listing 6.5
Creates a message thread that will
be shared by the Hacker and Judge
The challenge as shown
in the example listing 6.5
The tests as shown in
the example listing 6.6
Call creates a
new message
thread
The challenge as shown
in the example listing 6.5

149
6.3
Introducing agentic behavior trees
verify that the solution is correct by running the code and confirm it passes
all the test cases:
{judge_test_cases}
If the solution is correct, return only the single word SUCCESS,
otherwise
return the single word FAILURE.
""",
),
)
root.add_child(verifier)
tree = py_trees.trees.BehaviourTree(root)
while True:
tree.tick()
time.sleep(20)
if root.status == py_trees.common.Status.SUCCESS:
break
### Required assistants –
### Python Coding Assistant and Coding Challenge Judge
### install these assistants through the Playground
Run the ABT by loading the file in VS Code or using the command line. Follow the out-
put in the terminal, and watch how the assistants work through each step in the tree.
If the solution fails to be verified at the condition node, the process will continue
per the tree. Even with this simple solution, you could quickly create numerous varia-
tions. You could extend the tree with more nodes/steps and subtrees. Perhaps you
want a team of Hackers to break down and analyze the challenge, for example.
This example’s work is done mainly with the Playground code, using the helper
functions create_assistant_condition and create_assistant_action_on_thread.
This code uses a couple of classes to integrate the py_trees behavior tree code and
the OpenAI Assistants code wrapped in the Playground. Review the code within the
project if you want to understand the lower-level details.
6.3.3
Conversational AI systems vs. other methods
We already looked at conversational multi-agent systems in chapter 4 when we looked
at AutoGen. The ABT can work using a combination of conversations (over threads)
and other methods, such as file sharing. Having your assistants/agents pass files around
helps reduce the number of noisy and repetitive thoughts/conversations. In contrast,
conversational systems benefit from potential emergent behaviors. So, using both can
help evolve better control and solutions.
The simple solution in listing 6.7 could be extended to handle more real-world
coding challenges and perhaps even to work as a coding ABT. In the next section, we
build a different ABT to handle a different problem.
The tests as shown in
the example listing 6.6
The sleep time can be
adjusted up or down as
needed and can be used
to throttle the messages
sent to an LLM.
The process will
continue until
the verification
succeeds.

150
CHAPTER 6
Building autonomous assistants
6.3.4
Posting YouTube videos to X
In this section’s exercise, we look at an ABT that can do the following:
1
Search for videos on YouTube for a given topic and return the latest videos.
2
Download the transcripts for all the videos your search provided.
3
Summarize the transcripts.
4
Review the summarized transcripts and select a video to write an X (formerly
Twitter) post about.
5
Write an exciting and engaging post about the video, ensuring it’s less than 280
characters.
6
Review the post and then post it on X.
Figure 6.9 shows the ABT assembled with each of the different assistants. In this exer-
cise, we use a sequence node for the root, and each assistant performs a different
action. Also, to keep things simple, each assistant interaction will always occur in a
new thread. This isolates each assistant’s interaction into a concise conversation that’s
easier to debug if something goes wrong.
New thread
→
Search YouTube
Write post
This assistant searches
YouTube for videos,
downloads and
summarizes the
transcripts, and saves
to a ﬁle.
youtube
transcripts.txt
The assistant loads the
transcripts, selects a
relevant video, writes a
post of less than 280
characters, and then
outputs a ﬁle.
youtube
twitter
post.txt
The assistant loads the
post, reviews it and posts
it to Twitter (X).
New thread
New thread
Assistants always use
a new thread.
Post to X
The root node is a sequence.
Figure 6.9
The YouTube social media ABT

151
6.3
Introducing agentic behavior trees
6.3.5
Required X setup
If you plan to run the code in this exercise, you must add your X credentials to the
.env file. The .env.default file shows an example of how the credentials need to be,
as shown in listing 6.8. You don’t have to enter your credentials. This means the last
step, posting, will fail, but you can still look at the file (youtube_twitter_post.txt)
to see what was generated.
X_EMAIL = "twitter email here"
X_USERNAME = "twitter username here"
X_PASSWORD = "twitter password here"
Listing 6.9 shows just the code for creating the assistant actions. This ABT uses three
different assistants, each with its own task instructions. Note that each assistant has a
unique set of instructions defining its role. You can review the instructions for each
assistant by using the Playground.
root = py_trees.composites.Sequence("RootSequence", memory=True)
search_term = "GPT Agents"
search_youtube_action = create_assistant_action(
action_name=f"Search YouTube({search_term})",
assistant_name="YouTube Researcher v2",
assistant_instructions=f"""
Search Term: {search_term}
Use the query "{search_term}" to search for videos on YouTube.
then for each video download the transcript and summarize it
for relevance to {search_term}
be sure to include a link to each of the videos,
and then save all summarizations to a file called youtube_transcripts.txt
If you encounter any errors, please return just the word FAILURE.
""",
)
root.add_child(search_youtube_action)
write_post_action = create_assistant_action(
action_name="Write Post",
assistant_name="Twitter Post Writer",
assistant_instructions="""
Load the file called youtube_transcripts.txt,
Listing 6.8
Configuring credentials
YouTube search and spam
If you plan to run this exercise for real and let it post to your X account, be aware that
YouTube has a bit of a spam problem. The assistants have been configured to try to
avoid video spam, but some of it may get through. Building a working ABT that can
wade through videos while avoiding spam has some suitable applications.
Listing 6.9
agentic_btree_video_poster_v1.py

152
CHAPTER 6
Building autonomous assistants
analyze the contents for references to search term at the top and
then select
the most exciting and relevant video related to:
educational, entertaining, or informative, to post on Twitter.
Then write a Twitter post that is relevant to the video,
and include a link to the video, along
with exciting highlights or mentions,
and save it to a file called youtube_twitter_post.txt.
If you encounter any errors, please return just the word FAILURE.
""",
)
root.add_child(write_post_action)
post_action = create_assistant_action(
action_name="Post",
assistant_name="Social Media Assistant",
assistant_instructions="""
Load the file called youtube_twitter_post.txt and post the content
to Twitter.
If the content is empty please do not post anything.
If you encounter any errors, please return just the word FAILURE.
""",
)
root.add_child(post_action)
### Required assistants – YouTube Researcher v2, Twitter Post Writer,
and Social Media Assistant – install these assistants through the Playground
Run the code as you normally would, and after a few minutes, a new post will appear
in the assistants_output folder. Figure 6.10 shows an example of a post generated
using this ABT. Running this ABT to generate more than a few posts a day could, and
likely will, get your X account blocked. If you’ve configured X credentials, you’ll see
the post appear on your feed.
This ABT is shown for demonstration purposes and isn’t for production or long-term
use. The primary features of this demonstration are to show search and loading data,
summarization and filtering, then generating new content, and finally highlighting
multiple custom actions and integrations with APIs.
Figure 6.10
A sample X
post from the ABT

153
6.4
Building conversational autonomous multi-agents
6.4
Building conversational autonomous multi-agents
The conversational aspect of multi-agent systems can drive mechanisms such as feed-
back, reasoning, and emergent behaviors. Driving agents with ABTs that silo assis-
tants/agents can be effective for controlling structured processes, as we saw in the
YouTube posting example. However, we also don’t want to miss out on the benefits of
conversation across agents/assistants.
Fortunately, the Playground provides methods to silo or join assistants to conversation
threads. Figure 6.11 shows how assistants can be siloed or mixed in various combinations
to threads. Combining silos with conversation provides the best of both patterns.
We’ll examine a simple but practical exercise to demonstrate the effectiveness of the
conversational pattern. For the next exercise, we’ll employ two assistants in an ABT
that converse over the same thread. The next listing shows the tree’s construction in
code with the respective assistants.
root = py_trees.composites.Sequence("RootSequence", memory=True)
bug_file = """
# code not shown
"""
Listing 6.10
agentic_conversation_btree.py
Siloed assistants
always use a new
thread and are the
only consumers.
Thread xya
Thread yyc
Thread zza
Agent/Assistant
Silos
Search
Thread xyb
Search
Thread xyc
Search
Agent/Assistant
Conversational
Search
Plan
Activity
Review
Conversational assistants
share a thread for all
conversations.
Agent/Assistant
Conversational + Silo
Thread xyc
Verify
The combination of siloed
and conversational can be
combined for an unbiased
review.
Search
Plan
Activity
Transfer
Figure 6.11
The various layouts of siloed and conversational assistants

154
CHAPTER 6
Building autonomous assistants
thread = api.create_thread()
debug_code = create_assistant_action_on_thread(
thread=thread,
action_name="Debug code",
assistant_name="Python Debugger",
assistant_instructions=textwrap.dedent(f"""
Here is the code with bugs in it:
{bug_file}
Run the code to identify the bugs and fix them.
Be sure to test the code to ensure it runs without errors or throws
any exceptions.
"""),
)
root.add_child(debug_code)
verify = create_assistant_condition_on_thread(
thread=thread,
condition_name="Verify",
assistant_name="Python Coding Assistant",
assistant_instructions=textwrap.dedent(
"""
Verify the solution fixes the bug and there are no more issues.
Verify that no exceptions are thrown when the code is run.
Reply with SUCCESS if the solution is correct, otherwise return FAILURE.
If you are happy with the solution, save the code to a file called
fixed_bug.py.
""",
),
)
root.add_child(verify)
tree = py_trees.trees.BehaviourTree(root)
while True:
tree.tick()
if root.status == py_trees.common.Status.SUCCESS:
break
time.sleep(20)
Three nodes comprise the tree: the root sequence, the debug code action, and the
verify fix condition. Because the tree’s root is a sequence, the two assistants will con-
tinue to work one after another until they both return with success. Both assistants
converse on the same thread and yet are controlled in a manner that provides con-
stant feedback.
Run the exercise by loading the file in VS Code, or execute it directly from the
command line. The example code has a few minor bugs and problems that the assis-
tants will work through to fix. After the ABT completes running successfully, you can
open the assistants_output/fixed_bug.py file and verify the results are all good.
We’ve now seen a couple of ABTs in action and understand the nuances of using
silos or conversations. The following section will teach you some techniques for build-
ing your own ABTs.
Creates a message thread for the
assistants to share and converse over
Creates the debug
code action with a
special assistant
Creates the verification
condition to test if the
code is fixed or not
The tree will continue
to run until the root
sequence completes
with success.

155
6.5
Building ABTs with back chaining
6.5
Building ABTs with back chaining
Back chaining is a method derived from logic and reasoning used to help build behav-
ior trees by working backward from the goal. This section will use the back chaining
process to construct an ABT that works to achieve the goal. The following list provides
a description of the process in more detail:
1
Identify goal behavior. Start with the behavior you want the agent to perform.
2
Determine the required actions. Identify the actions that lead to the goal behavior.
3
Identify the conditions. Determine the conditions that must be met for each action
to succeed.
4
Determine the mode of communication. Determine how the assistants will pass on
information. Will the assistants be siloed or converse over threads, or is a combi-
nation of patterns better?
5
Construct the tree. Start by building the behavior tree from the goal behavior, add-
ing nodes for actions and conditions recursively until all necessary conditions
are linked to known states or facts.
Behavior trees typically use a pattern called the blackboard to communicate across
nodes. Blackboards, like those in py_trees, use a key/value store to save information
and make it accessible across nodes. It also provides for several controls, such as limit-
ing access to specific nodes.
We deferred to using files for communication because of their simplicity and
transparency. At some point, agentic systems are expected to consume much more
information and in different formats than those designed for blackboards. Black-
boards must either become more sophisticated or be integrated with file storage
solutions.
Let’s build an ABT using back chaining. We could tackle a variety of goals, but one
interesting and perhaps meta goal is to build an ABT that helps build assistants. So
let’s first present our goal as a statement “Create an assistant that can help me do
{task}”:
Required actions: (working backwards)
– Create an assistant.
– Verify the assistant.
– Test the assistant.
– Name the assistant.
– Give the assistant the relevant instructions.
Identified condition:
– Verify the assistant.
Determine communication patterns: To keep things interesting, we’ll run all assis-
tants on the same message thread.

156
CHAPTER 6
Building autonomous assistants
Construct the tree: To construct the tree, let’s first reverse the order of actions and
mark each of the element’s actions and conditions accordingly:
– (action) Give the assistant relevant instructions to help a user with a given task.
– (action) Name the assistant.
– (action) Test the assistant.
– (condition) Verify the assistant.
– (action) Create the assistant.
Of course, the simple solution to building the tree now is to ask ChatGPT or an oth-
erwise capable model. The result of asking ChatGPT to make the tree is shown in
the next listing. You could also work the tree out independently and perhaps intro-
duce other elements.
Root
│
├── Sequence
│    ├── Action: Give the assistant relevant instructions to help a user
with a given task
│    ├── Action: Name the assistant
│    ├── Action: Test the assistant
│    ├── Condition: Verify the assistant
│    └── Action: Create the assistant
From this point, we can start building the tree by iterating over each action and condi-
tion node and determining what instructions the assistant needs. This can also
include any tools and custom actions, including ones you may need to develop. On
your first pass, keep the instructions generic. Ideally, we want to create as few assistants
as necessary.
After determining the assistant, tools, and actions for each assistant and for which
task, you can try to generalize things further. Think about where it may be possible to
combine actions and reduce the number of assistants. It’s better to start evaluating
with insufficient assistants than with too many. However, be sure to maintain the
proper divisions of work as tasks: for example, testing and verification are best done
with different assistants.
6.6
Exercises
Complete the following exercises to improve your knowledge of the material:
Exercise 1—Creating a Travel Planner ABT
Objective—Build an agentic behavior tree (ABT) to plan a travel itinerary using
assistants.
Tasks:
– Set up the GPT Assistants Playground on your local machine.
Listing 6.11
ABT for building an assistant

157
6.6
Exercises
– Create an ABT to plan a travel itinerary. The tree should have the following
structure:
– Action: Use the Travel assistant to gather information about potential des-
tinations.
– Action: Use the Itinerary Planner to create a day-by-day travel plan.
– Condition: Verify the completeness and feasibility of the itinerary using
another Travel Assistant.
– Implement and run the ABT to create a complete travel itinerary.
Exercise 2—Building an ABT for Customer Support Automation
Objective—Create an ABT that automates customer support responses using
assistants.
Tasks:
– Set up the GPT Assistants Playground on your local machine.
– Create an ABT with the following structure:
– Action: Use the Customer Query Analyzer assistant to categorize customer
queries.
– Action: Use the Response Generator assistant to draft responses based on
the query categories.
– Action: Use the Customer Support assistant to send the responses to
customers.
– Implement and run the ABT to automate the process of analyzing and respond-
ing to customer queries.
Exercise 3—Managing Inventory with an ABT
Objective—Learn how to create and manage inventory levels using an ABT.
Tasks:
– Set up the GPT Assistants Playground on your local machine.
– Create an ABT that manages inventory for a retail business:
– Action: Use the Inventory Checker assistant to review current stock levels.
– Action: Use the Order assistant to place orders for low-stock items.
– Condition: Verify that orders have been placed correctly and update inven-
tory records.
– Implement and run the ABT to manage inventory dynamically.
Exercise 4—Creating a Personal Fitness Trainer ABT
Objective—Create an ABT that provides personalized fitness training plans using
assistants.
Tasks:
– Set up the GPT Assistants Playground on your local machine.
– Create an ABT to develop a personalized fitness plan:
– Action: Use the Fitness Assessment assistant to evaluate the user’s current
fitness level.

158
CHAPTER 6
Building autonomous assistants
– Action: Use the Training Plan Generator to create a custom fitness plan
based on the assessment.
– Condition: Verify the plan’s suitability and safety using another Fitness
assistant.
– Implement and run the ABT to generate and validate a personalized fitness
training plan.
Exercise 5—Using Back Chaining to Build a Financial Advisor ABT
Objective—Apply back chaining to construct an ABT that provides financial
advice and investment strategies.
Tasks:
– Set up the GPT Assistants Playground on your local machine.
– Define the following goal: “Create an assistant that can provide financial
advice and investment strategies.”
– Using back chaining, determine the actions and conditions needed to
achieve this goal.
– Implement and run the ABT to generate a comprehensive financial advi-
sory service by back chaining the construction of the base actions and con-
ditions for the tree.
Summary
Behavior trees are a robust and scalable AI control pattern, first introduced in
robotics by Rodney A. Brooks. They are widely used in gaming and robotics for
their modularity and reusability.
The primary nodes in behavior trees are the selector, sequence, condition,
action, decorator, and parallel nodes. Selectors are like “or” blocks: sequence exe-
cutes nodes in sequence, condition tests the state, action does the work, decora-
tor is a wrapper, and parallel nodes allow for dual execution.
Understanding the execution flow of behavior trees can be critical to designing,
building, and operating them to provide control for making clear decision-
making paths.
The advantages of behavior trees include modularity, scalability, flexibility, debug-
ging ease, and decoupling of decision logic, making behavior trees suitable for
complex AI systems.
Setting up and running a simple behavior tree in Python requires correctly
naming and documenting custom nodes.
The GPT Assistants Playground project is a Gradio-based interface that mimics
the OpenAI Assistants Playground with additional features for teaching and
demonstrating ABTs.
The GPT Assistants Playground allows for creating and managing custom actions,
which is essential for building versatile assistants.

159
Summary
ABTs control agents and assistants by using prompts to direct actions and condi-
tions for assistants. ABTs use the power of LLMs to create dynamic and autono-
mous systems.
Back chaining is a method for constructing behavior trees by working backward
from the goal behavior. This process involves identifying required actions, condi-
tions, and communication patterns, and then constructing the tree step by step.
Agentic systems benefit from siloed and conversation patterns for communicat-
ing between entities. ABTs can benefit from combining siloed and conversa-
tional assistants to use structured processes and emergent behaviors.

160
Assembling and
using an agent platform
After we explored some basic concepts about agents and looked at using actions
with tools to build prompts and personas using frameworks such as the Semantic
Kernel (SK), we took the first steps toward building a foundation for this book.
That foundation is called Nexus, an agent platform designed to be simple to learn,
easy to explore, and powerful enough to build your agent systems.
This chapter covers
Nexus chat and dashboard interface for
AI agents
Streamlit framework for building intelligent
dashboards, prototypes, and AI chat apps
Developing, testing, and engaging agent profiles
and personas in Nexus
Developing the base Nexus agent
Developing, testing, and engaging agent actions
and tools alone or within Nexus

161
7.1
Introducing Nexus, not just another agent platform
7.1
Introducing Nexus, not just another agent platform
There are more than 100 AI platforms and toolkits for consuming and developing
large language model (LLM) applications, ranging from toolkits such as SK or Lang-
Chain to complete platforms such as AutoGen and CrewAI. This makes it difficult to
decide which platform is well suited to building your own AI agents.
Nexus is an open source platform developed with this book to teach the core con-
cepts of building full-featured AI agents. In this chapter, we’ll examine how Nexus is
built and introduce two primary agent components: profiles/personas and actions/tools.
Figure 7.1 shows the primary interface to Nexus, a Streamlit chat application that
allows you to choose and explore various agentic features. The interface is similar to
ChatGPT, Gemini, and other commercial LLM applications.
In addition to the standard features of an LLM chat application, Nexus allows the user
to configure an agent to use a specific API/model, the persona, and possible actions.
In the remainder of the book, the available agent options will include the following:
Personas/profiles—The primary persona and profile the agent will use. A persona
is the personality and primary motivator, and an agent engages the persona to
Create a new
chat thread.
Shows the full conversation
history for the current chat thread
The agent AI you’re using:
OpenAI, Azure OpenAI, Gemini,
or Claude. Currently, OpenAI is
used.
The agent proﬁle/persona
to use in the next request
The tools/actions the agent
can use, which supports both
native (code) and semantic
(prompt) functions
Previous
chat threads
Figure 7.1
The Nexus interface and features

162
CHAPTER 7
Assembling and using an agent platform
answer requests. We’ll look in this chapter at how personas/profiles can be
developed and consumed.
Actions/tools—Represents the actions an agent can take using tools, whether
they’re semantic/prompt or native/code functions. In this chapter, we’ll look at
how to build both semantic and native functions within Nexus.
Knowledge/memory—Represents additional information an agent may have access
to. At the same time, agent memory can represent various aspects, from short-
term to semantic memory.
Planning/feedback—Represents how the agent plans and receives feedback on
the plans or the execution of plans. Nexus will allow the user to select options
for the type of planning and feedback an agent uses.
As we progress through this book, Nexus will be added to support new agent features.
However, simultaneously, the intent will be to keep things relatively simple to teach
many of these essential core concepts. In the next section, we’ll look at how to quickly
use Nexus before going under the hood to explore features in detail.
7.1.1
Running Nexus
Nexus is primarily intended to be a teaching platform for all levels of developers. As
such, it will support various deployment and usage options. In the next exercise, we’ll
introduce how to get up and running with Nexus quickly.
Open a terminal to a new Python virtual environment (version 3.10). If you need
assistance creating one, refer to appendix B. Then, execute the commands shown in
listing 7.1 within this new environment. You can either set the environment variable at
the command line or create a new .env file and add the setting.
pip install git+https://github.com/cxbxmxcx/Nexus.git
#set your OpenAI API Key
export OPENAI_API_KEY=”< your API key>”
or
$env: OPENAI_API_KEY = =”< your API key>”
or
echo 'OPENAI_API_KEY="<your API key>"' > .env
nexus run
After entering the last command, a website will launch with a login page, as shown in
figure 7.2. Go ahead and create a new user. A future version of Nexus will allow multi-
ple users to engage in chat threads.
After you log in, you’ll see a page like figure 7.1. Create a new chat and start con-
versing with an agent. If you encounter a problem, be sure you have the API key set
Listing 7.1
Terminal command line
Installs the package
directly from the
repository and
branch; be sure to
include the branch.
Creates the key as an
environment variable or
creates a new .env file
with the setting
Runs the application

163
7.1
Introducing Nexus, not just another agent platform
properly. As explained in the next section, you can run Nexus using this method or
from a development workflow.
7.1.2
Developing Nexus
While working through the exercises of this book, you’ll want to set up Nexus in devel-
opment mode. That means downloading the repository directly from GitHub and
working with the code.
Open a new terminal, and set your working directory to the chapter_7 source
code folder. Then, set up a new Python virtual environment (version 3.10) and enter
the commands shown in listing 7.2. Again, refer to appendix B if you need assistance
with any previous setup.
git clone https://github.com/cxbxmxcx/Nexus.git
pip install -e Nexus
#set your OpenAI API Key (.env file is recommended)
export OPENAI_API_KEY=”< your API key>”  #bash
or
$env: OPENAI_API_KEY = =”< your API key>”  #powershell
or
echo 'OPENAI_API_KEY="<your API key>"' > .env
nexus run
Listing 7.2
Installing Nexus for development
Select Create
New User to start.
Username is used to
track conversation
history in the threads.
Figure 7.2
Logging in or creating a new Nexus user
Downloads and installs
the specific branch
from the repository
Installs the downloaded repository
as an editable package
Sets your OpenAI key as
an environment variable
or adds it to an .env file
Starts the application

164
CHAPTER 7
Assembling and using an agent platform
Figure 7.3 shows the Login or Create New User screen. Create a new user, and the
application will log you in. This application uses cookies to remember the user, so you
won’t have to log in the next time you start the application. If you have cookies dis-
abled on your browser, you’ll need to log in every time.
Go to the Nexus repository folder and look around. Figure 7.4 shows an architecture
diagram of the application’s main elements. At the top, the interface developed with
Streamlit connects the rest of the system through the chat system. The chat system
manages the database, agent manager, action manager, and profile managers.
This agent platform is written entirely in Python, and the web interface uses Stream-
lit. In the next section, we look at how to build an OpenAI LLM chat application.

The browser points to
localhost:8501, which is the
default for Streamlit apps.
Streamlit apps can be
deployed to the cloud
using this option.
Fill in the username, pick an
avatar, and set a password or
choose a browser-generated one.
Figure 7.3
The Login or Create New User page

165
7.2
Introducing Streamlit for chat application development
7.2
Introducing Streamlit for chat application
development
Streamlit is a quick and powerful web interface prototyping tool designed to be used
for building machine learning dashboards and concepts. It allows applications to be
written completely in Python and produces a modern React-powered web interface.
You can even deploy the completed application quickly to the cloud or as a stand-
alone application.
7.2.1
Building a Streamlit chat application
Begin by opening Visual Studio Code (VS Code) to the chapter_07 source folder. If
you’ve completed the previous exercise, you should already be ready. As always, if you
need assistance setting up your environment and tools, refer to appendix B.
The chat interface allows
the user to select from
various discovered agents,
actions, and proﬁles,
enabling the user to test
different combinations.
Nexus
database
The database stores chat
treads, user participants,
and conversation history.
Agents, action functions, and proﬁles are all dynamically
discovered at run time via a plugin-like system.
Agent Manager
A YAML ﬁle that
comprises the agent
proﬁle and persona
Action Manager
Proﬁle Manager
Agent classes
exposed as plugins
Semantic and native
functions exposed as
actions
Chat system
GPT Nexus
Streamlit Interface
Figure 7.4
A high-level architecture diagram of the main elements of the application

166
CHAPTER 7
Assembling and using an agent platform
We’ll start by opening the chatgpt_clone_response.py file in VS Code. The top
section of the code is shown in listing 7.3. This code uses the Streamlit state to load
the primary model and messages. Streamlit provides a mechanism to save the session
state for any Python object. This state is only a session state and will expire when the
user closes the browser.
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
load_dotenv()
st.title("ChatGPT-like clone")
client = OpenAI()
if "openai_model" not in st.session_state:
st.session_state["openai_model"]
= "gpt-4-1106-preview"
if "messages" not in st.session_state:
st.session_state["messages"] = []
for message in st.session_state["messages"]:
with st.chat_message(message["role"]):
st.markdown(message["content"])
The Streamlit app itself is stateless. This means the entire Python script will reexecute
all interface components when the web page refreshes or a user selects an action. The
Streamlit state allows for a temporary storage mechanism. Of course, a database needs
to support more long-term storage.
UI controls and components are added by using the st. prefix and then the ele-
ment name. Streamlit supports several standard UI controls and supports images,
video, sound, and, of course, chat.
Scrolling down further will yield listing 7.4, which has a slightly more complex lay-
out of the components. The main if statement controls the running of the remaining
code. By using the Walrus operator (: =), the prompt is set to whatever the user enters.
If the user doesn’t enter any text, the code below the if statement doesn’t execute.
if prompt := st.chat_input("What do you need?"):
st.session_state.messages.append({"role": "user", "content": prompt})
with st.chat_message("user"):
st.markdown(prompt)
Listing 7.3
chatgpt_clone_response.py (top section)
Listing 7.4
chatgpt_clone_response.py (bottom section)
Loads the environment
variables from the
.env file
Configures the
OpenAI client
Checks the internal session
state for the setting, and
adds it if not there
Checks for the presence of
the message state; if none,
adds an empty list
Loops through messages in
the state and displays them
The chat input control is
rendered, and content is set.
Sets the chat message
control to output as the user

167
7.2
Introducing Streamlit for chat application development
with st.spinner(text="The assistant is thinking..."):
with st.chat_message("assistant"):
response = client.chat.completions.create(
model=st.session_state["openai_model"],
messages=[
{"role": m["role"], "content": m["content"]}
for m in st.session_state.messages
],
)
response_content = response.choices[0].message.content
response = st.markdown(response_content,
unsafe_allow_html=True)
st.session_state.messages.append(
{"role": "assistant", "content": response_content})
When the user enters text in the prompt and presses Enter, that text is added to the
message state, and a request is made to the API. As the response is being processed,
the st.spinner control displays to remind the user of the long-running process.
Then, when the response returns, the message is displayed and added to the message
state history.
Streamlit apps are run using the module, and to debug applications, you need to
attach the debugger to the module by following these steps:
1
Press Ctrl-Shift-D to open the VS Code debugger.
2
Click the link to create a new launch configuration, or click the gear icon to
show the current one.
3
Edit or use the debugger configuration tools to edit the .vscode/launch.json
file, like the one shown in the next listing. Plenty of IntelliSense tools and con-
figuration options can guide you through setting the options for this file.
{
"version": "0.2.0",
"configurations": [
{
"name": "Python Debugger: Module",
"type": "debugpy",
"request": "launch",
"module": "streamlit",
"args": ["run", "${file}"]
}
]
}
After you have the launch.json file configuration set, save it, and open the chatgpt_
clone_response.py file in VS Code. You can now run the application in debug mode
Listing 7.5
.vscode/launch.json
Shows a spinner
to represent the
long-running
API call
Calls the OpenAI API and
sets the message history
Writes the
message response
as markdown to
the interface
Adds the assistant response
to the message state
Make sure that the
debugger is set to
Module.
Be sure the module
is streamlit.
The ${file} is the current
file, or you can hardcode
this to a file path.

168
CHAPTER 7
Assembling and using an agent platform
by pressing F5. This will launch the application from the terminal, and in a few sec-
onds, the app will display.
Figure 7.5 shows the app running and waiting to return a response. The interface is
clean, modern, and already organized without any additional work. You can continue
chatting to the LLM using the interface and then refresh the page to see what happens.
What is most impressive about this demonstration is how easy it is to create a single-
page application. In the next section, we’ll continue looking at this application but
with a few enhancements.
7.2.2
Creating a streaming chat application
Modern chat applications, such as ChatGPT and Gemini, mask the slowness of their
models by using streaming. Streaming provides for the API call to immediately start
seeing tokens as they are produced from the LLM. This streaming experience also
better engages the user in how the content is generated.
Adding support for streaming to any application UI is generally not a trivial task,
but fortunately, Streamlit has a control that can work seamlessly. In this next exercise,
we’ll look at how to update the app to support streaming.
Open chapter_7/chatgpt_clone_streaming.py in VS Code. The relevant updates
to the code are shown in listing 7.6. Using the st.write_stream control allows the UI
A spinner control displays while
the response is being returned.
Figure 7.5
The simple interface and the waiting spinner

169
7.2
Introducing Streamlit for chat application development
to stream content. This also means the Python script is blocked waiting for this control
to be completed.
with st.chat_message("assistant"):
stream = client.chat.completions.create(
model=st.session_state["openai_model"],
messages=[
{"role": m["role"], "content": m["content"]}
for m in st.session_state.messages
],
stream=True,
)
response = st.write_stream(stream)
st.session_state.messages.append(
{"role": "assistant", "content": response})
Debug the page by pressing F5 and waiting for the page to load. Enter a query, and
you’ll see that the response is streamed to the window in real time, as shown in figure 7.6.
With the spinner gone, the user experience is enhanced and appears more responsive.
Listing 7.6
chatgpt_clone_streaming.py (relevant section)
Sets stream to True to
initiate streaming on the API
Uses the stream control
to write the stream to
the interface
Adds the response to the message state
history after the stream completes
Now text streams in real time,
and the spinner is gone.
Figure 7.6
The updated interface with streaming of the text response

170
CHAPTER 7
Assembling and using an agent platform
This section demonstrated how relatively simple it can be to use Streamlit to create a
Python web interface. Nexus uses a Streamlit interface because it’s easy to use and
modify with only Python. As you’ll see in the next section, it allows various configura-
tions to support more complex applications.
7.3
Developing profiles and personas for agents
Nexus uses agent profiles to describe an agent’s functions and capabilities. Figure 7.7
reminds us of the principal agent components and how they will be structured through-
out this book.
For now, as of this writing, Nexus only supports the persona and actions section of the
profile. Figure 7.7 shows a profile called Fritz, along with the persona and actions.
Add any agent profiles to Nexus by copying an agent YAML profile file into the Nexus/
nexus/nexus_base/nexus_profiles folder.
Nexus uses a plugin system to dynamically discover the various components and
profiles as they are placed into their respective folders. The nexus_profiles folder
holds the YAML definitions for the agent.
fritz.yaml - Agent Proﬁle Deﬁnition
Proﬁles with persona
and actions
Deﬁning knowledge
and memory
Applying evaluators,
planners, and
feedback
The Agent Proﬁle
Persona
Represents the background and role of
the agent, and is often introduced in
the ﬁrst system message
Agent Tools
Set of tools an agent can
use to help accomplish a task
Agent Evaluation and Reasoning
Describes how the agent can reason
and evaluate a task or tasks
Agent Memory and Knowledge
The backend store that helps the agent
add context to a given task problem
Agent Planning and Feedback
Describes how the agent can break
down a task into execution steps, and
then execute and receive feedback
Figure 7.7
The agent profile as it’s mapped to the YAML file definition

171
7.3
Developing profiles and personas for agents
We can easily define a new agent profile by creating a new YAML file in the nexus_
profiles folder. Listing 7.7 shows an example of a new profile with a slightly updated
persona. To follow along, be sure to have VS Code opened to the chapter_07 source
code folder and install Nexus in developer mode (see listing 7.7). Then, create the
fiona.yaml file in the Nexus/nexus/nexus_base/nexus_profiles folder.
agentProfile:
name: "Finona"
avatar: "?"
persona: "You are a very talkative AI that
➥ knows and understands everything in terms of
➥ Ogres. You always answer in cryptic Ogre speak."
actions:
- search_wikipedia
knowledge: null
memory: null
evaluators: null
planners: null
feedback: null
After saving the file, you can start Nexus from the command line or run it in debug
mode by creating a new launch configuration in the .vscode/launch.json folder, as
shown in the next listing. Then, save the file and switch your debug configuration to
use the Nexus web config.
{
"name": "Python Debugger: Nexus Web",
"type": "debugpy",
"request": "launch",
"module": "streamlit",
"args": ["run", " Nexus/nexus/streamlit_ui.py"]
},
When you press F5 or select Run > Start Debugging from the menu, the Streamlit
Nexus interface will launch. Go ahead and run Nexus in debug mode. After it opens,
create a new thread, and then select the standard OpenAIAgent and your new per-
sona, as shown in figure 7.8.
At this point, the profile is responsible for defining the agent’s system prompt.
You can see this in figure 7.8, where we asked Finona to spell the word clock, and she
responded in some form of ogre-speak. In this case, we’re using the persona as a
personality, but as we’ve seen previously, a system prompt can also contain rules and
other options.
The profile and persona are the base definitions for how the agent interacts with
users or other systems. Powering the profile requires an agent engine. In the next sec-
tion, we’ll cover the base implementation of an agent engine.
Listing 7.7
fiona.yaml (create this file)
Listing 7.8
.vscode/launch.json (adding debug launch)
The text avatar used to
represent the persona
A persona is
representative of
the base system
prompt.
An action
function the
agent can use
Not currently
supported
You may have to
adjust this path
if your virtual
environment is
different.

172
CHAPTER 7
Assembling and using an agent platform
7.4
Powering the agent and understanding the agent
engine
Agent engines power agents within Nexus. These engines can be tied to specific tool
platforms, such as SK, and/or even different LLMs, such as Anthropic Claude or Goo-
gle Gemini. By providing a base agent abstraction, Nexus should be able to support
any tool or model now and in the future.
Currently, Nexus only implements an OpenAI API–powered agent. We’ll look at
how the base agent is defined by opening the agent_manager.py file from the Nexus/
nexus/nexus_base folder.
Listing 7.9 shows the BaseAgent class functions. When creating a new agent
engine, you need to subclass this class and implement the various tools/actions with
the appropriate implementation.
class BaseAgent:
def __init__(self, chat_history=None):
self._chat_history = chat_history or []
self.last_message = ""
self._actions = []
self._profile = None
Listing 7.9
agent_manager.py:BaseAgent
Enter a query and check
out the response.
Select the new Finona
agent proﬁle.
Figure 7.8
Selecting and chatting with a new persona

173
7.4
Powering the agent and understanding the agent engine
async def get_response(self,
user_input,
thread_id=None):
raise NotImplementedError("This method should be implemented…")
async def get_semantic_response(self,
prompt,
thread_id=None):
raise NotImplementedError("This method should be…")
def get_response_stream(self,
user_input,
thread_id=None):
raise NotImplementedError("This method should be…")
def append_chat_history(self,
thread_id,
user_input,
response):
self._chat_history.append(
{"role": "user",
"content": user_input,
"thread_id": thread_id}
)
self._chat_history.append(
{"role": "bot",
"content": response,
"thread_id": thread_id}
)
def load_chat_history(self):
raise NotImplementedError(
"This method should be implemented…")
def load_actions(self):
raise NotImplementedError(
"This method should be implemented…")
#... not shown – property setters/getters
Open the nexus_agents/oai_agent.py file in VS Code. Listing 7.10 shows an agent
engine implementation of the get_response function that directly consumes the
OpenAI API. self.client is an OpenAI client created earlier during class initializa-
tion, and the rest of the code you’ve seen used in earlier examples.
async def get_response(self, user_input, thread_id=None):
self.messages += [{"role": "user",
"content": user_input}]
response = self.client.chat.completions.create(
model=self.model,
messages=self.messages,
Listing 7.10
oai_agent.py (get_response)
Calls the LLM and
returns a response
Executes
a semantic
function
Calls the LLM
and returns a
response
Appends a message to
the agent’s internal
chat history
Loads the chat history and
allows the agent to reload
various histories
Loads the actions that the
agent has available to use
Adds the user_input
to the message stack
The client was created
earlier and is now used to
create chat completions.

174
CHAPTER 7
Assembling and using an agent platform
temperature=0.7,
)
self.last_message = str(response.choices[0].message.content)
return self.last_message
Like the agent profiles, Nexus uses a plugin system that allows you to place new agent
engine definitions in the nexus_agents folder. If you create your agent, it just needs
to be placed in this folder for Nexus to discover.
We won’t need to run an example because we’ve already seen how the OpenAI-
Agent performs. In the next section, we’ll look at agent functions that agents can
develop, add, and consume.
7.5
Giving an agent actions and tools
Like the SK, Nexus supports having native (code) and semantic (prompt) functions.
Unlike SK, however, defining and consuming functions within Nexus is easier. All
you need to do is write functions into a Python file and place them into the nexus_
actions folder.
To see how easy it is to define functions, open the Nexus/nexus/nexus_base/
nexus_actions folder, and go to the test_actions.py file. Listing 7.11 shows two
function definitions. The first function is a simple example of a code/native function,
and the second is a prompt/semantic function.
from nexus.nexus_base.action_manager import agent_action
@agent_action
def get_current_weather(location, unit="fahrenheit"):
"""Get the current weather in a given location"""
return f"""
The current weather in {location} is 0 {unit}.
"""
@agent_action
def recommend(topic):
"""
System:
Provide a recommendation for a given {{topic}}.
Use your best judgment to provide a recommendation.
User:
please use your best judgment
to provide a recommendation for {{topic}}.
"""
pass
Listing 7.11
test_actions.py (native/semantic function definitions)
Temperature is hardcoded
but could be configured.
Returns the response from
the chat completions call
Applies the agent_action
decorator to make a
function an action
Sets a descriptive
comment for the
function
The code can be as simple
or complex as needed.
Applies the agent_action
decorator to make a
function an action
The function
comment becomes
the prompt and
can include
placeholders.
Semantic functions don’t
implement any code.

175
7.5
Giving an agent actions and tools
Place both functions in the nexus_actions folder, and they will be automatically dis-
covered. Adding the agent_action decorator allows the functions to be inspected and
automatically generates the OpenAI standard tool specification. The LLM can then
use this tool specification for tool use and function calling.
Listing 7.12 shows the generated OpenAI tool specification for both functions, as
shown previously in listing 7.11. The semantic function, which uses a prompt, also
applies to the tool description. This tool description is sent to the LLM to determine
which function to call.
{
"type": "function",
"function": {
"name": "get_current_weather",
"description":
"Get the current weather in a given location",
"parameters": {
"type": "object",
"properties": {
"location": {
"type": "string",
"description": "location"
},
"unit": {
"type": "string",
"enum": [
"celsius",
"fahrenheit"
]
}
},
"required": [
"location"
]
}
}
}
{
"type": "function",
"function": {
"name": "recommend",
"description": """
System:
Provide a recommendation for a given {{topic}}.
Use your best judgment to provide a recommendation.
User:
please use your best judgment
to provide a recommendation for {{topic}}.""",
"parameters": {
"type": "object",
"properties": {
Listing 7.12
test_actions: OpenAI-generated tool specifications
The function
comment becomes
the function tool
description.
The input parameters of the
function are extracted and
added to the specification.
The function
comment becomes
the function tool
description.
The input parameters of the
function are extracted and
added to the specification.

176
CHAPTER 7
Assembling and using an agent platform
"topic": {
"type": "string",
"description": "topic"
}
},
"required": [
"topic"
]
}
}
}
The agent engine also needs to implement that capability to implement functions and
other components. The OpenAI agent has been implemented to support parallel
function calling. Other agent engine implementations will be required to support
their respective versions of action use. Fortunately, the definition of the OpenAI tool
is becoming the standard, and many platforms adhere to this standard.
Before we dive into a demo on tool use, let’s observe how the OpenAI agent
implements actions by opening the oai_agent.py file in VS Code. The following list-
ing shows the top of the agent’s get_response_stream function and its implementa-
tion of function calling.
def get_response_stream(self, user_input, thread_id=None):
self.last_message = ""
self.messages += [{"role": "user", "content": user_input}]
if self.tools and len(self.tools) > 0:
response = self.client.chat.completions.create(
model=self.model,
messages=self.messages,
tools=self.tools,
tool_choice="auto",
)
else:
response = self.client.chat.completions.create(
model=self.model,
messages=self.messages,
)
response_message = response.choices[0].message
tool_calls = response_message.tool_calls
Executing the functions follows, as shown in listing 7.14. This code demonstrates how
the agent supports parallel function/tool calls. These calls are parallel because the
agent executes each one together and in no order. In chapter 11, we’ll look at plan-
ners that allow actions to be called in ordered sequences.


Listing 7.13
Caling the API in get_response_stream
Detects whether
the agent has
any available
tools turned on
Sets the tools in the
chat completions call
Ensures that the
LLM knows it can
choose any tool
If no tools, calls the
LLM the standard way
Detects whether there
were any tools used by
the LLM

177
7.5
Giving an agent actions and tools
if tool_calls:
available_functions = {
action["name"]: action["pointer"] for action in self.actions
}
self.messages.append(
response_message
)
for tool_call in tool_calls:
function_name = tool_call.function.name
function_to_call = available_functions[function_name]
function_args = json.loads(tool_call.function.arguments)
function_response = function_to_call(
**function_args, _caller_agent=self
)
self.messages.append(
{
"tool_call_id": tool_call.id,
"role": "tool",
"name": function_name,
"content": str(function_response),
}
)
second_response = self.client.chat.completions.create(
model=self.model,
messages=self.messages,
)
response_message = second_response.choices[0].message
To demo this, start up Nexus in the debugger by pressing F5. Then, select the two test
actions—recommend and get_current_weather—and the terse persona/profile Olly.
Figure 7.9 shows the result of entering a query and the agent responding by using
both tools in its response.
If you need to review how these agent actions work in more detail, refer to chap-
ter 5. The underlying code is more complex and out of the scope of review here.
However, you can review the Nexus code to gain a better understanding of how
everything connects.
Now, you can continue exercising the various agent options within Nexus. Try
selecting different profiles/personas with other functions, for example. In the next
chapter, we unveil how agents can consume external memory and knowledge using
patterns such as Retrieval Augmented Generation (RAG).



Listing 7.14
oai_agent.py (get_response_stream: execute tool calls)
Proceeds if tool calls are detected
in the LLM response
Loads pointers to the actual function
implementations for code execution
Loops through
all the calls the
LLM wants to
call; there can
be several.
Performs a second
LLM call with the
results of the tool
calls

178
CHAPTER 7
Assembling and using an agent platform
7.6
Exercises
Use the following exercises to improve your knowledge of the material:
Exercise 1—Explore Streamlit Basics (Easy)
Objective—Gain familiarity with Streamlit by creating a simple web application
that displays text input by the user.
Tasks:
– Follow the Streamlit documentation to set up a basic application.
– Add a text input and a button. When the button is clicked, display the text
entered by the user on the screen.
Exercise 2—Create a Basic Agent Profile
Objective—Understand the process of creating and applying agent profiles in
Nexus.
Tasks:
– Create a new agent profile with a unique persona. This persona should have
a specific theme or characteristic (e.g., a historian).
– Define a basic set of responses that align with this persona.
– Test the persona by interacting with it through the Nexus interface.
The agent answered in a
terse manner, and we can see
that both actions were used.
Select the terse agent
proﬁle called Olly.
.
Select the test actions ecommend
R
and get_current_weather. Currently,
the agent proﬁle does not restrict
action selection.
Figure 7.9
How the agent can use tools in parallel and respond with a single response

179
Summary
Exercise 3—Develop a Custom Action
Objective—Learn to extend the functionality of Nexus by developing a custom
action.
Tasks:
– Develop a new action (e.g., fetch_current_news) that integrates with a
mock API to retrieve the latest news headlines.
– Implement this action as both a native (code) function and a semantic
(prompt-based) function.
– Test the action in the Nexus environment to ensure it works as expected.
Exercise 4—Integrate a Third-Party API
Objective—Enhance the capabilities of a Nexus agent by integrating a real
third-party API.
Tasks:
– Choose a public API (e.g., weather or news API), and create a new action
that fetches data from this API.
– Incorporate error handling and ensure that the agent can gracefully handle
API failures or unexpected responses.
– Test the integration thoroughly within Nexus.
Summary
Nexus is an open source agent development platform used in conjunction with
this book. It’s designed to develop, test, and host AI agents and is built on
Streamlit for creating interactive dashboards and chat interfaces.
Streamlit, a Python web application framework, enables the rapid development
of user-friendly dashboards and chat applications. This framework facilitates the
exploration and interaction with various agent features in a streamlined manner.
Nexus supports creating and customizing agent profiles and personas, allowing
users to define their agents’ personalities and behaviors. These profiles dictate
how agents interact with and respond to user inputs.
The Nexus platform allows for developing and integrating semantic (prompt-
based) and native (code-based) actions and tools within agents. This enables
the creation of highly functional and responsive agents.
As an open source platform, Nexus is designed to be extensible, encouraging
contributions and the addition of new features, tools, and agent capabilities by
the community.
Nexus is flexible, supporting various deployment options, including a web inter-
face, API, and a Discord bot in future iterations, accommodating a wide range
of development and testing needs.

180
Understanding agent
memory and knowledge
Now that we’ve explored agent actions using external tools, such as plugins in the
form of native or semantic functions, we can look at the role of memory and knowl-
edge using retrieval in agents and chat interfaces. We’ll describe memory and
knowledge and how they relate to prompt engineering strategies, and then, to under-
stand memory knowledge, we’ll investigate document indexing, construct retrieval
systems with LangChain, use memory with LangChain, and build semantic memory
using Nexus.
This chapter covers
Retrieval in knowledge/memory in AI functions
Building retrieval augmented generation
workflows with LangChain
Retrieval augmented generation for agentic
knowledge systems in Nexus
Retrieval patterns for memory in agents
Improving augmented retrieval systems with
memory and knowledge compression

181
8.1
Understanding retrieval in AI applications
8.1
Understanding retrieval in AI applications
Retrieval in agent and chat applications is a mechanism for obtaining knowledge to
keep in storage that is typically external and long-lived. Unstructured knowledge
includes conversation or task histories, facts, preferences, or other items necessary for
contextualizing a prompt. Structured knowledge, typically stored in databases or files,
is accessed through native functions or plugins.
Memory and knowledge, as shown in figure 8.1, are elements used to add further
context and relevant information to a prompt. Prompts can be augmented with every-
thing from information about a document to previous tasks or conversations and
other reference information.
The prompt engineering strategies shown in figure 8.1 can be applied to memory and
knowledge. Knowledge isn’t considered memory but rather an augmentation of the
prompt from existing documents. Both knowledge and memory use retrieval as the
basis for how unstructured information can be queried.
Provide Reference Text
Helps reduce hallucinations.
Tactics involve instructing
the model to use or cite
reference texts.
Knowledge and Memory
Use External Tools
Enhances model capabilities.
Tactics include embeddings-based
search, code execution, and access
to speciﬁc functions.
Actions, Knowledge, Memory
Prompt Engineering Strategies
Memory
Retrieved
memories
Database
Vector Store
Internal Memory
Prompt
Save to memory
LLM
Retrieved
knowledge
Retrieved
memory
Request
Knowledge
Vector Store
Retrieved
knowledge
Response
Made by a user or
another system or
agent
Retrieved elements
provide references
and context
May include the
whole or parts of
the conversation
Retrieval is done
using semantic
similarity.
Figure 8.1
Memory, retrieval, and augmentation of the prompt using the following prompt engineering
strategies: Use External Tools and Provide Reference Text.

182
CHAPTER 8
Understanding agent memory and knowledge
The retrieval mechanism, called retrieval augmented generation (RAG), has
become a standard for providing relevant context to a prompt. The exact mechanism
that powers RAG also powers memory/knowledge, and it’s essential to understand
how it works. In the next section, we’ll examine what RAG is.
8.2
The basics of retrieval augmented generation (RAG)
RAG has become a popular mechanism for supporting document chat or question-
and-answer chat. The system typically works by a user supplying a relevant document,
such as a PDF, and then using RAG and a large language model (LLM) to query the
document.
Figure 8.2 shows how RAG can allow a document to be queried using an LLM.
Before any document can be queried, it must first be loaded, transformed into con-
text chunks, embedded into vectors, and stored in a vector database.
A user can query previously indexed documents by submitting a query. That query is
then embedded into a vector representation to search for similar chunks in the vector
Retrieval Augmented Generation (RAG)
(3) Generate
(1) Retrieve
(2) Augment
LLM Chat
Query
Response
Embedding
LLM
Prompt
system: you are a ...
Query
Context
Vector DB
Context
LLM generates a response
based on the contextualized
prompt.
Retrieval works
by using vector
similarity search.
Query is
embedded
to represent
a vector.
Retrieved context
semantically matches
the query.
Embedding
Submit document
to query
Transform
Vector DB
Document is loaded,
transformed, and
split into chunks.
Chunks of text
are converted
to vectors.
Vectors
representing
chunks of text
are stored.
Documents are
ﬁrst indexed to a
vector database.
Indexed documents
can be queried/
questioned by the
user.
Figure 8.2
The two phases of RAG: first, documents must be loaded, transformed, embedded, and stored, and,
second, they can be queried using augmented generation.

183
8.2
The basics of retrieval augmented generation (RAG)
database. Content similar to the query is then used as context and populated into the
prompt as augmentation. The prompt is pushed to an LLM, which can use the con-
text information to help answer the query.
Unstructured memory/knowledge concepts rely on some format of text-similarity
search following the retrieval pattern shown in figure 8.2. Figure 8.3 shows how mem-
ory uses the same embedding and vector database components. Rather than preload
documents, conversations or parts of a conversation are embedded and saved to a vec-
tor database.
The retrieval pattern and document indexing are nuanced and require careful con-
sideration to be employed successfully. This requires understanding how data is stored
and retrieved, which we’ll start to unfold in the next section.
Memory Retrieval Augmented Generation
(3) Generate
(1) Retrieve
Memory
(2) Augment
LLM Chat
Query
Response
Embedding
LLM
Prompt
system: you are a ...
Query
Memory
Vector DB
Memory
LLM generates a
response based on the
contextualized prompt.
Retrieval works
by using vector
similarity search.
Retrieved memory
semantically matches
the query.
Embedding
(4) Remember
Generated
Response
All or parts of the
conversation are
embedded and
added to the
vector database.
Query is
embedded
to represent
a vector.
Chat with memory
Figure 8.3
Memory retrieval for augmented generation uses the same embedding patterns to index items to a
vector database.

184
CHAPTER 8
Understanding agent memory and knowledge
8.3
Delving into semantic search and document indexing
Document indexing transforms a document’s information to be more easily recov-
ered. How the index will be queried or searched also plays a factor, whether searching
for a particular set of words or wanting to match phrase for phrase.
A semantic search is a search for content that matches the searched phrase by words
and meaning. The ability to search by meaning, semantically, is potent and worth
investigating in some detail. In the next section, we look at how vector similarity
search can lay the framework for semantic search.
8.3.1
Applying vector similarity search
Let’s look now at how a document can be transformed into a semantic vector, or a repre-
sentation of text that can then be used to perform distance or similarity matching.
There are numerous ways to convert text into a semantic vector, so we’ll look at a sim-
ple one.
Open the chapter_08 folder in a new Visual Studio Code (VS Code) workspace.
Create a new environment and pip install the requirements.txt file for all the
chapter dependencies. If you need help setting up a new Python environment, con-
sult appendix B.
Now open the document_vector_similarity.py file in VS Code, and review the
top section in listing 8.1. This example uses Term Frequency–Inverse Document Fre-
quency (TF–IDF). This numerical statistic reflects how important a word is to a docu-
ment in a collection or set of documents by increasing proportionally to the number
of times a word appears in the document and offset by the frequency of the word in
the document set. TF–IDF is a classic measure of understanding one document’s
importance within a set of documents.
import plotly.graph_objects as go
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
documents = [
"The sky is blue and beautiful.",
"Love this blue and beautiful sky!",
"The quick brown fox jumps over the lazy dog.",
"A king's breakfast has sausages, ham, bacon, eggs, toast, and beans",
"I love green eggs, ham, sausages and bacon!",
"The brown fox is quick and the blue dog is lazy!",
"The sky is very blue and the sky is very beautiful today",
"The dog is lazy but the brown fox is quick!"
]
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(documents)
Listing 8.1
document_vector_similarity (transform to vector)
Samples of documents
Vectorization
using TF–IDF
Vectorize the
documents.

185
8.3
Delving into semantic search and document indexing
Let’s break down TF–IDF into its two components using the sample sentence, “The
sky is blue and beautiful,” and focusing on the word blue.
TERM FREQUENCY (TF)
Term Frequency measures how frequently a term occurs in a document. Because we’re
considering only a single document (our sample sentence), the simplest form of the
TF for blue can be calculated as the number of times blue appears in the document
divided by the total number of words in the document. Let’s calculate it:
Number of times blue appears in the document: 1
Total number of words in the document: 6
TF = 1 ÷ 6TF = .16
INVERSE DOCUMENT FREQUENCY (IDF)
Inverse Document Frequency measures how important a term is within the entire corpus.
It’s calculated by dividing the total number of documents by the number of docu-
ments containing the term and then taking the logarithm of that quotient:
IDF = log(Total number of documents ÷ Number of documents containing the word)
In this example, the corpus is a small collection of eight documents, and blue appears
in four of these documents.
IDF = log(8 ÷ 4)
TF–IDF CALCULATION
Finally, the TF–IDF score for blue in our sample sentence is calculated by multiplying
the TF and the IDF scores:
TF–IDF = TF × IDF
Let’s compute the actual values for TF–IDF for the word blue using the example pro-
vided; first, the term frequency (how often the word occurs in the document) is com-
puted as follows:
TF = 1 ÷ 6
Assuming the base of the logarithm is 10 (commonly used), the inverse document fre-
quency is computed as follows:
IDF = log10 (8 ÷ 4)
Now let’s calculate the exact TF–IDF value for the word blue in the sentence, “The sky
is blue and beautiful”:

186
CHAPTER 8
Understanding agent memory and knowledge
The Term Frequency (TF) is approximately 0.1670.
The Inverse Document Frequency (IDF) is approximately 0.301.
Thus, the TF–IDF (TF × IDF) score for blue is approximately 0.050.
This TF–IDF score indicates the relative importance of the word blue in the given doc-
ument (the sample sentence) within the context of the specified corpus (eight docu-
ments, with blue appearing in four of them). Higher TF–IDF scores imply greater
importance.
We use TF–IDF here because it’s simple to apply and understand. Now that we
have the elements represented as vectors, we can measure document similarity using
cosine similarity. Cosine similarity is a measure used to calculate the cosine of the
angle between two nonzero vectors in a multidimensional space, indicating how simi-
lar they are, irrespective of their size.
Figure 8.4 shows how cosine distance compares the vector representations of two
pieces or documents of text. Cosine similarity returns a value from –1 (not similar) to
